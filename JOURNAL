INDEX
-----
	* 04 Nov '22
	* 11 Nov '22
	* 13 Nov '22
	* 15 Nov '22
	* 18 Nov '22
	* 30 Nov '22
	* 01 Dec '22
	* 03 Dec '22
	* 05 Dec '22
	* 06 Dec '22
	* 07 Dec '22
	* 08 Dec '22
	* 09 Dec '22
	* 12 Dec '22
	* 15 Dec '22
	* 16 Dec '22
	* 18 Dec '22
	* 19 Dec '22
	* 20 Dec '22
	* 22 Dec '22
	* 23 Dec '22
	* 06 Jan '23
	* 07 Jan '23
	* 08 Jan '23
	* 10 Jan '23
	* 11 Jan '23
	* 12 Jan '23
	* 13 Jan '23
	* 14 Jan '23
	* 16 Jan '23
	* 17 Jan '23
	* 18 Jan '23
	* 23 Jan '23
	* 26 Jan '23
	* 01 Feb '23
	* 03 Feb '23
	* 15 Feb '23
	* 21 Feb '23
	* 22 Feb '23
	* 23 Feb '23
	* 24 Feb '23
	* 25 Feb '23
	* 27 Feb '23
	* 01 Mar '23
	* 06 Mar '23
	* 08 Mar '23
	* 10 Mar '23
	* 11 Mar '23
	* 14 Mar '23
	* 15 Mar '23
	* 16 Mar '23
	* 17 Mar '23
	* 21 Mar '23
	* 23 Mar '23
	* 01 Apr '23
	* 03 Apr '23
	* 05 Apr '23
	* 18 Apr '23
	* 20 Apr '23
	* 21 Apr '23
	* 22 Apr '23
	* 25 Apr '23
	* 27 Apr '23
	* 29 Apr '23
	* 01 May '23
	* 09 May '23
	* 10 May '23
	* 17 May '23
	* 19 May '23
	* 22 May '23
	* 26 May '23
	* 29 May '23
	* 08 Jun '23
	* 26 Jun '23
	* 27 Jun '23
	* 28 Jun '23
	* 01 Jul '23
	* 07 Jul '23
	* 13 Jul '23
	* 18 Jul '23
	* 19 Jul '23
	* 20 Jul '23
	* 26 Jul '23
	* 31 Jul '23
	* 01 Aug '23
	* 04 Aug '23
	* 08 Aug '23
	* 09 Aug '23
	* 11 Aug '23
	* 14 Aug '23
	* 15 Aug '23
	* 16 Aug '23
	* 17 Aug '23
	* 21 Aug '23
	* 22 Aug '23
	* 23 Aug '23
	* 24 Aug '23
	* 25 Aug '23
	* 26 Aug '23
	* 28 Aug '23
	* 01 Sep '23
	* 02 Sep '23
	* 08 Sep '23
	* 15 Sep '23
	* 18 Sep '23
	* 22 Sep '23
	* 25 Sep '23
	* 14 Oct '23
	* 16 Oct '23
	* 18 Oct '23
	* 19 Oct '23
	* 23 Oct '23
	* 25 Oct '23
	* 30 Oct '23
	* 06 Nov '23
	* 28 Nov '23
	* 04 Dec '23
	* 23 Dec '23
	* 02 Jan '24
	* 10 Jan '24
	* 16 Jan '24
	* 17 Jan '24
	* 05 Feb '24
	* 09 Feb '24
	* 12 Feb '24
	* 13 Feb '24
	* 19 Feb '24
	* 20 Feb '24
	* 22 Feb '24

04 Nov '22
----------
These are just some notes to keep track of the changes made during porting.

For the initial bootstrap, I used nasm+x86 and coded up the Perl scripts
"genprims" and "genrom" to help with the bootstrap. Having those scripts handy
turned out to be pretty helpful, or at least ease some parts of the very first
"porting" exercise (if you want to call it that), which was to support an
additional assembler, again on x86 - the GNU "as" assembler.

The following were the main changes in assembler code that were needed:
- Comments start with ';' on nasm, it needs to be '#' in GNU "as"
- Registers need to be prefixed with the '%' character in GNU "as"
- Register indirect jumps needs an additional '*' prefix in GNU "as"
- Memory access indexed via a register is denoted with [] in nasm and () in "as"
- Source and destination ops are reversed, source is to the left, in GNU "as"
- byte allocation on nasm uses "db", it is ".byte" on GNU "as"
- word allocation on nasm uses "dw", it is ".word" on GNU "as"
- nasm uses %ifdef ... %endif whereas #ifdef ... #endif is used in GNU "as"
- nasm uses %define whereas #define is used in GNU "as"

During the port, to GNU "as", it helped that I already had a working emulator
and the scripts to generate x86 assembly equivalents from the Forth DSL.

I could have used the existing regression tests as is, but I decided to
change the ordering in which the Forth primitives were added so as to include
the branch operators early so that the testsuite could use the if{ ... }if
construct instead of writing out bytes to stdin and comparing them against
an "expected" set of bytes.

So due to the change in the ordering in which primitives were added and the
use of if{ ... }if for the regression tests, there is now an all new regression
testsuite (in addition to the previous one) either of which can be used during
any additional porting work.

This port from the nasm assembler to GNU assembler could have been done all
in one shot, using say, yet another Perl script, that translated from the nasm
style assembly code to the GNU "as" format, based on the changes in assembly
code format that were called out above. Instead, I chose to do it in a step
wise fashion so that each word could be regression tested, one at a time,
as it was being added, rather than having to troubleshoot one big blob
of code, at the very end. Doing it this way also serves as a good practice run
for what I expect will be the same process which will need to be repeated for
each new architecture to which this code will need to be ported.

So, now that I'm ready to call the x86 port done, I have a choice of which
architecture to pick next and some of the options I've listed below are in
the order in which I learnt about them (starting from the time I first came
across them as a kid)
- Z80 (ZX Spectrum)
- PDP11 ("Computer Organization" by Hamacher, Vranesic and Zaky)
- MIX (Knuth's Ye Olde Computer)
- 8085 (or was it an 8080? not sure anymore - a box with keypad for m/c code)
- x86 (IBM PC) : I'll consider this bootstrap/port already complete
- 68000 (Sun Microsystems?)
- SPARC (Sun Microsystems)
- MSP430 (TI dev board)
- ARM (ST's STM discovery board)
- RISC-V (just because it is the new hotness)

Initially I thought of doing the ports in the order listed above, starting with
Z80. One reason for giving the Z80 port a shot first is just for old times sake
since it was the first processor on which I tried to code Forth and also since
it has fewer registers than x86 and I assume it will be interesting to see how
things pan out with those tighter constraints. To be frank though, I'm torn as
to whether I should try my hand at the MIX CPU first, simply to see what fun
ensues on an arcane CPU which no one cares for anymore.

Finally I decided on going down a completely different path, to take what might
be a retrogressive step backwards (or is it sideways?) and create the next port
for C/POSIX. Obviously, the resulting implementation of Forth may then end up
being neither small nor baremetal but it does give a massive boost in terms of
portability so long as a C compiler for that given architecture exists and it
also gives me a data point for comparison with the other baremetal ported
implementation both in terms of size and speed (if I ever get around to start
performance benchmarking all of this). I assume it might also help with some
of the porting work since I could take a peek at what C generates on that
architecture (assuming the C compiler does a passable job of generating good
code for that architecture) and use that as a guide to shorten the time spent
reading data sheets and instruction set docs.

11 Nov '22
----------
The difficulty I'm running into now with the C port is that it is turning into
what appears to be a long drawn out struggle between C and Forth to figure out
who has first dibs on access to the system.

Forth obviously considers the entire machine as personal property unto itself,
to treat as it wishes. For example, Forth needs access to the return stack but
modifying the return stack in C looks like a fairly heavyweight operation using
getcontext/setcontext or other lower level alternatives using "asm"

There is also clearly an impedance mismatch between Forth's view of memory and
the memory abstraction that C provides - especially since the Forth bit'ness
of this implementation by design is 16 bits vs whatever processor bit width it
happens to be on the system that the C compiler is running on.

Rather than go into contortions trying to make the two world views conform to
fit each other, I'll call this port to C complete, for the most part, since new
Forth definitions can be added to defs.4th (although clipping its wings like
this makes for a very crippled/powerless Forth implementation).

So it does look like there is a real need for direct access to the CPU to have
Forth's power shine forth, so I think I'll go back to the original roadmap and
pick up things back up from where I left off, looking at what port to do next.

13 Nov '22
----------
Rather than jump directly into selecting a processor for the next round of the
porting exercise, I decided to take a step back to look at where I could be
more productive and not waste time on repetitive grunt work.

So now that I've done the porting exercise a couple of times, one thing that
I've found which appears to be a serious waste of time is starting over from
scratch for each port with an empty rom.4th and then adding the same generic
code over and over again after each step as the port progresses. For example,
the rom.4th changes to verify the key/emit functionality was done in commit
589f315d74e90e3e097112dc8760b41cdf958a22 at the time of the initial bootstrap.
At the time of "porting" this change to GNU "as", the same set of changes was
done in rom.4th at commit 2eba44f4643e42c98b8cf654c3936a333a4e225d. This was
repeated yet again at the time of the C port, when the exact same set of
changes to rom.4th was made in commit 07c25aaf30e1a7dc0a566adc086e3d0a3f896519

So rather than repeat this for each port, it makes sense to abstract out
the generic code in rom.4th and delimit each step of the porting process
within that file so that we can increase a "step" variable after each step
of the porting process so that when all the "steps" are complete, and all the
tests run successfully, we can declare that port complete.

This removes all of the duplicated effort that goes into keeping the tests
(which are part of rom.4th) in sync with each of the porting steps. Instead
of that approach, the new process ensures that the rom.4th contents remain
the same for all ports and the only thing that changes is the "step" variable
(which in some sense denotes the progress of a specific port).

Only time will tell if this "premature standardization" is a good thing or not.

As part of this process, I've also decided to add yet another primitive and
sneak it into the rom.4th "standard" as part of this overhaul. The primary
reason to add it in is for symmetry with "pick". For lack of a better name,
I'm calling it "stick" and like "pick", which gets an element from the stack,
"stick" replaces an element in the stack with a new value.

To parameterize individual ports, I've added a provision for Perl/shell-like
"dollar" variables. Since the code processor does not yet exist, I've not
modified the existing rom.4th files but created the new/generic version at
the top level. As this gets fleshed out and tested, the other rom.4th files
will be eventually obsoleted and removed.

---

That's it for the technical part of this journal entry. On a personal note,
as of today, it is 13 years since Lisa died. She would have been just the age
at which I was getting into the swing of all things related to coding. I wonder
if she would have chosen to be a coder like me.

Anyway, miss you Lisamma.

15 Nov '22
----------
I'm yet again at the crossroads of choosing a processor to work on next and as
with the earlier choice that was made, of fleshing out the generic test code in
rom.4th first, I've chosen to again start off by writing up what amounts to an
elaborate and generic how-to/"process document" on how to go about the porting
exercise for any given processor. It is meant to match up with the "step"s in
the rom.4th test cases although there isn't an exact 1-1 correspondence since
this "code" is meant to be more for human consumption than for direct use by
machine.

This is also an attempt to consolidate the things I've learnt from the previous
round of porting exercises that have been completed so far and the expectation
is that this "code" will continue to be updated with newer ideas as I work on
additional ports for other CPUs.

Since it is written for a "generic" CPU, I've placed it under pseudo/code since
much of the "code", if you want to call it that, is a mishmash of C and Forth
along with some non-C like notation for auto increment/decrement borrowed from
6809 assembly code. Although it is pseudo-code I've written it in a way such
that it may be possible to write a parser for it and turn it into machine code.

18 Nov '22
----------
This is starting to become a pattern now I guess: everytime I think I should
start on a new port, the overhang of the previous work takes me off on yet
another tangent. In this case it is an attempt to make sure that the new
version of the tests in rom.4th can actually work seamlessly with the original
code. The newer version of rom.4th had some changes from the version in the
port directories so I assume it is wise to test stuff out now on known code
rather than figure things out the hard way on unknown code where I'm wrangling
a new CPU and new toolchain along with the newer tests. It will also prove
if this strategy was a good choice to begin with.

30 Nov '22
----------
I think the x86 port is now complete (yes, really, at least to my satisfaction)
now that the last of the annoying little techdebt details are cleared. So I can
declare unambiguosly that it is now time to start on the next port.

In the initial list of architectures that I had listed in the PORTING doc, I
realized that I missed a truly important one: the PDP11 (I've updated it there
now). In my early student days, we covered the PDP11 as part of the course on
"Computer Organization" based on the textbook of the same name authored by
V. Carl Hamacher, Zvonko G. Vranesic and Safwat G. Zaky.

---

A small personal anecdote about this book : I bought this book long, long ago
when I was a student (when it, quite literally, cost a fortune). From the
scribbles on the back of the book, it looks like the price was $7.95 (USD? or
more likely Singapore Dollar, since it is the "International Student Edition"
printed in Singapore) and it was sold for the princely sum of Indian Rs 125/-
which in my student days would probably have been about ~2-4 months worth of
lunch money. This was in the late 80's so I'm really dating myself here. I'm
really grateful that my Dad (Happy Birthday, Apai!) and Mom plunked down their
hard earned money to buy this book for me.

Thank you Apai & Mom! :heart: :RIP:

---

Switching back to the technical discussion, the pseudo code (in pseudo/code)
that I wrote to help with the porting reminded me of how well attuned the PDP11
instructions are to the programmers needs from an assembly coding point of view

I'll assume that the instruction sets of the 68000 and the MSP430, both of
which are elegant in their own ways, all trace their lineage back to this
beautifully crafted, gem of an ISA. Obviously, I can only talk about what I
know, so in case the PDP11 inherited its elegance from an earlier design, then
hey, here's a shout out to them too.

Some research into how to emulate a PDP11 and cross-compile/build for it led me
to: https://ancientbits.blogspot.com/2012/07/programming-barebones-pdp11.html
which walks through all of the steps required to do this in excellent detail.

The quick summary/cheatsheet is:
- Build/install binutils (for pdp11-aout-as and pdp11-aout-ld)
- Build/install simh to emulate the PDP11
- Build bin2load from https://github.com/jguillaumes/retroutils
  This utility is used to modify the a.out binary generated by the pdp11 as/ld
  into a "lda" binary which can be load'ed directly by simh during emulation.

Using these instructions I was able to successfully complete the "Preamble"
step of porting documented in pseudo/code for the PDP11 port.

01 Dec '22
----------
Starting at step 0 of the porting work for PDP11 brought me back to yet another
round of thinking about the format of code.prims. So far, I've used the
	code{ ... }code, inner{ ... }inner and fallthru
among other directives for the assembly language primitives of the x86 ports
but looking back at it now, I find all of that a bit too verbose compared to
the spareness of Forth's own : ... ; notation. So as an experiment, I'm going
to try doing an exercise in extreme minimalism: what if assembly code did not
use any type of decoration whatsoever?

So the plan is that assembly code will be written in code.prims in the format:
	forthlabel : assembly-line1 ; assembly-line2 ; ... ;
all on one line to improve the "code density". The "forthlabel" is just the
conventional forth word name and the assembly code delimited by the semicolons
implement that word.

Since this will be preprocessed by the genprims script anyway, I'm thinking of
putting a spin on it though, where ';' will serve multiple purposes which
hopefully won't cause me too much confusion down the line.

As mentioned above, the ';' serves to delimit independent assembly code lines
but the new spin on it is that it also serves to denote calling "next" if it
is the terminating character on a line. If the line is not terminated by a
semicolon, the expectation is that the code will fall through to the next line
of code below it. So code blocks that currently looks like this:

	code{
	foo bar
		line1
		line2
		...
	}code

will turn into this:

	foo : line1 ; line2 ; ...

Note that the assembly label "bar" in the original code is no longer needed
since it will be auto-generated by the genprims script. In the initial x86
port, "bar" was usually a copy of "foo" if "foo" was alphanumeric (for example
"emit emit") or an alphanumeric replacement (for example "@ fetch"). I've
tried to semi-automate this by using the forth label if it is alphanumeric.

Similarly, inner{ ... }inner code blocks that currently looks like this:

	inner{
	foo bar
		line1
		line2
		...
	}inner

will turn into this:

	foo : line1 ; line2 ; ... ;

Note the addition of the terminating ';' in case of "inner" blocks which is
meant to denote adding the implicit call to "next".

Code blocks that needed "fallthru" can also be denoted in the new scheme just
by leaving out the terminating semicolon. Hopefully, this will make for a much
shorter and crisper implementation.

Although the purpose of the overall project is to showcase a really small Forth
implementation, simh/PDP11 provides me 64K of RAM which is such a luxury that
I'm going on a splurge and use an entire 16 bits for each word offset. This is
a code size win even for jsr calls so I'm not going to go into contortions to
reduce the offset down to 8 bits - although that should be fairly easy as well.

03 Dec '22
----------
Getting output to the console working under simh was not too much of a hassle
since I was continuing to follow the really helpful notes at
https://ancientbits.blogspot.com/2012/07/programming-barebones-pdp11.html

I did simplify the code, a lot, though, based on the sample code from the
"PDP11 Peripherals and Interfacing Handbook", an online copy of which is
available from:
http://www.bitsavers.org/pdf/dec/pdp11/handbooks/PDP11_PeripheralsHbk_1972.pdf

Although I initially used the console device for output, one difficulty I ran
into with using it was with trying to redirect that output to a named file. In
the end, I decided that the struggle was not worth it and just decided to use
a different device (the line printer, LPT/LP11) since simh allows it to be
directly attach'ed to a named file.

Next, I just need to do the same thing for console input as well. Let's see
how long figuring that one out takes.

05 Dec '22
----------
Sometimes it is the simplest things that take the longest to get done. It turns
out the premonition I had about redirecting the input from a file as mentioned
in my previous journal entry turned out to be fairly spot on.

My first attempt at implementing "key" was to use the console device and it
worked without much debugging - using the sample code from Digital in the
"PDP11 Peripherals and Interfacing Handbook" available from:
http://www.bitsavers.org/pdf/dec/pdp11/handbooks/PDP11_PeripheralsHbk_1972.pdf
came in pretty handy again.

Since I want to be able to automate the testing though, the next attempt was
to redirect the input from a file. I initially tried to use the same approach
that succeeded for me with "emit" (where I used the LPT device instead of the
DL11 console output). I thought I could attach the "Paper Tape Reader"/PC11/ptr
device to the input file and change the addresses from 017756X to 017755X and
call it a day. But for some unknown reason I haven't been able to get that
working so far. Running ex'amine on the device shows that the data exists as
expected but the code kept looping as if the data wasn't available. Rather than
spend even more time on trying to fix whatever was broken, I decided to read
through the simh docs to see if there was another device I could test instead
but happened to see the "send" command that allows you to inject data into the
console input. So for now, I've decided to use that feature as a workaround.

Given the time I've spent trying to get this working on simh, I now wonder if
it wouldn't have been faster to just write yet another emulator for the pdp11
just like I did for the x86. Perhaps, if I get stuck again, that's just what
I'll do.

06 Dec '22
----------
For implementing the data stack on the PDP11, there is a literal profusion of
choices since any of the PDP11 registers can be used as the data stack pointer
(given the PDP11's flexible addressing modes).

Since I want to see if the native/machine stack can be used for the return
stack, I'll choose the next available register (r2), rather than r6 as the
data stack pointer. The current register mapping is: R0: IP, R1: TOS, R2: SP

The remaining decision is about where to place the data stack. I'll make the
same choice that I made on the x86 port, which is to have it grow to low memory
starting from the beginning of the text area. So the current memory layout
looks like this:

			0x100 -> higher memory
	  ------------------------------
	   <- data stack | code/text ->
	  ------------------------------

07 Dec '22
----------
During the x86 port, I chose to use the macro features of the x86 assembler
to do all of the macro expansions that were needed when a Forth word used a
"lower" level forth word. For the PDP11 port though, I want to try something
different and have most of those expansions done by genrom instead. This seems
to be a cleaner approach than the ugliness of the x86 version where I have
to disambiguate between the macro expansion and a regular call by using '_' to
prefix the words that needed to be expanded.

So this required a little bit of addition to genrom's capabilities.

In the x86 port, I was using 8 bit offsets so all of the addresses were stored
as offsets from the base of the text area. Since I'm using the full 16 bits
for the PDP11 port, I can store the addresses as is.

08 Dec '22
----------
While working my way through "step 5" to implement conditionals on the PDP11
I decided that the scope of this step is too large and needs to be broken up
into smaller steps which are finer grained and more easily tested.

I also found that using "jmp" as a label seems to cause a hiccup for the
PDP11 assembler so it needs to be renamed to something other than "jmp".
I'll pick "j" as the replacement name, for now.

So, my solution to address these issues is to separate out the support for
implementing the primitives "j/jz/jnz" into 3 sub-steps which I'm calling
steps 4.1, 4.2 and 4.3 and then follow that up with the implementation for
"if{ ... }else{ ... }if" in genrom (which remains the same as before) as
part of the original "step 5".

I chose to use the floating point notation for the newer steps since it
allows me to not have to redo the numbering for all of the the other later
steps, thus keeping those step numbers the same, just in case they are
referred elsewhere.

Since it is quite useful to be able to test each of the basic "j/jz/jnz"
primitives independently of the language support (which is only added later
in "step 5"), some standalone/newer tests for these steps have been added
to rom.4th as well. This change then snowballed into requiring changes to
test.inp and test.expected as well. So while I was there I decided to clean
up the conditions used for the earlier tests from "step>N-1" to "step>=N"
which makes it easier to match up each test with the corresponding "step"
during coding and testing.

Since more granular steps are being added, I decided it is safer to test
it all out on the x86 ports first before trying it out on the PDP11 port.

One addition that I've made to the genrom feature set is the ability to
use "immediate offsets" which are different from the "immediate literals".
The "literals" are the usual Forth literals prefixed with the lit operator
and can be denoted as bare numbers/variables or prefixed with the $ notation.

The "offsets" are new and are used for encoding JUMP offsets which don't
need to be prefixed with 'lit' - they are denoted using a '#' prefix.

09 Dec '22
----------
Today was a fairly productive day as I cranked away at most of the easy
parts of the port. The next set of primitives are the hard ones since they
usually require you to pay attention to a lot of detail. I did start off
thinking about how to implement exec/enter/exit/call and have some ideas
about tying it to the PDP11 JSR instruction but that needs me to use the R6
register instead of the R4 register which is used currently.

I'm tired now though and I think all of that can wait for another day.

12 Dec '22
----------
I have a decent implementation of exec/enter/exit/call now, I think.

Trying to think of the issues that slowed me down, one obvious thing in
hindsight is the GNU assembler's violation of the law of least surprise.

My expectation was that "jmp r" where r is a register containing the
address to jump to should "just work". I found the hard way that the PDP11
GNU assembler expects this to be "jmp (r)" but since there was no error
either way, I had to spend some time looking at various docs to figure out
what was going on. Once past exec, enter/exit was the next gauntlet. I had
an idea of using JSR to do the call/return linkage and that panned out well
because all of the complex link chaining is automatically handled by the CPU.

Here also, the elegance of the PDP11 in the flexibility of JSR linkage shines
through. Looking at the history of PDP11 and Forth on wikipedia, it looks
like both are of about the same vintage (late 60's) and they seem to be a
perfect fit for each other.

15 Dec '22
----------
I found and fixed a stupid bug that managed to crawl into the code. It was
subtle, asymptomatic, and serious enough to cause memory corruptions and
it turned out to be an unnecessarily long and drawn out debug exercise.

The symptom was that although the simulation ended successfully and the test
passed, I noticed that the address at which the simulation ended was not at
the expected address. On the PDP11, halt's opcode is 0 so if the code goes
off into the weeds and accesses an uninitialized address with content 0, it
will halt right there instead of where it was expected to halt. Since "call"
is a tricky beast to implement, I was being fairly cautious and luckily was
able to catch the problem (although it was asymptomatic since the test itself
succeeds)

After a boatload of debugging using simh and struggling with the stupid
oct (used by simh) <-> hex (used by gas) conversions, I finally figured
out it was due to memory corruption of the instructions in the code area.

The cause of the memory corruption was because the return stack which grows
to low memory was initialized to the end of the code area for primitives
instead of the very tail end of the "rom" and this happened because the
"mem" label was not really at the tail end of code (including rom) but in
the middle of it (since it was defined in code.prims).

So although the debugging/understanding of what was going on took a while,
the fix was trivial: just place "mem" at the very end so it just needed
to be moved from code.prims to forth.S

---

After that bug was fixed, I ran into yet another bug with the same symptoms
- this one turned out to be bug in "call" itself since I was unnecessarily
incrementing the instruction pointer (since I used the x86 code as a template)

With both bugs fixed, the tests pass and emulator reports the halt happening
at the expected/right address, currently at PC: 000420

---

While doing an initial/quick browse of the PDP11 instruction set, I'd seen the
ASL/ASR instructions for shifting bits. Since these could only do 1-bit shifts,
I decided to defer the implementation of the shift operators << and >> until
they were really needed (and loop operations could be fleshed out). That time
has now arrived and my choices are to either implement this in Forth using
loops or do a native implementation (using loops in the assembler)

Since using a Forth loop would have less performance than native loops, I
decided to use assembly code and the initial implementation looked like this:
	<<     : nip ; 1: ; asl nos ; sob tos, 1b ; t_n ;
	>>     : nip ; 1: ; asr nos ; sob tos, 1b ; t_n ;
But reading through the PDP11 docs again, I noticed yet another opcode: ASH
which can be do multiple bit shifts. So the final implementation uses that.

Which means I could have saved all of the effort that went into the commit
titled "Move the shift operators to a later step". In any case, I assume
there will be microcontrollers that can only do 1-bit shifts so I hope all
this work was not a complete waste of effort and might come in handy later.

16 Dec '22
----------
As of the last commit from yesterday, the PDP11 Forth runtime can be considered
complete so I've included the PDP11 under the "allsteps" regression step in
the toplevel makefile.

---

Comparing sizes with the x86 port, without the tests compiled in, the PDP11
binary weighs in at 422 bytes (including initialization) where x86 needs 338
bytes. The additional overhead is partly because of using 2 byte offsets and
also the fact that x86 byte opcodes can be a tiny bit more compact than the
PDP11 opcodes which need atleast 2 bytes.

The PDP11 binary with all of the tests and initialization code clocks in at
1828 bytes compared to 1236 bytes for the x86 binary. Most of this difference
boils down to the fact that I chose to uniformly use 2 bytes for all Forth
words instead of the hybrid scheme on x86 which uses 1 byte for primitives and
3 byte calls for defined words.

---

The part I like best about this port is that code.prims has been whittled
down to just 60 lines of code. So if we use Fred Brooks' productivity metric
of ~10 lines of debugged code per day, for a "regular" programmer, I'll
guesstimate that a new Forth port can be completed in about a week (or two),
assuming a decent architecture like the PDP11.

---

So, where to next? I think I have a couple of choices:
1. Shrink wrap the x86 and x86-as code.prims just as I did for the PDP11
	- $TECHDEBT, nah!
2. Start off on a new port to one of the architectures listed in PORTING
	- Just completed one, nah!
3. Use the runtime I already have to create a Forth REPL for the PDP11 (or x86)

I think I like option 3 best so that's what I'll be spending some time on next.

18 Dec '22
----------
I've decided to go ahead with the REPL implementation to see how well it fares.

The "real" Forth REPL needs to read in "tokens" (which are defined as any
sequence of non-whitespace characters) and look them up in a "dictionary" and
either run the code (if it is found in the dictionary) or attempt to turn it
into a "literal" number (if it is composed of numeric characters).
If it doesn't match either of those categories the REPL could report an error.

As usual, I'll start off with small changes that I can test easily. So to begin
with, the only thing that the REPL does is read a "token" from the input. This
functionality is called "parse" in some of the Forth implementations that I
looked at so I'll stick to that convention.

Most implementations also use an input buffer to hold the bytes but since it
can be done in a single pass, I'll use the unallocated area for that purpose so
that the memory layout doesn't have to be fragmented into even more segments.
So this breaks with the usual Forth convention of needing words such as TIB
#TIB >IN etc but I prefer the simplicity of what I've done and hope that it
doesn't turn out to be too simplistic.

Looking ahead and planning for ports to other processors, it makes sense to
continue with the "step"wise addition of functionality that I've been using so
far. So the changes that I've made so far have been ifdef'ed under step 39.

To sanity test the implementation, the length of the token that was read is
verified and in addition, it checks the returned location where the string is
stored and also verifies the start and end bytes of the token that was read.

Testing these changes showed that it worked on x86 but failed in a weird way on
the PDP11 simh emulator despite the fact that the changes tested were identical
in both cases. Before lugging out the big guns for debugging the PDP11 issue, I
had a gut feel that the return stack was overflowing and based on that hunch I
bumped up the return stack size and luckily enough that fixed the problem.

Rationalizing about this later, it is obvious that the x86 version was not
affected since the return stack grows to higher addresses (which is currently
unused) whereas on the PDP11 the return stack grows to lower addresses (ie
toward the code area) and any stack overflow will result in overwriting and
corrupting the code area resulting in the weird errors that were observed.

Looking at the emulator output (for the x86) does show that the return stack
size had reached its configured limit. So, for the "real" fix, I've doubled
the configured stack size for the return stack on both the x86 and the PDP11.

It was just dumb luck that the problem was diagnosed fairly easily and I'm
glad this turned out to be an easy fix rather than yet another long drawn out
nightmare debug/redesign exercise.

19 Dec '22
----------
Continuing with the exercise of incrementally adding functionality to the REPL,
at this step (step==40), I've added support for turning a numeric string (read
by "parse" from the input stream) into the equivalent integer when the "state"
variable is non-zero (ie in "interpret"ing state). I've named the word that
does this "atoi" after the C library function that does the same thing.

20 Dec '22
----------
I'm starting to work on adding a dictionary and that brings up a philosophical
question: How much Forth do you really need?

Adding the dictionary manipulation routines (which in conventional Forth are
typically named "create" and "find") requires that the existing "primitive"
words and "defined" words will now need additional space to store their
"metadata" with the dictionary name and header in addition to the "data" (with
just the executable code). This additional requirement for ROM/RAM may exceed
the hardware capabilities that a really "small" microcontroller may have.

The most "minimal Forth" might be one which has just the data stack in RAM
and a bunch of primitives saved in ROM with all of the heavy lifting done
via "metacompilation" performed on the "umblical host". This can easily run
on boards with just a few bytes of RAM and very little ROM (say, less than
about 256 bytes of ROM, if we use something like the single byte offset
scheme that I used in the original x86 implementation).

The next step up might be to add a return stack which increases the RAM
requirements by a bit. Assuming N levels of nesting with 16-bit return
addresses requires N*2 bytes of additional RAM. For example, 4 levels of
call nesting and 4 data stack elements can easily fit within 16 bytes of RAM.

With a larger ROM, it may be possible to have a "static dictionary" stored on
the target (rather than on the host). This allows us to have something close to
a regular interactive Forth except the ability to add new definitions and we
are getting closer to the eventual goal of getting rid of the "metacompilation"
step. I assume that a 512 to 1KB ROM might be sufficient for such a standalone
Forth implementation which can support "find" but not "create" since supporting
"dynamic" dictionary additions enforces the requirement for a larger RAM.

Finally, with an even larger RAM, say 512 bytes or more, it will be possible
to have an "extensible dictionary" which can be used to define new words
residing on the target (with, say, 64 bytes reserved for data+return stack)
and have a completely standalone Forth target which can dispense with the
"umblical hosted metacompilation".

Thus we can see that there are effectively 4 "levels" of Forth needed.
For lack of better names, I'll refer to these "levels" as:
1/4 : "oneforth" (pun intended), which has only primitives and a data stack
      ROM : ~256 bytes, RAM : in the single digit byte range?
2/4 : "twoforth" which has definitions and a return stack (in addition to
      the primitives and data stack that "oneforth" has)
      ROM : ~256 bytes, RAM : 16 bytes (or thereabouts in two digit byte range)
3/4 : "threeforth" which has a static dictionary (in addition to the primitives
      and definitions and the two stacks that "twoforth" has)
      ROM : ~512 bytes, RAM : 16 bytes (or thereabouts in two digit byte range)
4/4 : a full fledged "fourforth"/full/regular Forth with a dynamic dictionary
      in addition to the rest of the bells and whistles from "threeforth".
      ROM : ~1024 bytes, RAM : 512 bytes or more - to hold the dictionary

So the answer to my earlier question: How much Forth do you really need?
is "it depends" so my response is to provide 4 options in the makefile
(as named above) and let the user who is stuck with a specific choice of
microprocessor decide how much Forth they really need.

Since microcontrollers come in various sizes, I'll also need to think of a
"shrink to fit" capability rather than the current incremental "step" wise
implementation such that only the closure of the set of all words required
from rom.4th gets pulled into the final ROM image.

22 Dec '22
----------
This entry is just a documentation of the debug exercise I went through, to fix
a bug, that cropped up while adding dictionary headers to all the "words".

I'm documenting it here simply as a reminder from "current me" to "future me"
in case other issues like this pop up on other architectures, as part of any
future porting exercises, by which time I expect I'll probably have forgotten
many of the more intricate parts of the plumbing. My hope is that this
documentation will help with making those debug exercises faster/smoother or at
least more productive.

Ok, so lets start with the problem. I'd made some code changes, primarily to
the script (genprims) that turns code.prims to assembly to generate dictionary
headers for each of those primitives. Testing it was resulting in a failure
only when the dictionary headers are generated, whereas things work as expected
when the headers are not generated. With the dictionary headers in place, I was
getting the following error from the pdp11/simh emulator:
	Trap stack push abort, PC: 000416 (HALT)
Using bc, we can map this octal address to the hex value:
	obase=16
	ibase=8
	000416
	10E
And subtracting 100 from 10E give address 0xE which can be looked up in the
assembly listing file which maps to:
			bye:
	000e	0000		halt
So it appears that it halted as expected, but why does it report that strange
"Trap stack push abort" error message?

Since the "stepfile" approach gives me a means of testing this at small code
change increments, I decided to give that a shot to find the earliest change
that triggers this bug. Running "make allsteps" and waiting for a while until
it fails and then running "head -1 fpp.config" gives me:
	step=22
which shows that the earliest failure is triggered at step 22. I decided to
confirm that things were really working at the previous step by setting the
step value to 21 and rerunning make :
	cd pdp11 ; sed -i 's/step=22/step=21/' fpp.config ; make
This to my surprise showed that that the test actually had failed even at
the earlier step 21 with this error:
	Trap stack push abort, PC: 000612 (JMP @(R0)+)
Unfortunately, this is not reported as a non-zero exit by pdp11/simh so despite
the error, make saw it as success and moved on to the next step.

I could change the makefile to handle anything other than "HALT instruction"
as an error and rerun the whole regression test with "make allsteps" to see if
I can catch this error much earlier. So I went ahead and did that and after the
usual long wait for the regression failure, and using "head -1 fpp.config",
just as before, it turns out the earliest failure actually happens at step 14
and the error is the same as the one that happened at step 21:
	Trap stack push abort, PC: 000612 (JMP @(R0)+)
Again using bc to do the oct->hex conversion:
	obase=16
	ibase=8
	000612
	18A
Subtracting 100 from 18A gives us offset 8A, which maps to the fetch/@
operator (by looking up address 8A in the forth assembly listing):
	96                    lbl007:
	97 0088 4112           mov (r1), r1
	98 008a 5800           jmp @(r0)+
So for context, what is happening is that at step 14, we have added the "here"
variable and we are fetch'ing its value and that for some strange reason fails
when we add the dictionary header (but works fine when there is no header).

Since I'm aware of alignment issues (from the time I worked on SPARC at Sun
Microsystems) the problem is obvious: the addition of the header made the
location of the "here" variable unaligned, so all that is needed to fix this
issue is to add a alignment directive (".align" in the case of binutils) ahead
of variable declarations.

If I was a newbie who was not aware of processor alignment issues, I guess the
next step might have been to trawl through the code in SIMH to figure out
exactly why it reports that error, but in this particular case, that additional
step was not required due to my earlier experience with these types of issues.

If I was a newbie working directly on the hardware and ran into something like
this, I assume it would result in either grey hair or maybe no hair ;)
The hard lesson here might be : always use an emulator - but that can come with
its own share of latent bugs especially if the emulation does not perfectly
match the hardware.

After fixing this alignment issue with variables in the genprims script, I then
decided to run yet another round of "make allsteps" in the hope that I was past
the entire class of such problems but it again ran into the earlier failure at
step 22 (which was the first problem that I had documented above, prior to the
step 14 failure).

Since alignment issues were top of mind for me, and it is at step 22 that the
generated definition for "bl" is used for the first time, it was fairly clear
to me that this issue was also due to not having an alignment directive for the
generated code produced by the genrom script. So that script was also modified
to generate the ".align" directive ahead of definitions as well.

In hindsight, it is clear that like most debugging exercises, cracking it was
a mix of grunt work and dumb luck. The "lucky part" was in observing that step
22 was not the very first failure and tracking the very first failure all the
way back to step 14 where it was easy to figure out the alignment problem. Once
that was out of the way, seeing the new issue again at step 22, and putting 2
and 2 together was a no-brainer. I assume things would have been harder if
these were encountered the other way around (ie in the opposite order).

Anyway, running the "make allsteps" regression step again after making these
two changes resulted in all of the tests passing without any further breakage.
I hope documenting all of this in gory detail now turns out to be useful later.

For now, the addition of the dictionary headers has been done only for the
PDP11 port - which I'll use as the "primary" port going forward. Adding the
dictionary headers to the x86 code is the next step. Since x86 supports
unaligned access, this bug will not be encountered there so I hope that the
addition of the headers to the x86 port goes more smoothly than this.

23 Dec '22
----------
Now that the dictionary support for x86 GNU "as" is done, it is time to look
at repeating it for the x86 nasm port as well. Since the initial bootstrap
implementation was done on x86 nasm, it has a makefile which is different from
that of the other ports. So as part of this exercise, I decided to "demote" it
a bit so it is no longer considered the "primary" port and it is now just "yet
another" port. This change also ensures that all of the makefiles now follow
the same template but getting there needed some major surgery to the x86 and
the x86-as makefiles since the x86-as makefile had some implicit dependencies
on the x86 build. But all of this is technical debt and in preparation for the
new year, I might as well pay it down now rather than later.

So now that the dictionary headers are available for all the current ports, I
plan to take a small break from all this for a week (or two) and just relax
over the holidays so here's to hoping for a refreshed, relaxed and wonderful
New Year.

06 Jan '23
----------
As I was getting ready to add the functionality to "exec" words from the repl,
and thinking about how to code something like "lfa2cfa", I realized that the
align directive used in PDP11 has now turned into a stumbling block since the
runtime does not have any meta data from the build to figure out if a padding
alignment byte was added or not. So the only choice apparent to me is to rework
the dictionary header layout by shuffling the fields around so that the padding
is kept out of the way.

The new header format (which, btw, completely breaks with the traditional Forth
header layout) can be described using the simple ascii diagram layout shown
below where the ^ symbol marks alignment boundaries:
	... | align | pad | nfa:(name ... | count) | lfa | cfa ... |
                    ^                              ^     ^
The layout could also be described more formally using this C'ish pseudo code:

	struct name {
		optional byte alignment[...];
		optional byte pad[...];
		byte name[count];
		byte count;
	};
	struct dict {
		struct name nfa;
		struct dict *lfa;
		byte cfa[...];
	};

The alignment bytes are used only if the previous dictionary entry ended on an
unaligned byte boundary. The pad bytes are used so that the name field always
ends at an aligned byte boundary.

Using this new scheme, it is clear that to get to the nfa from the lfa, we
just subtract the count (and unlike the earlier scheme, the padding and/or
alignment bytes are not in the way). Going from the lfa to the cfa is also
trivial (just add "cell"). The reverse mapping from the cfa to lfa also becomes
trivial (just subtract "cell"). This would have been much harder to do with the
traditional Forth header layout, so, all in all, I think this scheme is a much
better layout than the conventional Forth dictionary header layout.

Since making this change will regress the tests at steps 41, 42 and 43, I've
decided to rollback the step value to 40 and just make the dictionary header
changes after only a manual/visual inspection. I'll add the modified tests back
in at each step progression rather than turn this into one humongous commit.

07 Jan '23
----------
Adding support for exec'ing words from the repl exposed a bug that many of the
words did not have dictionary headers (but only on x86). It turns out that the
generation of the dictionary headers was not being done correctly for many of
the x86 specific code.prims directives. I'll attribute this to the existing
$TECHDEBT that genprims (and genrom) in each of the ports are copy-pasted. At
some point I should consolidate all of them and in addition have a unified
format for code.prims as well. For now though, I've just fixed the bugs in
genprims (in both x86 and x86-as).

08 Jan '23
----------
With the support for exec'ing defined words from the repl, "threeforth" is
in some sense complete since we can now interactively "exec" all the variables,
primitive definitions and Forth definitions which are available as part of the
dictionary. Since two different types of "thread"ing are used in the x86 and
PDP11 ports, I've added a config variable called "THREAD" to distinguish among
them. The x86 version which uses an opcode to prepend the cfa is called thread
type 1 and the PDP11 version which uses a bare cfa is called type 2.

The previous commit added the requirement that the "latest" variable needs to
be the last variable defined in code.prims since it is used as the boundary
between variables and primitives. This commit now adds another such requirement
that the definition of "bl" needs to be the very first Forth definition since
it is used as the boundary between primitive definitions and Forth definitions.

With this commit, all of the words that are already in the dictionary can be
run directly from the repl. As I've previously discussed in the entry dated
20 Dec '22, additional functionality to extend the dictionary is possible by
adding more Forth definitions. Even on relatively low-end microcontrollers, the
ROM tends to be fairly beefy, so this implementation proves that having an
easily portable and interactive version of Forth that can run even on the
lowest end microcontrollers is quite possible.

Currently the PDP11 ROM usage, (without all of the regression tests included),
clocks in at 1550 bytes and the x86 usage weighs in at 1217 bytes. With all
of the regression tests included, the PDP11 needs 3066 bytes and the x86 usage
is 2212 bytes. The "gensize" perl script which is part of this commit was used
to generate these numbers. I've also added this to the makefile so "make size"
should generate these results as well.

The runtime RAM usage can be estimated by running the the x86 emulation. RAM
usage, with all the tests enabled, shows that just a paltry 24 bytes for the
data stack and 12 bytes for the return stack are sufficient. Without the tests,
the usage remains at 4 bytes for data stack and 0 bytes for the return stack.
In addition, the static variables use 6 bytes.

So I'll go ahead and stake a claim that the "threeforth" version of Forth which
can be called interactive, (for some definition of exactly what "interactivity"
means in this context), can easily run even on microcontrollers that have less
than 32 bytes of RAM (if the current set of tests are disabled).

What threeforth cannot do is create new dictionary entries at runtime, which
one may claim is the essence of Forth. So now that threeforth is done, I can
now start on a final/fuller version of Forth (which I had called "fourforth" in
the entry dated 20 Dec '22) which can create dictionary entries and link them
to the older entries in ROM and exec them at run time for "full" interactivity.

10 Jan '23
----------
While working on this set of code changes, I realized my lack of foresight in
not providing something like "#}else{" and "#}elsif{" directives in the "fpp"
script. For now, I have to be very careful with the repeated use of "#{if" and
"#}if" pairs to make sure that these directives don't result in overlaps and
also cover all the cases. Perhaps I should follow Rust's example and enforce
complete coverage for all sum types, while I'm at it ;)

So far, for the Forth comments, I've been following a "structured commenting"
style where '[' stands for the "rest of the data stack" and ']' stands for the
"rest of the return stack" with '|' marking the boundary between them. Input
was denoted using '<' and output using '>' while memory addresses and values
were documented using "(addr:value)" with "//" used for additional clarifying
comments. Now that the dictionary can be modified at runtime, I'll extend that
notation a bit to use '\' to denote the contents of the dictionary.

The commit of the allocation (alloc, alloca) routines which was done yesterday,
marked the start of the implementation of "fourforth". Today I'm getting into
the meat of the implementation with the definition of "create" which "parse"s a
"token" from the input stream and adds it as a dictionary entry. Once this out
of the way, I can start working on the repl to add state handling and provide
a facility to deal with "immediate" words.

11 Jan '23
----------
In Forth, the "state" variable is used to track the transition from "interpret"
state (usually denoted by 0) where all words are exec'uted within the repl to
the "compile" state (usually denoted by 1) where all words are appended to the
latest word that was create'd. The conventional Forth word that does the switch
from 0 to 1 is '[' and the complementary word to switch the other way is ']'.
The state diagram that compactly expresses this is:
	state	event	nextstate
	0	[	1
	1	]	0
Since I've appropriated '[' for commenting purposes, I'm going to rename them
run[ and ]run which calls out the fact that the bracketed code is run even at
compile time. These words are internally used by the Forth "define"ing word ':'
and its complementary pair ';' which is the "immediate" word used to mark the
end of the definition started by ':' which means the above state diagram needs
to be extended a bit as shown below:
	state	event	nextstate
	0	:	1
	0	run[	1
	1	]run	0
	1	;	0

Once "compilation" starts and we assemble a sequence of existing Forth words
into a sequence of cfa's to be exec'uted, we need a means of switching from
"compile" state back to "interpret" state. Rather than hardcode some kind of
a reserved word to do this, "immediate" words count as Chuck Moore's brilliant
solution to do this in Forth. "immediate" words will be exec'uted by the repl
even in "compile" state and this provides a generic escape mechanism to allow
all types of intermediate processing to happen while "compile"ation is still
in progress.

Enabling the addition of "immediate" words to the dictionary now allows me to
code up a full fledged Forth REPL. While "create" enables adding new dictionary
entries, "immediate" allows us to create words that can switch the state. So,
as the next step forward, I'll work on a repl that can take advantage of the
"immediate"ness of words that have been added to the dictionary.

12 Jan '23
----------
This is the first year in which I cannot call either of my parents on their
anniversary. After Dad died in 2020, Mom soldiered on for two years and this
year I'll miss both of them.

Happy 56'th Anniversary Apai and Mom! All of us miss you. :heart:

13 Jan '23
----------
The bulk of the work involved in testing out the code for the all important
Forth words ':' and ';' (which are used to define new words in Forth) was done
as part of the tests in the previous commit at step 50. So in this commit, I've
consolidated those changes into actual definitions. Rather than code up a repl
to use these definitions, I've decided to make the tests at this step call ':'
and ';' explicitly since I'm still thinking through how to make ';' immediate.
---
On a personal note, as of today, it is 3 years since Dad passed away from
cancer (multiple myeloma) at the age of 79. Miss you Apai. :RIP:

14 Jan '23
----------
Since empty definitions were proven to work yesterday, the next step I could
think of was to add support for compiling numbers into the body of definitions.
After making those changes, testing showed some weird behaviour. It worked with
no issues on x86 but consistently got into a hang state on PDP11. I spent some
time going over the code with a fine tooth comb especially the #ifdef'ed parts
and adding some debug prints for troubleshooting to make sure I had not messed
up something related to the PDP11 specific parts since the code is now starting
to be rife with ugly #ifdef's sprinkled helter skelter. Despite all that work,
I didn't make much headway with those debug efforts, until I remembered that I
had observed this kind of failure once before (see the JOURNAL entry dated 18
Dec '22). Based on that I suspected yet another return stack overflow. The x86
emulator reported that the return stack usage was 18 bytes (of the configured
20). This was close enough to the limit that I decided to bump it up to see if
the problem went away and sure enough after increasing it to 30 bytes (on both
architectures), PDP11 also started working without any hitches. Whew!

16 Jan '23
----------
Now that I'm getting to the part where the repl starts to get a bit more
complicated with the addition of immediate words and compilation of defined
words, it was predictable enough that I'd run into weird bugs. But these bugs
were nasty and seemed to literally crawl out of the woodwork. They slowed me
down quite a bit so I think it is worth documenting them here. I'll list them
in the order that I found them:
1. state was not initialized to 0 (it was initialized to 1 for the c@/c! tests)
2. cpl_ex used @ instead of c@ to access the state variable
3. cpl_ex and cpl_ex_imm expected an lfa but were passed a cfa

Bug #1 was a "wrong initialization bug" where the repl code expected to start
with interpreter state==0 but because of the tests (written long long ago,
which predictably enough, I'd forgotten all about), it had been initialized to
1. The fix was to initialize the state variable prior to calling the repl.
So that was a relatively easy bug to fix.

Bug #2 and #3 fall under the category of type bugs. Since Forth does not have
any notion of static typing (or any means of enforcing it), such bugs can
easily sneak in and strike at runtime. Bug #2 was almost a C-like type cast
bug caused by using a byte as an int.

Bug #3 was subtler since an address on the stack just looks like any other
address. The initial coding was done with cpl_ex and cpl_ex_imm expecting an
lfa on the stack. But somewhere along the line, while refactoring stuff, I
changed the repl to send a cfa and forgot to update the called routines. I
think the lack of static typing may rule out using Forth for large projects
unless rigorous attention is paid to handling interface changes such as this.

Or perhaps it's just me being tired and careless.

Anyway, with all of these bugs out of the way, things are finally working. Yay!

---

After all the struggles I went through to get compile time definitions working,
adding variables and primitives turned out to be a walk in the park. So at
step 54, I think I can call the repl functionally complete and fourforth is
done. The rest as they say is just a "small matter of programming".

Looking at the stats generated by the gensize script, x86 needs 3021
bytes total and 1774 bytes without tests while PDP11 needs 4146 total and
without tests it fits in 2280 bytes.

So here's to freedom from the slavery of code bloat (on MLK Day)!

For comparison, here's what C needs:
	echo 'main(){}' > x.c ; make x ; wc -c x #  8544 x
which shows that the generated binary needs 8544 bytes - to do nothing!
And for another example with Rust:
	echo 'fn main(){}' > x.rst ; rustc x.rst ; wc -c x # 3321352 x
which shows the Rust binary needs ~3.3 MB to do nothing although stripping
the binary does bring it down to "only" 297232 bytes. Granted this is using
rustc 1.50.0. Finally, while I'm pointing fingers, let's not leave out Go:
 echo -e 'package main\nfunc main(){}' > x.go;go build x.go;wc -c x # 1101232 x
which shows Go needs no less than ~1.1MB to do nothing and even the stripped
binary needs 737896 bytes. Like the Rust version the Go version I have is also
behind the times (go version go1.6.2), but I don't really believe any newer
versions are going to improve anything. So the "bloat prize", by a wide margin,
should go to Go.

That's enough of a rant (and probably an unfair one at that - I assume all
three languages have good reason to have large binaries). For Go, I assume it
is their runtime and for Rust I think it is probably the standard library. C's
bloat might also be due to the standard library. In any case, on machines with
gigabytes of RAM, none of this bloat really matters.

So I'll continue to chip away at the problem that I'm trying to address for a
really niche and extremely narrow problem space of microcontrollers which are
resource constrained in terms of ROM and RAM (and quite likely, power usage).
So, changing gears to look at next steps, I could start a new port to yet
another such microcontroller architecture. Since the two ports that have been
completed so far have been little-endian, I'm tempted to try a big-endian
architecture for a change to see if that turns up any new portability issues.

SPARC, maybe?

17 Jan '23
----------
Before moving on to doing yet another port to some other processor, I decided
to finish fleshing out the repl a bit more to add support for the conditional
and loop control structures. But before adding even that, the very first thing
I really need is a means of writing comments. The typical implementation of
comments in Forth is trivial - something along the lines of "10 parse 2drop" to
read everything upto the end of the current line and ignore what was read. Oh,
and of course it must be marked "immediate" since it can be used within
definitions. The fact that comments can be added to the language after the fact
without any change to the "original language" is one of the more jaw dropping
features that folks new to Forth often encounter since you run into it sooner
than the fact that loops and conditional structures can also be bolted on to
the "language", in almost the same way, almost as an afterthought.

But before I can go ahead with adding support for comments, I need a more
flexible means of switching between the test code in rom and the repl.
Currently I'm counting words to handle this switch. A more flexible approach is
to use the old "2ret+call" technique to implement a simple semi-coroutine like
mechanism. So that will be the very first thing I'll work on before attempting
to code the rest of the stuff.

---

After trying out a couple of alternatives, rather than use semi-coroutines, I
ended up with a simpler approach which is to just do a multi-level return from
a "longjmp" like word which I've provisionally called "3ret" (since it drops
off the top 3 levels of the return stack, on x86). Calling 3ret from within the
"outer" repl will return control back to the test. During testing, I found that
the PDP11 needed an extra layer of return stack unwinding but I'll leave the
name as is for now since I can't think of something more meaningful currently.

18 Jan '23
----------
Now that I have a reliable means of switching from the repl back to test mode,
I went ahead with adding the code to handle comments (which as I mentioned in
the previous JOURNAL entry, is fairly trivial). Initially I debated with myself
whether adding new definitions should continue to be done in defs.4th or should
be part of the "console input" via rest.inp. For now I've reluctantly decided
to add the definitions to rest.inp (mixed in with the tests) rather than adding
just the definitions to defs.4th since the outer interpreter is the place which
can process "immediate" requests. A different way to solve this might be to
define "immediate:" which take a parameter (just like create) but that also
requires entangling the code with the input stream. Another idea is to
introduce yet another defining word pair (say imm{ ... }imm, just like the
def{ ... }def pair) to declare words which are immediate. Of these choices,
sticking newer definitions into rest.inp seemed easiest. So that's what I've
ended up doing for now.

One side effect of this choice is that the entirety of the code needed for a
"full Forth" implementation is now spread over three different files:
code.prims, defs.4th and now, rest.inp as well instead of being centralized
or available in one "object" such as the assembly listing file (forth_dict.lst)
This also means that an accurate means of getting the ROM/RAM requirements
becomes harder.

I'll assume that the amount of additional new code that will be needed is not
a lot. So I'll forge ahead and revisit this decision if it turns out to be a
major problem down the line. I also have in mind the idea of a "shrink to fit"
tool which can be used at runtime to generate the closure of all dependencies
of any given word. So that might be another alternative way of getting a single
snapshot of all of the required code.

---

One issue that showed up during testing is that comments need the newline
characters to be passed through. The existing code goes out of its way to get
rid of them (for legacy reasons). So I've added some special casing in the
makefiles for rest.inp, to preserve the newlines. I have a special generator
("genrestinp" on PDP11) which sticks the newlines back in (via the simh/"send"
command) and on x86, rest.inp is special cased so that the newlines are not
egregiously removed.

23 Jan '23
----------
This entry is just an attempt at documentating yet another bug that I ran into.
Hopefully the steps I took here will be useful in the future when strange bugs
such as this pop up.

The bug itself was fairly old and was introduced over a month back (on Dec 15)
but I ran into it only now, while it lay in wait biding its time to pounce and
lay waste my time.

This one was also seen only on the PDP11 port and showed up only when I added
support for the looping constructs at step 59 although I think it should have
popped up at step 58 as well.

Anyway, to begin at the beginning, the symptom of the problem I was running
into was that the PDP11 test would fail at the assert added in step 59 while
the x86 test passed without an error running the identical code changes.

Rather than use simh for debugging, I decided to go with "print debugging" and
so I added an implementation of '.' to defs.4th which prints out the value at
the top of the stack. I added a "dup ."  after the call to "outer" at step 59
in rom.4th to see why the assert was being hit and to see what that incorrect
value was. Unfortunately adding this "print" resulted in a hang while running
make within the pdp11 directory. (Note: when you run into a hang in simh, you
need to use Ctrl-e to break out of the hang, not Ctrl-c).

So now that things are going sideways rapidly, the next "print based debug" was
to add a "dup ." within cpl_ex to get a bigger picture of what was going on.

Running make in the pdp11 directory again after adding the newer print also
resulted in a hang. Getting out of the hang with Ctrl-e worked but doing so
made "make" remove the test.dict output file. So I needed to run whatever make
was running by hand. Since make only needs to run: "pdp11 simh_dict.cmds", I
just ran it manually then waited for it to hang and pressed Ctrl-e to get an
output file. The output in test.dict showed that a bunch of cfa's were
processed in the outer interpreter but to get more context I added another
debug print this time by adding "dup emit" at the start of "append".

The next round of testing was: make + Ctrl-e followed by another manual run
of: "pdp11 simh_dict.cmds" followed by Ctrl-e and then look at the generated
output in test.dict. At the tail end of the output, I noticed something that
caught my eye: the comments were being treated as compile/"exec"utable words.
And this pattern started soon after the code in the definition of "}else{"
which calls "[compile] }if" was processed. This code was added to the code as
step 58 in the previous commit where it appeared to work (ie my tests did not
signal any errors at step 58).

Since it was clear that something funny was going on with "[compile]", the next
debug print that I added was to check the value of the "state" variable. Since
PDP11 uses a padded out word for state due to alignment issues my guess was
that this difference was somehow triggering the difference in behavior on the
PDP11. But that line of thinking didn't turn up anything useful but all of that
debugging helped to narrow down the problem which could be now be summarized
as: "[compile] }if" was expected to result in "}if" being defexec'ed but it
looked like that wasn't happening on PDP11.

So the new round of debugging focused on the following execution chain:
	outer -> repl -> cpl_ex -> cpl_ex_imm -> defexec
mainly to see why the "exec" path inside defexec wasn't being taken on PDP11
when it needed to "defexec" the "[compile]'ed" word "}if".

defexec calls "isdefn" so the question was further narrowed down to see why
"isdefn" wasn't returning a "true" flag (on PDP11). This helped narrow it down
to ">=" not returning true. I verified that the values that were compared were
sane by "print"ing them out using '.' so the only code left to check was ">="
which was just a shim layer over '~' and just browsing the code and seeing the
difference between the code and the comment was enough of a hint to figure out
the bug - which was that the PDP11 implementation of '~' mistakenly used the
constant 0xF000 instead of 0x8000.

In hindsight, looking back at the other commits made on 15 Dec, it looks like
it was, all in all, a pretty productive day with a lot of progress made for the
PDP11 port, but doing too much on one day may have made me careless enough that
I let this bug slip through. Note that the "proof comment" that accompanies the
code was correct while the code itself was wrong (and the code had diverged
from the comment). The simple test case used to exercise the code did pass so
I could also attribute it to insufficient testing. In any case, it seems clear
that the bug might have been just a typo - ie, not a "thinko".

26 Jan '23
----------
With all of the recent commits, the repl has been gaining a fair bit of
functionality and so I'll consider the addition of '.' in today's commit as a
good stopping point for a "feature freeze" since all of the features that have
been added so far should be more than enough to get a decent amount of code
written and debugged directly from within the repl.

So I'll go out on a limb again and declare "fourforth" as officially complete,
ignoring the earlier assertion in the JOURNAL entry of 16 Jan '23 when I had
jumped the gun a bit and declared, a little too hastily perhaps, that it was
complete. Between then and now, over the past ten days, I've added support to
the repl for many of the control structures familiar to most programmers:
# Conditionals:
	* Forth's "if/then"	: if{ ... }if
	* and "if/else/then"	: if{ ... }else{ ... }if
# Various types of loops:
	* Forth's "while" loops	: loop{ ... }while{ ... }loop
	* and "until" loops	: loop{ ... }until{ ... }loop
	* and "for" loops	: for{ ... }for
Writing meaningful "stack picture" comments are enabled using '[' and
"print based debugging" is possible using '.'

Definitions can be created using the conventional ':' and ';' although in my
own code, I prefer using the syntactic sugared def{ ... }def that I've been
using using all along in defs.4th - I've enabled this in the repl as well by
using a tiny shim that wraps over the existing defining words ':' and ';'

Obviously I have no intention of adding a boatload of even more features and
word definitions to make this implementation conform to any of the existing
Forth standards since that will just result in bloating it up beyond any
reasonable hopes of fitting it into small microcontrollers. So I expect
feature additions to freeze here but I'll keep an open mind based on further
testing and future experience gained on real hardware.

Obviously this implementation can be extended to your heart's content in any
way you see fit - but those changes belong in other "project specific" repos.

Barring any other bugs that I may run into, I expect there will be no further
changes to any of the existing files. The only changes I expect to make as I
port this to newer architectures/microcontrollers/cpus will be to create new
directories and add them to the top level makefile - perhaps even add them to
the "allsteps" make target for regression test, in case that becomes necessary.

So now that I'm clear in my mind about what not to do, the next question always
goes back to what I should work on next? In the entry for 16 Jan '23 I tossed
out SPARC as an option since it is big-endian. That still sounds reasonable so
I'll start to look at what tools in terms of build and emulation are handy.
Another option might be to look at any of the other architectures that are
emulated on simh and also have binutils assembler support. Given my familiarity
with that toolchain now, switching to one of those architectures might also be
an option if the SPARC port starts to look like too much of a hassle.

01 Feb '23
----------
After spending some time looking at a couple of big-endian architectures to
come to a decision on the next porting target, SPARC and Motorola 68000 among
them, I decided to pivot a bit and go back and fix up the C port which got
stalled along the way, a while back.

The rationale behind this approach is that C compilers exist for quite a few
processors and I know that SPARC and the m68k architectures are well supported.
So rather than try to write the bare metal assembly code directly from scratch,
it makes more sense to generate the assembly code using the C compiler's "-S"
option (for those processors that do have a C compiler) and then tweak that
output to run on bare metal rather than try to do all of the heavy lifting all
by myself.

Instead of just continuing where I left off with the earlier version of the C
porting attempt, I decided to just get rid of the old code and start from
scratch so that I can start using the "step wise" approach that I had tested
for the PDP11. This will give me yet another opportunity to debug any porting
issues when using the "step wise" methodology. Since the PDP11 port was the
first attempt at using the "step wise" approach, I've copied over all of the
generator scripts from pdp11 and modified them to get a working version of the
C port for step 0.

Since the purpose of this exercise is to make the code as small as possible,
I've used the -Os option to optimize for space and sprinkled a few "register"
declarations in the hope that the compiler can do some "magic" with it although
IIRC, "register" hints are ignored by most modern C compilers.

This should also give me a good opportunity to see how well the latest and
greatest versions of the C compilers fare compared to earlier versions versus
my own hand coded assembler versions.

The C compilers that I'll use for this exercise (tail output from cc -v) are:
	gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2)
	clang version 3.8.0-2ubuntu1 (tags/RELEASE_380/final)
since they are the versions that are available by default on the really ancient
Ubuntu 16.04 distro that I have on my laptop. I'll compare these against the
newer release versions of gcc (which seems to be 11.x) and clang (also at 11.x)

03 Feb '23
----------
We are barely at step 3 and it looks like a byte offset which was sufficient
for my hand coded assembly code is not sufficient for the code generated by
the C compiler even with the -Os option. So in terms of code density, it is
pretty clear that the compiler doesn't seem to be much of a match for a
competent coder - even in this day and age. Perhaps ChatGPT can hallucinate
better code - but only after it has ingested some of my code I guess ;)

15 Feb '23
----------
I'm back at trying to find a new solution to the problem documented as the
very first entry in this JOURNAL (see the entry dated 11 Nov '22 - note that my
frustration at finding a solution then was part of the reason that I started
this JOURNAL). Since this time around I've chosen to use GCC's "labeled gotos"
for jumps, by necessity, the "rom" needed to be local to main (or whichever C
function happened to contain the labels for the "primitive" operations). Since
higher level "definitions" also need access to the "primitives", this implies
that newer "definitions" (which need to be part of the "rom", in some sense)
also need to be in data structures local to main (just like the "rom" array
itself). Unlike assembly code, C does not provide any means of referring to
individual array elements. One solution might be to do a second pass using
objdump to parse the generated binary to get the addresses if they were outside
the function (in the global name space). Since that sounds a bit too hacky, my
solution is to put each of the "definitions" in its own "rom" array and then,
(this is the clever part), add a layer of indirection using yet another array
that contains pointers to the start of each of these "definition roms" and hope
and pray that the C compiler does not insist on rearranging the ordering of the
various "definition rom" array elements.

With this setup, referring to definitions just needs the index into that array
and the index can be passed around as an int on the data stack without having
to do any casts between pointers and ints. Unfortunately this separation also
means that I now need a third "machine" stack to hold the pointer sized return
addresses. This change then triggers a domino effect change on the how rp@! is
implemented but I'll defer that for now to minimize the amount of code that
needs to go in as part of this change set.

21 Feb '23
----------
To deal with variables, the initial implementation starting at step 14 assumed
that a struct (called "ram") with an array (called "mem") plus some offsets
into that was a good enough abstraction. This allowed a clean compile without
all of the warnings about "pointer to int casts" which the compiler would whine
about if I had chosen to directly use pointers instead.

Unfortunately that abstraction runs into trouble starting at step 41 where I
need to traverse the dictionary (which primarily involves pointer chasing).

Given that parts of the dictionary could be stored either in "ROM" or in RAM,
depending on whether it was defined at compile time or run time, the "prev"
pointer of a dictionary entry could be either in RAM or in "ROM".

But given that the current abstraction can only access RAM, following a pointer
into the "ROM" won't work without additional changes. So my choices are:
1. Create a similar memory access abstraction for data in "ROM"
2. Copy the "ROM" dictionary contents into the RAM and use RAM for everything
3. Give up on the abstraction and just use pointers directly

The downside to (2) is obviously the higher RAM requirement and the downside to
(1) is that each memory access will then need an additional tagging scheme to
distinguish between RAM vs "ROM" access.

So I'm going to cave in and just use pointers directly instead of the previous
"array + offset" scheme. But this brings up the problem of whether the location
of the variables will be at a small enough address that fits in an int since
the default is LP64 (long and pointer use 64 bits, while integers are 32 bits).

On my x86_64/Linux laptop, running "nm" on the generated binary shows that
static/global variables are allocated at addresses which fit in 32 bits while
addresses on the stack appear to need all 64 bits. Based on that small bit of
information, it looks like I can safely get away with casting the pointer to an
int to access the data despite the compiler warning.

It is not clear though if this address allocation is true for all other OS and
compiler combinations, so to be future proof, the safer means of doing this is
to use 64-bit ints but I'm not going to bother with that for now. On compilers
which generate either ILP64 or ILP32 (ie integers and pointers have the same
bit width), things should "just work".

So, after doing away with the whole "struct ram"+offsetting into its mem array
scheme that I was using earlier, the new scheme declares the three variables
that are needed at bootstrap within a "vars" struct which is aliased using a
"varalias" character array pointer. The offset of each of these variables is
small enough to fit in a short (or even a byte actually) so that is used in the
rom array instead of the actual pointer (which will not fit in a short) but
that meant adding a new "var" primitive which turns the short offset into the
appropriate address pointer.

Since I'm switching back to using pointers directly, I also decided to do away
with the distinction between the "return stack" and the "machine stack" (which
was introduced at step 23) since I can now refer to ip addresses directly. So
I've reverted the code to match the earlier design that was used in the x86 and
PDP11 ports of using only a "return stack" since the "ip" addresses are small
enough that they will fit in an int.

Since there have been a boatload of changes, that affect earlier steps, I've
gone ahead and added yet another Perl script (called runallsteps) to ensure
that no regressions were introduced by any of these changes at any of the
earlier steps.

One of the weird issues that I ran into while debugging this set of changes
was a compiler optimization issue. Although the dictionary structures were
correctly generated by genrom and compiled without any errors, there is no
direct reference to any of them in the C code and so the GCC compiler decided
(probably since I'm using the -Os option to optimize space) that all of the
unreferenced dictionary related structs are not needed and stripped them out of
the generated binary. To workaround the procrustean attitude of the compiler,
an extra array was added that references each of the generated structs and also
added an assert which accesses a random struct element to hint to the compiler
that all of the generated structs are needed (none can be discarded).

Another issue that needed to be debugged and resolved was that the padding
generated by the compiler is at odds with the expectation that all the entries
are packed together in the dictionary. The workaround to this issue was to use
GCC's __attribute__((packed)) directive to eliminate the padding.

---

On a personal note, it's my Mom's birthday today but this will be the first
year I will not be able to just call and hear her voice as always. Miss you
Mom, Happy Birthday! :RIP:

22 Feb '23
----------
Although step 42 worked without any problems, at step 43, I ran into a SEGV and
with some debugging I found that the sigsegv happened when "here" was looked up
in the dictionary. Debugging some more, I found that although the dictionary
headers were generated correctly, for all of the definitions in defs.4th, the
dictionary headers for the primitives (including "here") which was generated by
the genprims script was being stripped by the compiler since I had forgotten to
apply the same hack that I'd done yesterday for genrom. Rather than continue
down that hacky route, I decided to go with a different solution which makes
the dictionary struct header exactly the same as the assembly version and made
sure to make this change in both the genprims and the genrom scripts.

The new dictionary header structure also eliminates the need for the array of
structs that was needed in the previous implementation since the assignment to
the "latest" dictionary header pointer variable ensures that all the structs
are marked as live by the C compiler so it does not try to strip them out.

I'm happier with this version than the clunky hack that I'd coded up yesterday.

23 Feb '23
----------
Compared to coding in assembly, coding Forth in C is actually turning into a
real PITA. To debug the issues that cropped up at step 44, I needed to add even
more debug printfs which helped to narrow down the issues.

The first problem turned out to be that the current tests assume that the repl
lookup of "here" returns an address which is writable. For the C port though,
I've marked the statically generated dictionary headers as "const" which makes
them readonly so that they can, in theory at least, be stored in a "ROM". So
I needed to add another layer of indirection for "primitive variables" in C
which have been wrapped in the dictionary header. Unlike traditional Forth, the
"cfa" of these variables is readonly and only contain a pointer to the "real"
variable's writable location.

This is workable but requires changes to the tests in rom.4th when variables
are accessed via the "repl". For now I've made an ugly band aid fix of adding
yet another configuration parameter called "prim_var_deref". If that is set to
1, it means that the repl needs to do an additional indirection on the cfa
before fetching/storing a value to the address of the underlying variable.

With that issue out of the way, the next issue I ran into was another segv.
Tracking it down with the debug printfs showed that the problem was that the
CELL size was still set to 2 (which was inherited from the PDP11 port). In this
case since we are using CELL size to step over the lfa and since that is a
pointer sized location in the C implementation, CELL needed to be configured to
8 instead of 2. This is just yet another band aid fix rather than a "real fix"
so that I can think through what exactly "CELL" should mean in this port.

Traditionally, in Forth, the CELL size is the native "word" size of the CPU on
which the Forth VM runs. But given the mix of "word" sizes I have used along
the winding path to reach this point, I think I need at least 3 different CELL
descriptors. The "short" bytecodes used in the VM proper need a CELL size of 2,
the "int" sized stack entries (in the data stack and the return stack) need a
CELL size of 4 and of course any "pointer" sized values need a CELL size of 8.
Obviously the "one size fits all" philosophy of regular Forth is not going to
fly well here.

Since it is fairly late now, I'm going to commit this fix for now and continue
to think about better options for a later commit. I think I'll just sleep on it
and see if there is a neater way to encapsulate this mess.

In any case, since the common code in rom.4th was modified, I ran the full
regression using "make allsteps" and the earlier ports haven't rotted away yet.

24 Feb '23
----------
While coding in assembly, I had the full freedom to intersperse code with data.
Since C does not allow that freedom (for good reason), I needed to do a little
backtracking to modify some of the older decisions made at step 45.

With the placement of the dictionary header for variables in "ROM" (which was
done at the previous step, step 44, yesterday), the older method of using the
location of "latest" to distinguish between "primitive definitions" and
"primitive variables" no longer works since the dictionary header is separate
from the actual variable that it wraps. So I needed to fall back to a more
traditional Forth like means of invoking the cfa contents (think DOVAR, DOCOL
etc) from the dictionary. So I changed cfaexec to directly "call" the contents
of the dictionary, thus restoring the earlier freedom of assembler code to mix
data with code which C had taken away.

Since common code was changed at this step as well, I ran the full regression
using "make allsteps" to make sure that "all is well".

25 Feb '23
----------
The traditional Forth technique of directly "call"ing the cfa is a much better
solution than the existing, (and in hindsight, pretty clunky) method that I'd
implemented (for x86 and PDP11). I'll stick with the new change only for the C
port for now and revisit the earlier implementations later as time permits.

27 Feb '23
----------
The porting of steps 47, 48 and 49 were, for the most part, smooth sailing. At
step 50 though, I needed to introduce yet another configuration parameter which
I've denoted as THREAD type 3, for the C port which uses a short 2 byte offset
for the "primitives". Although PDP11 also uses a 2 byte offset, the C port does
not use a leading prefix at the start of definitions so I needed to distinguish
between these configurations with yet another parameter. This also required the
addition of yet another non-conventional Forth word which I've called "s," (for
"short ,") to append a 2 byte little-endian short to the dictionary.

While I was there, I realized that the machinestack configuration variable
which was introduced a while back (and then removed later) was still hanging
around in the x86 and PDP11 config files so I've cleaned that up as well.

As usual, since common code was modified, I ran make allsteps as a sanity check

01 Mar '23
----------
There was another SEGV that needed a fair bit of debugging at step 52. By
dumping out the list of words in the dictionary, it was clear that some of the
dictionary entries were getting corrupted. With additional tracing, I tracked
the cause of the corruption down to an overrun of the return stack. Since C
uses 4 bytes for each return stack entry which is twice the size used on x86
(and PDP11), I've doubled the configured return stack size for C (from 30 bytes
to 60 bytes). Although this change has fixed the sigsegv, I need to think of a
better way to deal with issues like this longer term since I had run into the
identical problem earlier as well (while doing the PDP11 port).

Another long standing issue (which I've mentioned earlier on 23 Feb '23) is the
usage of CELL for multiple/different things. Since C literals need 4 bytes (as
opposed to 2 bytes for x86 and PDP11), I've created a new configuration param
called LITC which needs to be set in the architecture specific fpp.config file
and configured it for the C port to 4 and for x86 and PDP11, it is set to 2.

06 Mar '23
----------
I seem to be making progress on the C port one segv at a time. The latest segv
came out of left field - primarily since I'd forgotten a relevant detail, which
I'll blame on the distractions from real life (rains, roof leaks).

Due to all of the recent rains (which were a welcome relief after a couple of
years of fairly intense drought) here in California, the low slope roof on my
patio decided to go ahead and spring a leak. I think it was last repaired about
10 years ago so it was bound to fail any day now. As a short term fix, while
browsing around in the nearby Home Depot, I found a "repair and seal" tape with
an aluminum overlay called "Resisto" and used that to patch up the ripped seams
(at least the ones that I could locate). Fingers crossed that all of it will
hold up for the next batch of rains that are predicted soon.

Anyway, coming back to the sigsegv, it turned out that the old way of marking
the dictionary entry for ";" as an immediate word, "after the fact" as it were,
does not really work since the dictionary headers are marked "const" (because
they are stored on a read-only page). An obvious way to workaround this is to
make the dictionary headers writable by removing the "const", but this requires
them to be placed in RAM. Since one of the primary rationales that led to this
project is minimizing RAM usage, moving the headers to RAM is not a very useful
solution. So it is clear that making the headers "const" is obviously a "good"
constraint to have since it allows more stuff to be held in ROM but it also
implies that the "immediate" bit needs to be set in the dictionary header prior
to the C compilation. So this required changes to the genrom script for the C
port which then had the follow on effect that to maintain compatibility across
the various ports, I need to repeat that same set of changes to genrom 3 more
times for all of the other ports as well (ie x86, x86-as and PDP11).

To mark words as "immediate", I went back to an approach I'd considered a while
ago and rejected (see my earlier entry dated 18 Jan '23). I'd decided against
doing it at that point in time but with hindsight, my mind is now made up that
reversing that decision is the right thing to do. So this change introduces the
keywords imm{ ... }imm to define immediate words (ie to create the dictionary
headers marked with the "immediate" bit set)

Making this change also involved changes to defs.4th (since the definition of
";immediate" becomes superfluous and can be removed) and to rom.4th as well
(since it no longer needs to call ";immediate"). As usual, since there were
changes to common code, "make allsteps" was used to verify all that code churn
did not introduce any regressions.

With all of that restructuring out of the way, the rest of the work looked very
simple: just "call" the cfa from the REPL when "interpreting" and prefix the
cfa with "enter" when "compiling". So I went ahead and prototyped that only to
find myself running into yet another SIGSEGV. Tracking that one down helped me
realize that the leaky roof had led to stuff seemingly leak out of my brain as
well. ;)

I had to go look at the code to remind myself that "enter" in the C port was
partially intended to abstract away the fact that I can't squirrel away a 32
(or a 64) bit wide pointer into an array of 16 bit shorts. Although C by design
cannot introspect on it's symbols at run time, Forth's dictionary allows it do
just that. So instead of calling "enter", I've modified it to push the cfa onto
the stack (by wrapping it with a "lit"eral) and issuing a "call" to that cfa.

Now that I know that even a small context switch from working on code to other
stuff is enough to make me forget tiny details, I hope that the prediction of
even more of these rains (which will likely result in some more of these roof
leaks) will not result in yet another round of the coding context in my head
getting washed away as well.

08 Mar '23
----------
Getting steps 54, 55 and 56 verified was pretty easy but I ran into a fair bit
of trouble at step 57 : "support conditionals at the repl". The first issue was
the fact that jump offsets are 16 bit. While this works fine on the PDP11 since
16 bits happens to also be the CELL size, it doesn't work on C since ints are
32 bit wide. So the first change was to introduce a definition to store shorts
called "s!". Once that was sorted out, I ran into a second difficulty: since I
use the cfa uniformly across variables, primitives and definitions, primitives
such as lit and j/jz/jnz which use "immediate addressing" to get their operands
will not work (unless I change the code to match, which would make them pretty
inefficient). Since I just need a means of getting their values to store into
the dictionary, I've used the workaround of adding a new word called "#jz" to
do this - the '#' is meant to be a mnemonic that it is an absolute value (kinda
like the equivalent denotation used in assembly). An alternative to this might
be to define the conditionals in defs.4th where I won't need to jump through
such hoops but I guess there might be some value in minimizing ROM usage unless
absolutely necessary so I'll stick to the current approach. In any case, once
that issue was sorted out, the third bug I ran into was that the jump offset
wasn't calculated correctly. This turned out to be due to the fact that C does
pointer addition which scales the offset by 2 (since it was a pointer to a
short) so I needed to scale down the offset by the equivalent amount before
storing it into the dictionary header. Once all these fixes were done,
conditionals started to work as expected.

Since common code was changed, I ran "make allsteps" to check for regressions.

10 Mar '23
----------
At step 60, I ran into a SIGSEGV which turned out to be a pain to debug. So I
added a few more debug prints to "show" each token as it is being parse'd
within the repl in the "outer" interpreter. Using this, I was able to narrow
down the SIGSEGV to be occurring when the "for{" keyword was being executed. By
adding an additional debug print to the "call" primitive, the bug was sort of
easier to track down to a misinterpretation of how "r>" was supposed to work.

In the C port, I had chosen to make the handling of CFA's (after a dictionary
lookup in the outer interpreter) uniform across primitives, variables and
definitions (both static and dynamic). This differs from the earlier x86 and
PDP11 implementations. In the C port, invoking "r>" (via the outer interpreter)
will turn it into the following sequence:
	lit CFA_of_r>_in_the_dictionary call
where the dictionary entry itself contains the following sequence at the CFA:
	r> exit

In the x86 and PDP11 ports (and even in the code generated by genrom for the C
port), primitive invocations are turned into direct jumps to the native code
offset which does not use "call" - and this is the important part: it does not
affect the return stack.

The additional "call" layering to "r>" in the "outer" interpreter in the C port
was messing with the functionality of "r>" and was the source of the bug. So
the simple fix was to move the code for "compile" from rest.inp (which is
handled by the outer interpreter which adds the "call" layer) to defs.4th
(which is handled by genrom which keeps "r>" and ">r" as primitives) and that
was good enough to fix the bug. I'll call this out as TECHDEBT since this
violates the law of least surprise and is going to bite "unwary me" somewhere
down the line.

11 Mar '23
----------
Looking back at the very first journal entry, it was exactly 4 months ago that
I started this journal - primarily to vent about the fact that I was giving up
on the very first attempt at a C port because of my frustration with how much
of a struggle it had become to make Forth see eye to eye with the abstraction
imposed on the baremetal by the C compiler.

So now that I've successfully completed a "second system"/from scratch C port,
this is as good a time as any to look back and figure out lessons learnt and
what could be done better for the other upcoming ports.

Although my second attempt at the C port took much longer than I ever expected,
the end result gives me a deep sense of satisfaction since I think that it has
resulted in a much better implementation overall since the read-only/ROM and
read-write/RAM areas have well delineated boundaries now.

It was also a bit more pleasant to test things out since I could debug things
in userland instead of mucking around in a slow emulator. The protections that
are offered by running it with MMU protected pages makes it more likely to die
sooner with a SIGSEGV, in case of bugs, instead of chugging away and corrupting
random locations in memory as happened in the case of the PDP11 port.

One thing that is pretty clear is that the "step wise" approach that was begun
as part of the PDP11 port turns out to be a really good idea. Some of the parts
which took longer in the C port need to be examined to see if it is possible to
break them up into smaller, more easily tested/debugged chunks.

One thing that I'm surprised about is that it took me almost 6 weeks to get the
C port done (despite it being a second attempt). Now that I've completed 4
ports in ~5 months, I guess it might be reasonable to estimate that each new
port will take ~5-6 weeks.

Since this port felt like it was starting to take too long, I may have been a
little too trigger happy in adding techdebt along the way. In particular, I'm
unhappy with the addition of yet another THREAD'ing type (3) which has resulted
in some parts of the code becoming even more cluttered with conditional compile
directives than earlier. I also had to implement things a little differently
from the older ports since the static part of the dictionary is now read-only.

I hope to bring the other ports into sync with this implementation so I can get
rid of at least some of the parameter types from the fpp.config configuration.

Anyway, that's work for another day. Today, I'm just going to bask in the fact
that I have yet another port under my belt, which I've completed successfully,
and the quality of which is to my satisfaction, instead of being one of those
rushed "just get it out the door" things that are common in many $DAYJOBs.

14 Mar '23
----------
Before starting on the next port I needed to do some research on how to setup
all the tools (build+emulation/flash in case of real hardware) that will be
required for that CPU. For x86 (and x86-as), the choice for the build tool was
straightforward: nasm/binutils. For x86 emulation, I chose to code an emulator
from scratch although using other existing tools might have been a workable
solution. For the PDP11, binutils and simh turned out to be a good choice.

For the next port, I have a choice of picking either SPARC or m68k since both
of them are big-endian architectures and both of them have gcc/binutils and
qemu support. Unfortunately, qemu does not provide a documented/simple means of
exiting from the guest VM (other than generating a triple-fault and using the
--no-reboot option). There doesn't seem to be an architecture neutral means of
accessing the serial ports either. So my choices are to peek at the code for
other guest OS'es to see how they manage to perform a graceful exit from QEMU
or to take a look at the QEMU code itself. I don't relish either of these
choices since it involves having to wade through the millions of lines of code
that both choices have to offer.

As an alternative, I've started to look at unicorn-engine which appears to be
layered on top of qemu. libcpu might be yet another alternative although it
appears to be dead since the code on github is marked as a read-only archive.

Before going off to jump into the deep end on that research, I decided to try
and see if I could generate a profile of the running code in the C port to see
which primitives are heavily used and might be in need of optimization when I
eventually start on the native code implementations. Rather than spend too long
generating a well thought out design, I threw together a "quick and dirty"
hacky prototype which seems to be good enough to get the job done.

To get the profile (which was only enabled for the C port, since it was easy to
get it done there), the following steps are needed:
	1. Uncomment the "#define PROFILE" in forth.c
	2. Run "make clean" in preparation for the next step
	3. Run "make 2> prof.tmp ; tail -101 prof.tmp > profile.counts"
	4. Run "join profile.counts profile.names | sort -nk 2 | less"
	5. Clean up by running "rm profile.names profile.counts prof.tmp"
	6. Comment out the "#define PROFILE" in forth.c

Using the above list of instructions, I generated a profile from running the
build+tests, the output of which is shown below. It is sorted on the second
column (which tracks the number of times the primitive was called):
{begin:profile
	1 1 bye,bye
	14 1 inv,inv
	29 1 stick,stick
	31 1 lbl011,rp@!
	34 1 exec,exec
	39 1 lbl015,p!
	30 2 lbl010,sp@!
	38 2 lbl014,p@
	20 14 lbl004,|
	6 18 emit,emit
	43 19 lbl018,0=
	8 32 neg,neg
	0 79 next,next
	40 107 lbl016,<<
	21 337 lbl005,^
	41 369 lbl017,>>
	25 741 lbl007,!
	37 1363 call,call
	44 3308 var,var
	9 5242 jnz,jnz
	27 6165 lbl009,c!
	5 6265 key,key
	12 11263 inc,inc
	28 16527 pick,pick
	16 20377 dip,dip
	15 21303 nip,nip
	3 21336 lbl000,2drop
	24 21744 lbl006,@
	13 22702 dec,dec
	19 26095 lbl003,&
	4 27407 drop,drop
	26 28766 lbl008,c@
	32 29528 lbl012,>r
	33 29553 lbl013,r>
	17 47075 lbl001,-
	18 53971 lbl002,+
	11 70029 j,j
	2 70224 dup,dup
	42 75757 over,over
	7 86147 lit,lit
	22 86607 swap,swap
	23 86607 t_n,t_n
	10 95966 jz,jz
	35 113738 enter,enter
	36 115076 exit,exit
}end:profile

One surprising piece of info that shows up in this data is that there are 79
jumps to offset 0 (the row "0 79 next,next" in the data above). That equates
to a "nop" which isn't explicitly coded anywhere so I assume it indicates a
bug of some kind, so I think I'll track that down next.

Since this is not the profile of a real workload, it cannot really be used to
make decisions. But it does highlight some of the big hitters that I'll need to
be aware of when working on all of the future ports (or to optimize the earlier
ones).

15 Mar '23
----------
I tracked down the cause of the NOPs that I found in the profile yesterday to
the fact that variables are encoded in the dictionary using a pointer (within
the CFA). There is no way other than to use a pointer sized encoding for this
since the C compiler will error out, otherwise. Due to the little-endianness of
x86, the "short" offsets to which it is cast sees a pair of NOP's (after the
"lit" that precedes the variable address has already cast the pointer to an int
and skipped over the leading 4 bytes which contain the address).

I hope the following ascii diagram makes the situation clearer:
	----------------------------------------
	| lit     | address pointer   | exit    |
	----------------------------------------
	| 2 bytes | 4 bytes + 4 bytes | 2 bytes |

These 4 bytes are 0 filled -----^----- since the address happens to fit in
the preceding 4 bytes. Since these are 0's they are seen as 2 nops by the VM.

Since the nops are harmless and are just an artifact of the C compilation, I'm
going to ignore them and move on to the next port.

16 Mar '23
----------
One pattern that I've seen repeated in this project is that at every place when
I need to pick a new CPU, I agonize over the decision mostly because all of the
alternatives have some blocker that makes every single one of the available
choices fairly painful. My earlier choice of the PDP11 was in no small part due
to simh/pdp11 "dwim"ming along to my intentions without turning into a blocker.

So, here I am, at yet another fork in the road, and while I evaluate qemu vs
unicorn vs libcpu vs whatever else may show up in my research, my gut instinct
is telling me to pivot yet again - to something easier.

Since the entire point of the C port was to be able to generate assembly code
so that I could leverage that code without having to go through thousands of
pages of CPU architecture manuals, for each CPU that I want to port to, my
"light bulb" thought was: why not start with an x86 assembly language port?
Obviously this will be different from the earlier x86/x86-as ports since
1. It is a userland port and
2. It will be 64 bit, not a 16 bit realmode implementation, and the best part
3. It can run natively, with no emulators involved.

As an additional bonus, it will give me a chance to compare the code generated
by the compiler vs hand written code (in terms of both size and speed).
So that's what I'm going to do next while I continue researching alternatives
for how to easily emulate SPARC/m68k/other CPUs on my list.

17 Mar '23
----------
One of my observations about why it takes so long to do a port is that an
inordinate amount of time is spent on updating the JOURNAL entries. While it
certainly does help documenting various aspects of the design and also the bugs
encountered along the way, it is a big time sink. So in this new x86 assembly
"userland" port, I'm going radio silent until the port is complete.

I'll just document this one piece of info, before I switch off JOURNAL updates,
that I'm splitting up step 0 into smaller chunks since getting started can be
very painful as you research tools and figure out how to build the code as well
as fleshing out the infrastructure to do the emulation and test. This makes the
"runallsteps" script the final arbiter of the actual "steps" and I'll note as a
$TECHDEBT that at some future point in time, I'll need to update the steps that
are outlined in pseudo/code so that they are in sync with what I do in reality.

21 Mar '23
----------
This is an important enough piece of information that I'll break the radio
silence that I'd promised in the previous JOURNAL entry and document this here.

Since the x86 userland assembly port uses a dictionary layout that is aligned
with the dictionary layout that was used as part of the C port (but breaks with
tradition from the earlier ports which were done in assembly), I've decided to
document it in some detail since I assume this will be the format used by all
future ports.

I'll start with the layout of ROM which contains these parts (in this order):
- Start up/init code implemented in native/machine code
       Assembled from forth.S
- init and test "bytecodes"
       Generated from rom.4th by genrom and assembled from rom.s
- dictionary headers for the "primitive variables"
       Generated from code.prims by genprims and assembled from dict.s
       usual format: align; pad; nfa; lfa; cfa:{ lit ; $var_addr ; exit }
       Note that "here" needs to be very first dictionary entry - this is
       verified by the test code
- dictionary headers for the "primitives"
       Generated from code.prims by genprims and assembled from dict.s
       usual format: align; pad; nfa; lfa; cfa:{ $prim ; exit }
       There are no ordering constraints except that the dictionary entry
       preceding the first one needs to be "latest"
- dictionary headers for the defined words/"definitions"
       Generated from defs.4th by genrom and assembled from defs[_dict].s
       usual format: align; pad; nfa; lfa; cfa:{ ... ; exit }
- Machine code for the primitives (usually starting on a 256 byte boundary)
       Generated from code.prims by genprims and assembled from prims[_dict].s

For now, RAM contains:
- the datastack
- the return stack
- the "primitive" variables
- the "memory area" (used by the return stack and the runtime dictionary)

To summarize:
        ROM: {
                startup/init code : forth.s
                init/test byte code : rom.4th
                primitive variable dictionary headers : code.prims
                        cfa : lit $var ; exit : {
                                here
                                ...
                                latest
                        }
                primitive code dictionary headers : code.prims
                        cfa : $prim ; exit
                defined words dictionary headers : defs.4th
                        cfa : ... ; exit
                machine code for the primitives, starting on 256 byte boundary?
                        assembled from code.prims
        }
        RAM: { // ordering and overlap of these sub components is undefined
                data stack
                return stack
                "primitive" variables
                available memory
        }

23 Mar '23
----------
So now that the x86 assembly userland port has also been completed, I can now
break my self imposed radio silence.

This port took only about a week but that required me to work over the weekend
and pretty much ignore everything else that was going on around me. So I still
think a reasonable estimate for how long a port should take is 2-4 weeks if we
can assume that all the other dependencies are resolved and there are no other
blockers.

The fact that the MMU on the x86 provides decent fault isolation and quickly
generates a SIGSEGV instead of corrupting random locations in memory also
helped a lot with the turnaround.

In any case, being productive is a function of lots of environmental variables
so being able to finish this in a week just goes to show the importance of
having fairly good infrastructure to be able to build and test things quickly.
All in all, I think I now have a good enough framework in place for porting all
of this to other CPUs in the future.

Since the C port and x86 assembly port both work in userland, running natively,
it gives me an opportunity to compare compiler vs hand written code performance

Running `perf stat`, I generated the following table comparing the two:

.-------------------------------------------------------.
| Metric		| C		| Assembly	|
+-----------------------+---------------+---------------+
| Task-clock (msec)	| 4.439651	| 3.957470	|
| CPUs utilized		| 0.884		| 0.861		|
| Cycles		| 9,969,446	| 8,866,091	|
| Instructions		| 10,365,760	| 6,413,838	|
| Insns per cycle	| 1.04		| 0.72		|
| Branches		| 2,374,783	| 1,734,081	|
| Branches M/sec	| 534.903	| 438.179	|
| Branch-misses		| 204,129	| 130,745	|
| % of all branches	| 8.60% (56.95%)| 7.54% (41.86%)|
| Time elapsed		| 0.005021309(s)| 0.004598909(s)|
'-------------------------------------------------------'

The hand written assembly version appears to be better on pretty much every
metric, so I assume compilers still have some catching up to do ; gcc --version
reports: gcc (Ubuntu 5.3.1-14ubuntu2) 5.3.1 20160413

Looking forward, I still need to get to a conclusion on what tools to use for
future CPU ports - unicorn appears to be the best choice I've found so far.
But for now, this project goes on the backburner since I'll need to address my
"real world" problems first (starting with my leaky patio roof for one, and tax
season will soon be upon me, before I even know it).

So the SPARC and m68k ports (and all the others), will just have to wait.

Oh, and before I forget: Happy Birthday Shiji!

01 Apr '23
----------
While researching SPARC32 emulation, I had one of my usual pivot ideas: rather
than start directly on SPARC which needs emulation, why not first start with
an x86 32 bit port which can run natively so that the x86 gets "full porting
coverage" in some sense, and be done with it. The older x86 and x86-as ports
provide 16-bit "realmode", if you will, coverage of the x86 and the x86-user
(and the C port) were tested on 64 bits so this could be the last hurrah on
x86 with a 32 bit port.

Since I have a really ancient 32 bit x86 Toshiba laptop (which I think I bought
new in 2003) which is still going strong, I decided to use it for the 32 bit
port. The first issue with using it though was getting it to use a modern linux
distro (I used to run Solaris on it). Ubuntu is my usual distro of choice but
none of the recent versions of Ubuntu appear to be able to even boot up on the
"puny" 256MB memory that this laptop has.

After a bunch of research and experiments with various distros, I've settled
on using it with NixOS 22.05, which according to Repology has the largest
selection of package choices. I don't need a lot of stuff for development
but it is nice to know I have choices, if I need it.

Since GNOME is too bloated to run on 256MB of memory, I needed a slim window
manager, so I've installed dwm on it for now although at some point I want to
port olvwm to it as well. For actual development, I was able to pull in a
fairly recent version of gcc (10.3.0) using nix-shell. So with all of those
preliminaries out of the way, I can now start on the actual port.

03 Apr '23
----------
Rather than start from scratch, as I'd done with most of the earlier ports,
this time, I'm using most of the code "as is" from the x86-user port since I
assume most of the code can be common across these two ports.

To start off, I've modified the runallsteps scripts since it makes it easy to
run all the regression steps, if needed. Next I copied over files as needed
from x86-user into x86-32 and made some small tweaks for the 64 bit to 32 bit
change and ran make/`runallsteps x86-32` until I had a passing "step 0".

The primary changes required were to switch all the registers to use the 32 bit
variants and to use the 32 bit "lodsl" instruction equivalent of the 64 bit
"lodsq" instruction.

----------

The API for calling putchar from assembly appears to have changed with the
newer version of OS/glibc/gcc that I'm using for this port, so rather than
try to parameterize that as well, I'm going to just document it here and
quietly move on since this is just another userland port which I'm using
only to sanity check the 32 bit port.

05 Apr '23
----------
I'm starting to realize that I should have named the directories better, but
in my defense I'll just say that naming is hard.

The just concluded "x86-32" port denotes an "x86 32 bit userland assembly" port
which currently holds the record for how fast a port can be done mostly because
it just needed a few fairly simple modifications to the "x86-user" port.

The "x86-user" port in turn denoted the "x86 64 bit userland assembly" port
which held the previous record for how soon a port could be done - at ~1 week.

From the timestamps, starting from the beginning to the end of the port, it
took ~3 days as per the git log (Apr 1 to Apr 4) but looking in detail at the
git timestamps, the actual time spent appears to only have been ~5-6 hours.

I guess that it helped that I used a script which automated much of the grunt
work - since it updated the "step" used in the stepfile at each incremental
step before running `make` and `git commit`ted the change on success.

The script was setup to exit when the `make` invocation failed so that it let
me intervene and fix up things manually whenever there was a failure. I feel
that the script definitely helped speed things up since it got rid of all of
the mundane work and allowed me to focus on just the new bugs that showed up.

Unfortunately, this port hit a speed bump while trying to integrate it back
into the existing regression test harness. Since this is an x86 32 bit port, I
first tried to compile a 32 bit x86 binary on my 64 bit laptop by using the
"-m32" option to cc but that failed with:
	/usr/bin/ld: cannot find crt1.o: No such file or directory
	/usr/bin/ld: cannot find crti.o: No such file or directory
in addition to even more errors about an inability to find libgcc

In an ideal world, the only thing needed to fix this is probably to run:
	`apt update ; apt install libc6:i386 libgcc1:i386`

Unfortunately, I'm running Ubuntu 16.04, a distro which is ancient and is no
longer supported since it is past it's 5 year LTS. So I can't install the newer
libraries using `apt`. I could upgrade to a newer Ubuntu distro but all of the
newer distros, after 16.04, need atleast 4 GB of memory which my ancient laptop
does not have and I'm definitely not going out to buy a newer laptop just to
continue on the treadmill of never ending software bloat which appears to have
become the hallmark of modern software. Do people even remember that we went to
the moon (and returned back, safely) using ~70KB ROM and ~2KB RAM? Sorry this
is turning into a rant, I just needed to vent.

For the record, I'll note that the changes required in the makefile to run into
the errors noted earlier was the addition of these directives in the makefile:
	ASFLAGS=-m32
	LDFLAGS=-m32

I made a half-hearted attempt to see if clang fared any better by setting
	CC=clang
in the makefile and it came up with an even longer list of missing libraries:
	/usr/bin/ld: cannot find crt1.o: No such file or directory
	/usr/bin/ld: cannot find crti.o: No such file or directory
	/usr/bin/ld: cannot find crtbegin.o: No such file or directory
	/usr/bin/ld: cannot find -lgcc
	/usr/bin/ld: cannot find -lgcc_s
	/usr/bin/ld: cannot find -lc
	/usr/bin/ld: cannot find -lgcc
	/usr/bin/ld: cannot find -lgcc_s
	/usr/bin/ld: cannot find crtend.o: No such file or directory
	/usr/bin/ld: cannot find crtn.o: No such file or directory

So now that I'm kind of stuck, I see a couple of choices to move forward.

My knee jerk choice is to ignore this issue by not adding the 32-bit build as
part of the regression test since I know that it was built and tested perfectly
fine on a 32 bit system, but that would be just be me trying to weasel out of
this stupid problem.

Another alternative given that I know that NixOS can run without any issues
on my ancient 32-bit laptop (with "only" 256MB of memory) would be to "upgrade"
my laptop from Ubuntu 16.04 to the latest version of Nix. But I don't want to
go through what appears to be an unnecessary hassle especially since this is
the "primary" system on which I do all of my coding and I don't know what other
problems will show up trying to do the upgrade to a completely alien distro.

Since both the available choices don't appear too palatable, I'm going to be
doing some more research trying to figure out what other solutions exist which
might include the less invasive option of giving one of the newer "Debian lite"
ISO images a whirl.

Since it is starting to get close to tax time though, that is the high priority
item on my todo list now, so I'll need to get that done before coming back to
see what I can do about this stupid mess.

For now I'm going to disable the regression test for the x86-32 port.

18 Apr '23
----------
I'm restarting from where I left off before tax time and spring break caused an
interruption to my regular schedule.

It did take a while to find a good solution to the cross compilation issue that
I'd mentioned in the previous JOURNAL entry but the solution that I've found
after all of the research done over the past couple of weeks is just too good
to be true so all of the time spent reading up stuff on various internet forums
(Stack Overflow, Ask Ubuntu, Reddit, etc) was well worth the effort.

I'll start off with some background: rather than try to solve the immediate
problem of figuring out how to run (or even build) 32 bit x86 binaries on an
x86_64 system, which I was struggling with earlier (documented in the previous
JOURNAL entry) I tried to find a solution to the older problem of how I could
go about testing other architectures on my laptop. That research turned up
QEMU user mode - I was aware of QEMU system emulation but QEMU user was new to
me.

So now that I'm no longer limited to just the older architectures supported by
SIMH or having to do the equivalent of "DIY emulation" using Unicorn (which in
turn is also layered over QEMU), I have the luxury of emulating ~43 different
architectures using QEMU directly from my laptop without much effort.

With that temporary resolution to the emulation problem out of the way, I could
then go back to figuring out how to do cross compilation for all of the various
architectures. The simplest (and quite possibly the absolute gem of a solution)
which is beautifully documented in Andrew Kelley's blog about `zig cc`[1]
[1] `zig cc` a Powerful Drop-In Replacement for GCC_Clang - Andrew Kelley.html
is: just use `zig cc`. Of course it does add a dependency on `zig` but in some
sense that may be a net win since, as Andrew points out in his blog, you are
trading in clang using ~380 MiB for zig using just ~45 MiB for what is vastly
more functionality. Note that using `zig cc` does come with a one-time cost in
terms of building out the cache the very first time a build is done.

I'm tempted to give zig - the language, a shot as well - especially since it
has the `comptime` feature which mirrors the equivalent functionality of Forth.

Some of the other options I looked before deciding on `zig cc` were:
1. A bunch of VM/container/schroot/chroot alternatives, each seemingly more
   complicated than the next.
2. `cargo cross` (which wouldn't work for me due to the `apt` dependencies
   mentioned in the previous entry, dated 05 Apr '23, of this JOURNAL)
3. `cargo test` using the target.triple.runner (rust only? though, I think)
4. Nix's pkgCross which I didn't investigate too deeply since it appears to be
   tied at the hip to nixpkgs (and the documentation wasn't too clear either)

20 Apr '23
----------
As I mentioned in the previous JOURNAL entry, although `zig cc` is currently
needed only to build and test the 32-bit x86 version on a 64-bit x86 system,
I'm going to start cautiously and see how `zig cc` fares on the plain old C
code in the `C` subdirectory before attempting more experiments with `zig cc`.

Another advantage to doing it this way is that I can use the `target` option
to generate code for other architectures easily (so I can have a look at the
assembly before doing the actual port).

I started off by running the usual regression test (running `./runallsteps C`),
and hit the first issue which was that zig (or more likely clang, under the
covers) allocates the variables at different locations compared to gcc. This
resulted in requiring changes to the `runallsteps` regression script. For the
most part the changes involved were:
	- run the regression script (until a failure is seen)
	- cd C ; objdump -dx ./forth_dict | grep 'vars$'
	- copy paste the address into the right place in the runallsteps script
	- rinse lather repeat
But this started getting old pretty fast so I decided to bring the memory tests
(starting at step 13) in parity with the x86 assembly versions by changing the
load address to use the memory contents of init but this failed as well since
`zig cc`/`clang` moves the locations of the functions around after each build
(likely to improve security by using ASLR).

After puzzling over this a bit, I ran objdump after compiling a couple of times
and tried to see if there were any addresses that remained unchanged between
the various runs and it appears that the only set of addresses that seem to
remain unchanged between runs are the following:
  SYMTAB               0x00000000002002e8
  STRTAB               0x0000000000200400
  GNU_HASH             0x00000000002003a8
  HASH                 0x00000000002003c8
  VERSYM               0x0000000000200378
  VERNEED              0x0000000000200384

For now I've just picked the very first address just to get this over with.

Since the only reason for having a "test" field in the "var" struct was to be
able to read it (using it's hardcoded address), that can now be removed.

One nice result of this exercise is that the regression test for C is much
simpler since all of the hardcoded constants that were stuck in there are now
eliminated and may actually make this portable to other systems without any
changes to the `fpp.config.C` configuration file.

Just to check for portability between zig/clang vs gcc I compared the objdump
between the zig generated binary and the gcc generated binary, and see that
they have no addresses in common at all, so this code will SEGV if it is
regression tested using gcc from step 13 onward. I could obviously solve that
by splitting the C directory into C-gcc (which keeps the current semantics) and
create something new, say C-zig-cc (to use zig cc), but I'm not going to bother
with that for now. Although portability is the driving force behind this code,
portability across CPU's, not compilers, is what I'm aiming for.

21 Apr '23
----------
Before moving on to focus on the remaining work, I decided to redo the earlier
comparison that I had done on 23 Mar '23 to include the `zig cc` results as
well. Since `zig cc` uses the newer clang version (zig cc --version reports
"clang version 16.0.1"), it gives me a chance to compare the latest clang
compiler version vs a gcc version from ~7 years ago vs hand written assembly
code performance.

The table below is a copy of the original table with the addition of another
column to track the performance of the binary generated using `zig cc`/clang
and all of the performance data is generated using `perf stat` as before.

.-----------------------------------------------------------------------.
| Metric		| GCC 5.3.1	| Assembly	| zig cc/clang	|
+-----------------------+---------------+---------------+---------------+
| Task-clock (msec)	| 4.439651	| 3.957470	| 2.886195	|
| CPUs utilized		| 0.884		| 0.861		| 0.831		|
| Cycles		| 9,969,446	| 8,866,091	| 6,435,679	|
| Instructions		| 10,365,760	| 6,413,838	| 8,338,773	|
| Insns per cycle	| 1.04		| 0.72		| 1.30		|
| Branches		| 2,374,783	| 1,734,081	| 1,297,254	|
| Branches M/sec	| 534.903	| 438.179	| 449.469	|
| Branch-misses		| 204,129	| 130,745	| 101,190	|
| % of all branches	| 8.60% (56.95%)| 7.54% (41.86%)| 7.80% (28.73%)|
| Time elapsed		| 0.005021309(s)| 0.004598909(s)| 0.003472718(s)|
'-----------------------------------------------------------------------'

So this time I can gracefully accept defeat at the hands of the latest compiler
since it has me beat on almost every metric except for the total number of
instructions executed (which I think is a proxy for how small the code can be).

BTW, this was using the -Oz optimization option to clang so I assume that the
only place compilers are still lagging (at least on x86, which I assume has
received the bulk of the optimizations), is in generating compact code compared
to what can be done manually. So I think there is still a reason to forge ahead
with my hobby project since I'm targeting it for resource constrained systems.

22 Apr '23
----------
Yesterday's journal entry about the large sizes of the generated binaries got
me wondering about why they need to be that large. For example, the size of
C/forth_dict generated using `zig cc -Oz` is ~31K/12K (before/after running
`strip` on the generated binary). The size of the code generated for x86-user,
which is generated from x86 assembly, but running in userland, is ~36K/14K
(again, the sizes listed are before/after strip'ing). Since these sizes are
~4-5x larger than the corresponding "baremetal" equivalents in x86/forth_dict
it makes sense to assume that all of that bloat is probably coming from the
libc/libgcc/libdl/crt* libraries.

These libraries are required for the support of start/exit and getchar/putchar.
So it sounds like I could try to shrink them down by coding to Linux's syscall
layer directly instead of using any of the higher level libraries. Obviously,
that comes with the risk of ABI changes that break that interface but since I
just need SYS_{exit,read,write}, 3 constants total, I think I can live a little
dangerously. I spent a fair bit of time researching how to do all that so I'm
going to turn that into yet another x86 port which I'll call x86-sys.

So that's what I'm going to be working on next. As a data point, the "step 0"
implementation using the syscall interface to just halt, clocks in at only 664
bytes compared to a minimal C/assembler code that needs more than ~10x that
size due to all of the libraries mentioned above.

25 Apr '23
----------
I was able to wrap up the x86-sys port also fairly quickly. It was completed in
just about ~2 days but it was possible to finish this up quickly only because
it was just yet another variation on one of the existing x86 ports - in this
case it was a mod of the x86-user port to create a standalone/freestanding
binary without any library dependencies, by directly calling into the Linux
syscall layer and thus continue to have it work in userland.

The overall size of the binary is now ~28K/8K (before/after running `strip`)
which is a savings of about 4KB on the strip'ed binary compared to the version
generated by `zig cc` (with the -Oz flag), which I think is significant since
adding in the libraries result in a ~50% increase in size.

One problem with using the syscall interface directly is that it results in a
measurable performance impact ; this implementation clocks in as the worst of
the bunch among all of the x86 ports as measured by `perf stat`. I assume this
is primarily because it is invoking syscalls which can be expensive, instead of
library calls, primarily for the putchar/getchar routines, which just cache the
data in file system buffers in memory and issues syscalls only to flush the
data, perhaps just once, at the end of the execution.

Here's a summary of the various x86 port variations that have been done so far:
16 bit real mode:
	x86	: using nasm (running baremetal, not even a BIOS)
	x86-as	: using GNU as (running baremetal, not even a BIOS)
32 bit:
	x86-32	: using GNU as (running on a 32-bit libc userland)
64 bit:
	x86-user: using GNU as, libc userland
	C	: using GCC -Os, libc userland
	C	: using zig cc -Oz, libc userland
	x86-sys	: GNU as, Linux syscall

With all of these x86 port variations out of the way, I think I'm going to give
x86 a rest (for real, this time) and move on to other architectures. So the
older decision of making a choice between SPARC and m68k is back on the table.

I'll take a look at trying to build and test them using cross-compilation using
`zig cc` (or any other available means if that runs into problems) along with
emulation using qemu-user (or any other available alternatives) and see how far
I can get.

27 Apr '23
----------
Although I keep declaring that I'm finished with x86, for real this time, there
seems to always be some new tiny little detail that crops up to remind me of
unfinished business.

Before starting out on using `zig cc` on SPARC or m68k, I wondered if it was
safer to try it out on the x86 assembly ports first. Since I was able to
successfully use it on the C port, it seemed sensible to try it on the x86-user
assembly port which is also 64 bit and can run natively. So I went ahead and
did that.

The very first issue that I ran into with switching to using `zig cc` from GCC
(or perhaps more correctly, gas) was that clang does not seem to be aware of
the "movsxd" instruction and errors out. I worked around that by switching it
to use the "movsbq" instruction instead, which had the nice effect of reducing
the code by one line.

After fixing that I ran into a really strange issue that took a while to debug.
It turns out that `zig cc` internally uses a cache but the .o object file from
assembling forth.S doesn't get marked as stale after the increment of each step
value done by the runallsteps regression script, probably due to all of the
preprocessing shenanigans that I do as part of the make. Rather than file a bug
against `zig cc`, since I'm unsure for now, about exactly who is at fault here,
I've just added a line in the runallsteps script to remove the stale entry
before each build.

Once I was past that, at step 13, there was the usual problem that the address
and value that are fetch'ed and compared need to be modified since `zig cc`
counts as a new "platform" on which this code is being run.

The final issue that I ran into was at step 50 where I consistently hit a segv.
This reminded of the earlier problem which I'd run into during the x86-sys port
which I'd fixed by bumping up the memory allocation and that fixed the issue
here as well.

With all of those bugs fixed, `./runallsteps x86-user` runs through all of the
62 steps successfully, regression testing each step along the way.

Thinking about next steps, a useful follow up to this exercise might be try out
`zig cc` for the 32 bit x86-32 assembly port as well so that I can enable
regression tests for x86-32, which are currently disabled (see my earlier entry
dated 5 Apr '23 for the reasons). Before venturing off into foreign lands by
trying to see how `zig cc` handles non-x86 architectures, it seems prudent to
check how a 32 bit x86 binary generated using `zig cc` fares on my 64 bit host.

29 Apr '23
----------
I managed to get `zig cc` to build 32 bit binaries on the x86-32 port so it can
now run natively on my 64-bit Ubuntu system. With this change, the x86-32 port,
which was the one outlier that wasn't part of the regression tests, can also
now be added to the set of ports which are regression tested.

For the record, this testing was done using `zig version`
	0.11.0-dev.2725+4374ce51b.

`zig targets` lists two targets for 32-bit: x86-linux-gnu and x86-linux-musl
these are listed under libc, which I assume means these targets are supported
on Linux using libc. Since I'm using an ancient version of Ubuntu which uses
glibc 2.23, my first attempt was to use the `x86-linux-gnu` target using:
	zig cc -target x86-linux-gnu
Although I was able to compile a binary, which is reported as having 32 bitness
	ELF 32-bit LSB executable, Intel 80386
(the above output was from `file`), it fails to run and even `strace` whines:
	execve("./a.out", ["./a.out"], [/* 30 vars */]) = -1 ENOENT

Rather than spend too much time debugging this, I decided to give the next
available option, which was the `x86-linux-musl` target a shot using:
	zig cc -target x86-linux-musl
This was able to successfully generate a 32 bit binary which was runnable.

From there, it was just a matter of removing the stale object from zig's cache
(just like I'd mentioned in the previous JOURNAL entry), and then changing the
ADDR and VALUE parameters in the `fpp` configuration file at step 13 and then
bumping up the memory allocation at step 24 (and again all the way to 2K at
step 62). With all of this sorted out, `./runallsteps x86-32` can now run to
completion through all 62 regression steps.

Despite my earlier claim that the 16-bit, 32-bit and 64-bit ports complete the
x86 porting landscape, I realized while working on this change that each of the
available APIs (such as baremetal, BIOS, UEFI, multiboot, various OS and
library combos) are all viable porting targets. But I think I've ported x86
enough times already so I'm going to give it a rest and move on from x86, for
real this time.

01 May '23
----------
I spent a fair bit of time trying to evaluate the list of architectures for
which `zig cc` can generate executables and making sure that qemu-user can then
actually run those binaries. So far, the tuples that work on my system are:
	(aarch64-linux-musl, qemu-aarch64)
	(mips64-linux-musl, qemu-mips64)
	(mipsel-linux-musl, qemu-mipsel)
	(mips-linux-musl, qemu-mips)
	(powerpc64le-linux-musl, qemu-ppc64le)
	(powerpc64-linux-musl, qemu-ppc64)
	(powerpc-linux-musl, qemu-ppc64abi32)
	(riscv64-linux-gnu, qemu-riscv64)
Note that neither of the two architectures that I had planned for the next port
(SPARC and Motorola 68000) are on this list so it looks like I will have to
carry on without the support of all of the cross platform goodness of `zig cc`
despite the fact that `zig targets | egrep -i 'sparc|m68k'` shows plenty of
matches so it looks like things aren't working quite as advertised yet.

I'm using a fairly recent version of zig (0.11.0-dev.2725+4374ce51b) so I'm not
holding out hope that pulling in a newer version will magically add in this
support. Since zig internally depends on clang/llvm I took a look at what is
supported in there and can see that although SPARC support exists, the Motorola
68000 appears to have fallen by the wayside. So that helped me make up my mind
- I'm going to choose the m68k architecture for porting, especially since it is
the older architecture.

Binutils, (which I had used earlier for the PDP11 port) appears to have support
for assembling and linking m68k binaries and qemu-m68k can be used to run the
userland emulation of the generated binaries so that will be my toolchain of
choice despite the fact that I'm adding yet another external dependency. `simh`
which was used for the PDP11 emulation does not seem to have support for m68k
although the code base has some references to m68k as part of the emulation for
`sage`. Given how slow the pdp11 emulation using simh is though, I want to see
if qemu performs better/faster.

For looking up information about opcodes and instruction sets, I'll be using my
trusty old "Computer Organization" textbook (see the earlier mention in the
JOURNAL entry dated 30 Nov '22). Unlike the x86 ports where I could liberally
borrow code between ports, most of the native code will need to be written
from scratch so it will give a good measure of how long a "real" port takes.

Just as before, I'll go mostly radio silent (see JOURNAL entry dated 17 Mar 23)
until this port is complete unless something very technical needs to be talked
about.

09 May '23
----------
This entry marks the completion of the Motorola 68000 `m68k` port. It needed
almost a week because of some bugs that I hit along the way and also due to the
fact that this is the first port to a big-endian architecture. One thing that I
realized over the course of this port is that I need some kind of a porting
guide since it is hard to remember various minutiae which I keep rediscovering
when I run into bugs as part of the porting exercise. So I'll work on that next
and add that information to the PORTING file. Since a file called PORTING was
already created a while back and contains stuff that seems to belong to this
JOURNAL, I've moved those contents over to this file and added it as the very
first JOURNAL entry.

10 May '23
----------
Now that the m68k port has been successfully completed with a solution for big
endianness, I'm curious to see if a SPARC port (which is also big endian)
becomes easier. So I think that's just what I'm going to set out to answer.

Historically, SPARC microprocessors have usually been used only in high end
"enterprise" gear which are in most cases filled to their gills with RAM. Even
back in 2010, I think I worked on a system with ~1TB of main memory. So it is
reasonable to ask if it makes much sense in porting this tiny little project
which is meant to run on resource constrained systems to SPARC. Luckily, I'm
beholden to no one else and only answerable to me, myself and I on this issue
and so my thinking on this is to "just do it".

Nevertheless it is meaningful to ask: is this SPARC port going to be useful to
anyone at all? I assume the answer is: No. The followup question then is:
Am I going to do it anyway? And the answer to that is: Yes, of course!

I'll try to see how far I can get without referring to the ISA manuals, using
only the assembly code generated by clang as my guide. I think I must have
worked on SPARC for a little under 2 decades over the course of my career at
Sun Microsystems so although it has been more than a decade since I even looked
at or touched any SPARC code, my hope is that the memory refresh from looking
at the generated assembly will be sufficient to carry me through without having
to go through the architecture manuals.

For building the binaries, as I mentioned in the 01 May '23 JOURNAL entry, zig
is not going to be of much use. So I'll have to stick to old faithful binutils.
As in the case of the m68k port, QEMU(qemu-sparc) will be used for testing.

Just as before, I'll go mostly radio silent (see JOURNAL entry dated 17 Mar 23)
until this port is complete unless something very technical needs to be talked
about.

17 May '23
----------
This entry marks the conclusion of the SPARC port. Like the m68k port, this one
also took about a week. I'll use this as an opportunity to go over some of the
bugs that I ran into.

The latest one, and the one that took me almost a couple of hours today was in
the implementation of `stick`. Unlike the earlier architectures, I couldn't
just fall through to invoking `store` since there was a bit of pointer aliasing
that screwed things up. The implementation of `enter`/`exit` also took a bit of
time to get working since I got the ordering of the increment/decrement pairs
incorrect. And having things in the delay slot obviously makes code invisible!

Another such bug that took me a while to figure out was in using the opcode to
set a flag in the delay slot of a conditional branch. Despite my resolution to
not look at the SPARC Architecture manual, (see the previous JOURNAL entry for
the reason for that piece of masochism), I had to go looking for those details
in the manual for what happens in that particular case but eventually decided
to just write the code in as simple a way as possible since I didn't want to
spend even more time debugging.

Anyway, coding in assembly can be pretty brutal and unforgiving, despite the
fact that I'm not even dealing with the really difficult stuff, so I just can't
wait for our new GPT overlords to do their thing and make this easier. I guess
we will all see soon enough see whether all of that is really going to pan out.

Looking back at the older bugs/design choices, I spent a fair bit of time on
`lit`, agonizing over whether I should enforce alignment (at 4 bytes/2 bytes)
and ultimately settled on assuming that there were no alignment guarantees so
I read the data a byte at a time so I expect that will have performance impacts
but none of this code is meant for performance so it might be mediocre at best.

One constant source of irritation during this port was the rework that needed
to be done every time that the 256 byte primitive area became full and this was
happening for almost each one of the primitives that was added. In hindsight, I
should have just chosen to use a different scheme since the opcode is uniformly
4 bytes wide. If I were to redo this, I might choose an implementation closer
to the PDP11 scheme instead of the current version.

In my mind though, the primary purpose of this port was mostly to see if the
big-endian changes done for m68k were sufficient for other ports and it appears
that it has successfully met that requirement since I now have 2 big-endian CPU
ports under my belt.

Looking back at the landscape I've covered so far, it spans 16/32/64 bit CPUs
and also little and big-endian architectures. So the obvious missing piece is a
port to an 8-bit architecture (and it makes sense that those CPUs will be the
primary niche that this project attempts to cater to anyway given that they are
the ones that are the most resource constrained), so I think I'll pick one of
them next. Z80, perhaps?

19 May '23
----------
Before I can start on a port, I need three essential tools:
	(1) Something to build the binaries ie build tools
	(2) Something to test the generated binaries (ie emulator/simulator)
	(3) Documentation about the target ISA

For the Z80, I started looking for an emulator first since it turns out that
of the seemingly endless number of systems that QEMU supports, the Z80 is,
surprisingly enough, not one of them.

Searching for other open source Z80 emulators that work on Linux brought up a
lot of choices both for emulators and the build systems around it:
  yaze/MAME/z80e/z88dk/z80emu/z80pack etc and a bunch of suggestions centered
around running CP/M or Fuse/Speccy and using that as the development system.

There was also a Hackaday link to Uzi/Fuzix to get Unix running on a Z80 which
didn't sound as appetizing as running say, Turbo Pascal (1.0, 2.0?) on CP/M as
the development environment. Now, that would be a real trip down memory lane.

The one that the internet search engines don't seem to be able to find despite
all their much vaunted AI intelligence, is the sdcc/ucsim combination which I'm
aware of from previous usage. I particularly prefer this combination since it
comes with a C compiler (even if I don't currently need it). So I'm going to
start off with that. To summarize, the tools that I'll be using are:
	- "sdcc -mz80" for turning C into Z80 binaries
	- "sdasz80" for turning Z80 assembly into Z80 binaries
	- "sz80" for emulating Z80 binaries generated using the above tools

The versions of the above tools that I'm using are:
	- SDCC : mcs51/z80/z180/r2k/r2ka/r3ka/sm83/tlcs90/ez80_z80/z80n/ds390/TININative/ds400/hc08/s08/stm8/pdk13/pdk14/pdk15/mos6502 4.2.0 #13081 (Linux)
	- sdas Assembler V02.00 + NoICE + SDCC mods  (Zilog Z80 / Hitachi HD64180 / ZX-Next / eZ80)
	- sdld Linker V03.00 + NoICE + sdld
	- uCsim 0.5.4

For documentation about the Z80, I'm starting to dust off and leaf through my
ancient Z80 book "Z80 Assembly Language Programming" by Lance A. Leventhal.
Strangely enough, this book doesn't have overall page numbers, just per chapter
page numbers and since the chapter on the instruction set is ~170 pages, I'll
estimate that I'll have to do a quick browse through atleast half of it to look
at the stuff relevant to my work and also refresh my memory about the Z80 in
general. Just like my trusty old "Computer Organization" textbook (see my
earlier mention in the JOURNAL entry dated 30 Nov '22), I've carried this book
with me for well over 30 years so I might as well put it to some use now.
The back page has the store keepers note about the price of the book: $5.95
(I'll assume it is Singapore $, since it is the Asian edition) and I bought it
for Indian Rs 81.50, which in my student days, would have paid for a couple of
months of lunch. I'll always be ever grateful to my parents for spending their
hard earned money to buy these books and for everything they have done for me.

Thank you Apai & Mom! :RIP: :heart:

22 May '23
----------
As with the earlier ports, I'm continuing to take on even more $TECHDEBT by
copying the genrom and genprims scripts for yet another port. For now I've used
the sparc version as the template since that's the latest I have. genrom needed
to be modified from the sparc version but the genprims code was kept as is. The
makefile is also a heavily modified copy of the sparc version. fpp.config.z80
is also a copy from the sparc version since I don't plan to change the THREAD
model but since this is a step down from 32 bits to an 8 bit architecture, many
other changes may be necessary in the future.

Unlike qemu, since the success criteria that the sdcc/ucsim emulator uses for
termination is unclear, I've used a `grep` to check for successful termination
just as I'd done earlier for the PDP11 port.

26 May '23
----------
I got stuck for a while with sdcc/ucsim trying to figure out how to redirect
the emit/key output/input to/from named files since those are the necessary
beginning baby steps of any new porting exercise. In my quick look through the
docs, the information in simif.html appears to make it clear that doing the
redirection should be trivial, but for the life of me I couldn't find code
samples searching for it on the internet or any clear description of what
exactly needed to be done to get it to work.

I was now at a fork in the road, and my choices were to either continue with
sdcc/ucsim or choose one of the zillion other implementations of Z80 emulators
that an internet search surfaces. Given the lack of adequate documentation in
sdcc/ucsim, I decided to do a survey of the Z80 emulation landscape. My first
stop was to see if a port of qemu user for the Z80 exists since I had used QEMU
earlier for both the m68k and SPARC ports. It looks like there is a Z80 port
but it appears to still be work in progress and has not been merged upstream so
I decided to give that a pass. From all the research that I had done as part of
that work, I found that the simplest approach might be to roll out yet another
wrapper over libz80 and call it a day. But that approach also needed a package
that could assemble the Z80 code and since I was using sdcc for that I finally
decided to revisit ucsim again, but not before giving a once over for a bunch
of other choices: z88dk, z80pack, iz80 in Rust and z80emu in zig

Like sdcc/ucsim the z88dk package also comes complete with a compiler (zcc) but
it appeared to be a wrapper over sdcc so I was afraid I'd have the same issues
with ucsim that I was running into. Yet another option I evaluated was z80pack
which comes with an assembler and simulator bundled together just like sdcc. It
also has a simple test that shows how to redirect to stdin/stdout but like lz80
it is a "roll your own Z80 CPU" solution.

Wandering farther out, I also took a cursory glance at the Rust cargo module
iz80 which has the nice property that it could be built without any external
dependencies and which comes with code samples that are easily understandable
along with the emulator for a simple CPU (which they have called "cpuville"). I
was extremely tempted to roll with the iz80 solution except for the fact that
the compile times were occasionally pretty glacial - sometimes even slower than
the simh/pdp11 emulator which is currently the long pole in the tests. So I
reluctantly decided to put that off for later consideration since, like the
libz80 solution, it also has the requirement of needing a separate package for
the Z80 assembler.

There are some solutions out there that are based on zig as well but those seem
to be based on an out of date version (0.6.0) and I didn't want to add yet
another zig dependency especially to an out of date version which no longer
builds with the current version(0.11.0). Just like the libz80 and the Rust iz80
implementations, the zig version also will need an additional package for the
Z80 assembler.

In the meantime, I had the additional distraction of getting a copy of Samuel
Butler's translation of Homer's Illiad and Odyssey so I spent a bunch of time
reading that in the middle of the analysis paralysis induced by the plethora of
available choices for the Z80 emulation.

The conclusion that I reached after about a week of surveying the Z80 landscape
while taking a crash course on Greek mythology (funnily enough, about a guy who
keeps getting carried away from his destination), was that I should just bite
the bullet and stick to sdcc/ucsim and perhaps just grovel through the source
code to figure out how to get putchar/getchar working with file redirection.

The sdcc/ucsim code is in C++, which is a language that I detest, for the
really simple (and probably inane) reason that the language reference clocks in
at thousands of pages: 2000 and counting when I last looked at it, so my
preferred language for low level stuff is C, which I think I can comfortably
hold in my head, without even really trying.

But life is what it is so I had to convince myself to go ahead and just hold my
nose long enough to browse through the C++ ucsim code and figure out how to get
the putchar/getchar with file redirection working. After a week of digressions
into looking at a bunch of other solutions, among other g(r)eeky distractions,
I've decided to stick to my original approach and continue with sdcc/ucsim, for
now at least, since I finally have something that works to show for all of the
effort that I put into it. I'm not sure if the time I spent on this research
should be counted as "wasted" or "learning" though.

29 May '23
----------
Now that the z80 assembly code implementation and the z80-c version coded in C
have reached "step 4 feature parity", it is as good a time as any to do a quick
code space utilization comparison. The assembly version clocks in at 0x73 bytes
while the C version needs all of 0x156 bytes which is almost a savings of ~3x
for coding it in assembly. Despite the fact that the Z80 assembly code feels a
lot like grunt work, it seems like it is meaningful to keep working on it.

In any case, now that I've picked up steam on the Z80 C porting exercise, I
could try keeping parity at each step between the two implementations. My hope
is that much of the x86 C code can be used as is. But since I'm afraid that the
context switch between the assembly and C for each step might be high, my plan
is to go full bore on the C implementation first since that is the easy path
and then after that is complete, I can revisit the version in assembly.

08 Jun '23
----------
Between hosting visitors, attending various anniversary parties and the start
of my kid's summer vacation I had enough distractions to keep me from making
progress for almost a week.

Anyway, after spending a fair bit of time trying to figure out the failure that
was happening at step 44, I was able to track things down to configuration file
changes that I had not changed after copy pasting them from the older C config.

The first bug that was that CELL was set to 8 which was a holdover from the
initial port to C which was implemented on x86_64 which uses 8 bytes. In the
case of sdcc/z80, that needs to be trimmed down to 2.

The next bug was that LITC was set to 4 and that needed to be bumped down to 2
as well, but while looking through the code under THREAD==3, I realized that
in my hurry to get the C port completed, I'd left a lot of hardcoded footguns
behind which are going to blow up in my face as this port progresses.

I guess it is time for all of that $TECHDEBT to be repaid, with interest, now.

26 Jun '23
----------
Completing the z80 assembly code port took much longer than I ever expected.
Some of that delay was obviously due to bugs slowing me down but the major part
of it was due to various distractions. Everyone is on their summer break and
obviously that comes with its share of distractions - who wants to sit in front
of the computer debugging when Half Moon Bay is belting out its siren songs! ;)

After taking a break of about a week, I restarted work on the z80 assembly port
in earnest on Jun 15, and I was able to make fairly rapid progress until I hit
a very weird bug at step 39 which turned out to be a bug in the implementation
of `c!` (the implementation of which was done all the way back at step 15)
where the stack wasn't being popped which resulted in a stack overflow. Running
a regression test at that step resulted in an all new failure at step 26 which
was very laboriously tracked down to the fact that `key` was not clearing the
high byte. Unlike my usual knee-jerk response of using `printf` debugging, (or
the Forth equivalent of `emit` based debugging), I actually used ucsim/sz80's
neat data breakpoint facility by running: `break rom r 0x42D` followed by `run`
which was all I needed to get to the point of failure and then single stepping
the rest of the way while keeping an eye on the registers after each step was
enough to troubleshoot and figure out this bug.

The next bug after that was at step 40 where atoi was not turning "1000 " into
0x03E8 - instead, using ucsim single stepping after breaking at read access
to 0x5C6, I saw it was getting 0xE8. Since the only thing that couldn't have
been working here was the `<<` operator, I could figure out the bug without
much difficulty and figured out a bug fix which went into `shiftleft`. I'm
unsure though if this was an actual bug caused by my misunderstanding of the
diagrams in the book or if this is a bug in ucsim which should not happen on
"real hardware" which works as per the diagrams in the book. In any case, the
new fix should work in all cases.

The next bug to pop up was at step 44 but then various social engagements were
taking priority resulting in a delay of yet another week before I could get
around to getting that fixed. Since that bug was in the code generation scripts
it was mostly a lucky break that I noticed that the .lst files contained the
wrong offset due to using the wrong subtrahend (`next`, instead of `cold`) and
with that fix out of the way, the rest of the steps were polished off in a
matter of minutes.

As usual, since I have a compiled version as well as the hand crafted version,
it is straightforward to make comparisons between the two. The SDCC generated
code takes ~1600 bytes while the hand coded version needs just ~500 bytes of
code (ie the compiler generated code is ~3x larger). Running it under the ucsim
emulator shows that the running time reported is also about ~3x larger (~15 sec
vs ~5 sec). So for resource constrained devices, it may still make sense to
craft things by hand. The nice advantage of using SDCC though, is that the code
is now portable to every CPU that SDCC supports. So if ROM/RAM resources are
not a constraint, I should be able to have ports for all of those architectures
with almost no effort. Running `sdcc --version` reports support for the
following architectures so I think I'll try each of them in turn next:
mcs51/z80/z180/r2k/r2ka/r3ka/sm83/tlcs90/ez80_z80/z80n/ds390/TININative/ds400/
hc08/s08/stm8/pdk13/pdk14/pdk15/mos6502

27 Jun '23
----------
I decided to give the "z80 adjacent" processors that sdcc supports a whirl
first before moving on to other architectures. Experimenting with the z180
option to sdcc gives me a working port so I'll chalk that up as yet another
working port. Since I didn't need to make any changes to any of the files
except the makefiles, I've added them in as symlinks rather than as copies
and git appears to be able to handle that without any problems, so far.

A recompile using `sdcc -mz80n` also worked without any problems. So I'll
chalk that up as yet another port.

28 Jun '23
----------
One thing I forgot to mention while finishing up the z80n port was that the
ZX Spectrum was one of the first computers that I ever had access to. My uncle,
Paul had bought it in Dubai where he had worked in Sony and brought it with him
during one of his vacations (this was in the late 80's I think). I remember
typing in computer games from a book and playing them and trying to save them
to audio cassettes to avoid having to type them in all over again the next time
around. This was on a 48KB system, I think.

More important than the games themselves was the Forth manual of a version of
Forth (from ID Software?) which came in a tiny book written in a tiny font
which was my introduction to Forth. I taught myself Forth by poring over that
manual just as I had taught myself BASIC by typing in games.

During the course of my engineering classes (again this was in the late 80's),
I got an opportunity to implement a Forth interpreter during my final semester.
I had implemented a Lisp interpreter before this during the 6'th semester, so
it was interesting to see the differences in the difficulty of implementation
between two "little languages" that have had an outsized influence on the world

So that concludes my trip down memory lane which gives some context for how I
got started on my journey with Forth, all thanks to my uncle bringing home a
computer which was a new fangled thing at that time. Thank you, Paul Uncle!

So, what about my current journey with "romforth"?

While I could continue with the busywork of "porting" to even more of the
architectures supported by SDCC, I've decided to give that tangent a rest and
focus on something that is more interesting to me.

Going over the initial list of targets that I'd listed at the beginning of this
project, I see that the remaining ones on the list that are not yet done are:
(the below list is a copy/paste+edited list from the 04 Nov 2022 JOURNAL entry)
- MIX (Knuth's Ye Olde Computer)
- 8085 (or was it an 8080? not sure anymore - a box with keypad for m/c code)
- MSP430 (TI dev board)
- ARM (ST's STM discovery board)
- RISC-V (just because it is the new hotness)

MIX is clunky and outdated and probably consigned to the junk heap of history
to be replaced by MMIX, so I may only take a look at it later, as time permits.

The 8080 is just an underpowered Z80, for most intents and purposes, so I think
I'll give that also a pass since the Z80 is pretty well covered by the assembly
and sdcc/C ports.

So the next one down that list brings me to the MSP430 and I guess that is
enough reason to make it the one I'll work on next.

I'd purchased an MSP430 "Launchpad dev kit" for $4.30 (cute marketing, TI guys)
almost 10 years ago. It promptly went on a shelf soon after I got it since it
needed boatloads of "developer kit software blobs" which involved downloading
gigabytes of software to a Windows box. Those logistical difficulties with
trying to do something as simple as blink an LED on that board triggered the
entire raison'd etre for romforth (but see also the RATIONALE file).

Things have become more civilized over the past decade and msp430-gcc exists
as does mspdebug both of which work fine on Linux. So if all I wanted to do
was blink the LED on the board, I should be able to do it without booting up
the Windows partition or downloading gigabytes of TI MSP specific build kits.

But now my sights are set beyond just blinking the LED and I want to see if
romforth will be able to fit the constraints of these relatively popular chips.
Since I have real hardware to run it on, this will be the first port which can
be truthfully declared to run baremetal, as opposed to running "baremetal, but
on an emulator".

The MSP430 Launchpad developer kit came with 2 included CPUs: MSP430G2231IN14
and MSP430G2211IN14. Both have 2KB ROM, 128 byte RAM, 10GPIO pins, 1x16 bit
timer, among various other peripherals. The MSP430G2231 has a 10 bit ADC which
the MSP430G2211 doesn't have.

Searching for an existing version of Forth which runs on the MSP430 led me to
CamelForth but the Readme says: "CamelForth should also be adaptable to any
MSP430 device having at least 512 bytes of RAM, 8K of ROM, and one USART/USCI"
Given the smaller ROM and RAM constraints for the microcontroller that I have,
 it is clear that CamelForth won't be able to work on it, as is.

Rather than try to shrink fit CamelForth, I'm going to take on the challenge of
trying to get romforth to work on the two MSP430 CPUs that I have. As usual,
I'll start off by doing a survey of the existing build and emulation tools that
are available that can be shoehorned into the existing build framework so that
I can run things under emulation before moving to real hardware.

01 Jul '23
----------
I wasn't too successful trying to build an MSP430 binary using the msp430-gcc
compiler since it needs other support files (memory.x and periph.x) which don't
appear to be installed on my system. Trying a couple of variations for the
`-target msp430-freestanding` option to clang didn't go anywhere since it
complained about a missing crt0.o and that led me to try zig with `-target
msp430-freestanding` but that failed (error: unknown target CPU 'generic') and
since the MSP430 is at the bottom of the support list for Zig, I'll assume that
I need to stick to msp430-gcc.

So while I'm researching msp430-gcc some more, I tried to see if the binutils
support for MSP430 would "just work" and it did, so for the very first step of
this port, I'm just using binutils but that comes with its own set of quirks.

Since I'm trying to keep things as simple as possible and not use a linker
script, the msp430-elf-ld linker sticks the code at 0x8000 by default. So for
the emulation I need to explicitly set the PC to that address. Also, since
there is no halt or other exit mechanism I've chosen the clunky hack of setting
a breakpoint and exiting when that breakpoint is hit within mspdebug. And
talking about emulation, I did find a qemu port for the MSP at:
	github.com/draperlaboratory/qemu-msp
but I ran into difficulties trying to build it so I've moved on with just using
mspdebug which could be easily built from the source.

All these build/test issues are a reminder to me of why people just stick to
their one favorite microcontroller and never move from their winning combo
especially if they have the hardware and software fully debugged and working.

07 Jul '23
----------
After a bunch of research I finally figured out that the memory.x and periph.x
files that msp430-gcc was looking for during compilation are in the `msp430mcu`
package. Although that package was installed, msp430-gcc cannot know which
target device you are compiling for unless it is specified explicitly and since
I couldn't quite figure out what options to use to specify the directory, for
now, I've just hardcoded the path by symlinking the two files directly. So this
may work only on ubuntu (or any other debian flavor distro) and I'll need to
fix this up later. Anyway, with that issue out of the way, I was successfully
able to build an MSP430 binary using msp430-gcc so I've changed the makefile to
use the msp430-gcc compiler instead of binutils.

Given the architectural similarities and how close the instruction set of the
MSP430 is to the PDP11, it makes sense to use the same threading type that was
used for the PDP11 for this port. I'm a bit worried that it will result in a
larger footprint which may not fit into the small 2KB ROM of the MSP430
microcontrollers that I have. I'll worry about that problem when I get there,
so for now I've gone ahead and used a copy of the PDP11 genrom script with some
mods to make it work within the current build scheme.

13 Jul '23
----------
Figuring out how to get simulated input working on the console took a while.

Since I couldn't get github.com/draperlaboratory/qemu-msp to even build due to
build dependency hell on the ancient Ubuntu distro that I run on my laptop, I
was left with no choice but to figure out a way to get console input working on
mspdebug. For now, I've gone ahead and patched the mspdebug code to be able to
handle input from the console. Console output using simio is supported (by
default) in mspdebug so that didn't need any special handling (well, except for
actually figuring out how to enable it using the simio commands).

The commands to enable input on the console are structured almost identically
to that for output. The forked version of mspdebug with support for console
input (via simio) will be uploaded to https://github.com/romforth/mspdebug

I'll also need to figure out how to send a pull request to
	https://github.com/dlbeer/mspdebug
from which this code has been forked. This will be my first pull request on
github since this is first time I've had to change any code that I've cloned
from github.

18 Jul '23
----------
I struggled my way through some design mistakes and then some coding mistakes
but I think I finally have an acceptable implementation for invoking defined
words.

For the call/return linkage, I've decided to use an additional register R9 so
that I can skimp on the bytes required to encode "call linkage" from 4 to 2.

The linkage itself just uses the call instruction to push the next ip on the
data stack and this is restored by the code in "linkage" which first saves the
current ip on the return stack. Symmetrically, the return stack is then unwound
by the code in "return". This design is the same as the one I used on the PDP11

The lack of post increment addressing modes for the destination register in the
MSP430 (and pre/post decrement addressing modes as well), considering that it
is in the lineage of the PDP11 seems to be a tad disappointing. I guess there
must have been various tradeoffs involved when these decisions were being made
at the CPU architecture level, but ultimately it boils down to yet another case
of why "we can't have nice things".

19 Jul '23
----------
While trying to implement `call` for the MSP430, I ran into a pretty weird bug
and after some debugging found that the data segment initialization code had an
off-by-one bug. Fixing that gives me a working call implementation as well.

Things went rather smoothly after that until at step 27 I hit two issues. The
first problem was that the code has grown enough that a 512 byte jump offset
used in the MSP430 instruction encoding is no longer sufficient. So I recoded
the jump into a call with the corresponding followup adjustments that became
necessary to deal with that modification. With that out of the way I then hit
the second problem which was a failure at step 27 which I debugged to the fact
that key was not saving the tos before clobbering it with a new value. While I
was there I fixed the corresponding bug in emit as well so it now drops the tos
after it has printed it. I have a memory of having run into this bug some time
before this as part of some other port so I think I'll fix up the early tests
for key/emit to catch this much sooner. Since this set of changes is fairly big
enough already, I'll do that next as a separate commit.

20 Jul '23
----------
At step 43 I found out (the hard way, again) that `here` needs to be the last
of the variables defined in code.prims since the tests in step 43 assert that.
I wasted a bunch of time debugging this since it was overshadowed by a couple
of other problems. I'll defer describing all of that investigation until I get
to commit those changes.

26 Jul '23
----------
There was yet another long delay caused by a pretty confusing bug at step 46
which turned out to be partly due to a disconnect between the config values
specified in the fpp.config.* files vs the code generated by genprims/genrom.

Part of the reason for the disconnect is that I started with the genrom script
for SPARC since it is the newest port. Although the MSP430 port is technically
a clone of the PDP11 port, I didn't want to use that genrom script since it was
the older port and I wasn't too sure of how much of it was out of date.

Since the genrom script was SPARC based, I decided to keep the configuration
parameters also initially based on the SPARC equivalents, so that they were
consistent and I've been switching them over to the PDP11 values whenever I ran
into bugs along the way that were caused by differences in the "world view".

So when I hit the test failure at step 46, my initial conclusion was that it
was again due to this disconnect between the configuration parameters. Checking
the diffs between the fpp.config for the current MSP430 port and PDP11, it was
clear that the THREAD'ing model needed to be changed from SPARC's type 3
to PDP11's type 2. The other significant differences I could see were these:

< ARCH="msp430"
> ARCH="PDP11"

< prim_var_deref=1
> prim_var_deref=0

< RSTKSZ=60
> RSTKSZ=30

< ALIGN=0
> ALIGN=1

< PRIMSZ=1
> PRIMSZ=2

I assumed I could hold off on the diffs for ALIGN and PRIMSZ, at least at this
step. Since RSTKSZ is larger than the PDP version, it shouldn't matter so the
only change that seemed to be required at this step was to switch the value of
prim_var_deref. Now, prim_var_deref was a band-aid which was added during the
C port. I later realized that despite being a hack, it was in some sense the
right way to handle variables. So I've been using prim_var_deref=1 for all the
later ports as well. So it seems prudent to see if prim_var_deref=1 will also
work for the PDP11. Unfortunately this tickled a bug at step 44 while testing
for any regressions in PDP11 after the change and so I decided to cleanup the
cfaexec definition (to be "more correct") and that was when I realized that I'd
opened up a whole new can of worms.

My choices at this point are to keep the old ports ie the ones coded prior to
the prim_var_deref=1 change which currently are the x86, x86-as and PDP11 ports
"as is" or drag them in to the new scheme of things and get rid of the config
value "prim_var_deref" which will result in one less thing to worry about for
future ports. For now I've decided to leave things as they are until I've
finished up the MSP430 port and then I can revisit this mess later.

So now that I'm sticking to prim_var_deref=1 for the MSP430 port as well, it
was time to debug the step 46 failure on the MSP430 in earnest.

After a bunch of stepping through the code using mspdebug, it became clear that
choosing to call the new THREAD'ing type 2 after the PDP11 port when the actual
implementation is subtly different was not a good idea after all.

This meant that the places which "call" the subroutines now need to be
modified. So I had to go back in and modify all the places (mostly the multiple
implementations of repl in defs.4th) to deal with this.

I'm a bit afraid that I'm setting up a footgun by calling both implementations
"THREAD=2" when they are subtly different but I'll wait and see if trouble
ensues from this choice in the future due to this $TECHDEBT.

Since this change involved changes to common code, I went ahead and ran the
full regression test which tickled what seems to be an existing bug in the
regression tests for x86-32 because zig is stricter than the all the other
C compilers in flagging a constant that is too large to fit as an error rather
than as a warning. So I fixed that first as a separate commit prior to making
this set of changes. The current set of changes passes all the regression tests
so other than the confusion that may ensue in the future, I'm willing to go
ahead with this for now and review the bigger picture later.

31 Jul '23
----------
At step 51 I ran into yet another weird bug which took a bit of effort to
debug. My preferred debug methodology is "printf based debugging" (I assume
that's what it is called nowadays) which just means that you sprinkle printfs
(or emits in this case) and try to figure out what is going on. For debugging
the earlier bugs, I have switched between this approach and using breakpoints
and/or step based debugging using mspdebug. To keep the codebase clean, I've
typically removed the debug code after each debug session but this is getting
a bit tiresome so for now I've decided to leave it all in there under a debug
flag. This particular type of debug coding used to be called "scaffolding debug
statements" but I've not seen it used anywhere nowadays so I assume it may
have fallen out of fashion.

The first issue that I ran into after adding the debug prints was that the
output from '.' (which is a copy paste of the code in rest.inp) appeared to be
incorrect and this turned out to be an existing bug in the implementation of
<< and >> when the shift value is 0. So I fixed that as part of the debug
changes.

Note: All of the debug code and fix for << and >> was merged in the previous
commit.

After fixing that, I then dug in trying to root cause the actual problem at
step 51. Running mspdebug to step through the code showed that the call to
defexec which was added in step 51 ended up trying to run code at 0xffff and
from there to address 0. In mspdebug 0xffff is an indication of uninitialized
code and this uninitialized code was in the body of "bar".

For further debugging, I enabled debug=1 in fpp.config.msp430, then ran make
and looked at the output in test.out. The tail end of the generated output
(with the current set of scaffolding debug prints in place) showed this:

bar|alloc 0x4048 cr1 0x4042 cr2 0x404C  0x1289 ,|alloc 0x404E  0xD130 ,|alloc
0x4001 bar|find 0x404C

This shows that the body of "bar" is being filled out with the call prefix
"0x1289" which is added to the dictionary at 0x404E which appears to be as
expected. But after that, the addition of exit/"0xD130" goes sideways since
the allocation for storing it is at address 0x4001 instead of the expected
(0x404E + 2) == 0x4050 address. Due to this the body of "bar" wasn't filled out
correctly since it only got the call prefix and nothing else so that when "bar'
was defexec'ed, control flow went off into the weeds.

So it looked like alloc returned the wrong address and my speculation was that
this was due to some corruption that was happening to the content of "here".

Looking at the objdump of the binary and searching for the address of 'here'
showed that it was placed at address 0x203. My spidey senses immediately
started tingling and I assumed that this was yet another case of alignment
issues. Sure enough, after swapping the positions of "here" and "state" things
are working again. Whew! I guess looking at the objdump was a lucky break that
helped avoid a much longer and laborious debug exercise.

01 Aug '23
----------
This entry marks the conclusion of the MSP430 port. Unlike some of the earlier
ports, for eg: the SPARC and m68k, which were completed in short weekly bursts,
this one turned into a long hard slog that took nearly a month to complete just
like the Z80 port. I think part of the reason for the slow progress is that it
is still summer vacation time, and that of course comes with its fair share of
distractions but I think the real reason was the introduction of yet another
THREAD'ing type which reuses PDP11's THREAD type of 2 but which is in many ways
subtly different because of the additional prim_var_deref=1 configuration.

Although I got it working, the code, especially the grungy parts, are starting
to look really ugly and I'm tempted to try to see if I can clean them up since
it felt like reading and modifying the code was a fair bit of struggle for each
of the bugs that I ran into. Given the vacation vibe, it was easy to slip into
doing something else instead of continuing to struggle with each bug as it
popped up. Averaging over all of the ports that have been completed so far, an
estimate of 2-4 weeks for a port still seems to hold and this port also falls
within that envelope.

Anyway, now that I have yet another port under my belt, the usual question of
"what next" pops up. Although I've been tagging the "emulator tested" ports as
"Baremetal", so far none of the ports has been tested on actual hardware.

Since this port is done and since I have the MSP430 Launchpad dev kit on hand
(for almost a decade now, actually), this is as good a time as any to try it
out on real hardware. Unfortunately the distro that I use is pretty old - it's
Ubuntu 16.04, which is currently 7+ years old (and no longer supported), so I
can no longer install the packages required to get mspdebug to talk to real
hardware. So I'm going to be spending some time figuring out how to get all of
that to work. I may need to rebuild the required packages to get it working.

There is also the additional remaining hard work of shoehorning all of this
code to fit into the tiny 2KB ROM that the MSP430 devices that came with the
Launchpad kit are equipped with.

Maybe, just maybe, given that there are only a few more days of summer vacation
remaining, I should just give in to procrastination, kick back, relax and go
hang out at the beach instead ;)

04 Aug '23
----------
I tried to see if disabling the tests can make the code space small enough to
fit within the 2KB ROM that the MSP430 devices have. It turns out that even
with tests disabled, the code still needs ~2800 bytes. So I decided to take a
bit of a detour and compare the sizes of all of the ports that have been
completed so far to see if I can discern patterns. Since the MSP430 and the x86
are 16 bit implementations, but use different THREAD types, I was curious to
see how that implementation choice affects code space usage. I've added the
data as a table to the end of the README. From the data it is clear that THREAD
type 1 (used in x86 as well as the z80) generates the most compact code while
THREAD type 2 (used in the PDP11 and MSP430) generates less dense results.

So the immediate conclusion I can draw from the data in that table is that if
ROM capacity is the biggest constraint, it might be better to choose THREAD=1

In the case of the MSP430 devices that I have, ROM is not the only constraint.
The RAM at 128 bytes is also a big constraint. Since the RAM is so small, it
does not make sense to have a runtime dictionary so this rules out "fourforth".

Since there is no character input device, even the REPL is superfluous and so
even the static dictionary becomes unnecessary. So "threeforth" is also out of
the picture and so we are left with just "twoforth" which only needs umbilical
hosting for a set of defined words. I can see how this kind of thinking can
turn into a race to the bottom so rather than indulge in that, I'll try to see
how much of the code can possibly be shoehorned into the 2KB ROM that these
devices have. So I guess that's what I'll focus on next.

08 Aug '23
----------
After mulling over this decision a fair bit, I've decided that forking off to
work on "real hardware" is too much of a distraction right now so I'm going to
try and finish the two remaining ports that I'd intended to work on from the
start of this project and then revisit the port to "real hardware" when it is
more convenient to do so.

The only two remaining ports from the initial list are ARM and RISC-V and I've
decided to start with ARM first just because I happen to have an old STM board
which I can use for testing whenever I get around to testing these ports on
real hardware.

In my JOURNAL entry for 01 May '23 I'd listed ports which have zig+qemu support
and both ARM(aarch64-linux-musl, qemu-aarch64) and RISC-V (riscv64-linux-gnu,
qemu-riscv64) can be easily built using zig and tested using user mode qemu.
Since figuring out the tooling for build and test tends to be one of the harder
parts of doing a port to a new architecture, I'm happy to take the easy way out
and work on these since the infrastructure issues are already sorted out.

09 Aug '23
----------
Rather than start out with a port done in ARM assembly, I've decided to try and
see if I can use the C code "as is" for shaking out any problems I may run into
by using the zig/qemu combination (since this is the first time I'm trying out
that combination). Since this port should be, for the most part, identical to
the C port, I've symlinked all the files that will be common and left out the
ones which won't be shared as new files.

Unlike the ports of the Z80 variants where the C porting "just worked" all the
way to step 62, this port fails at step 62 when I tried to see if it would be
that easy, so I'll fall back to my usual method of testing out each step one at
a time.

11 Aug '23
----------
I should have realized ahead of time that the there would be a failure at step
13, even for the portable C code, since the addresses specified in fpp.config
are per port since they are memory layout specific. Since I ran into this again
I'll go ahead and document what I needed to do here so that it makes this step
a bit easier in the future. As I mentioned previously in the JOURNAL entry for
20 Apr '23, the trick is to find addresses that don't move after each compile
step. To do this, I appended:
	printf("got %p\n", tos);
to the @ code in code.prims and collected the sorted output from nm forth_dict
before and after the change was compiled. Running `comm -12` with the sorted
output files (from nm) gives the addresses that don't change after a recompile
and in this case with clang 11.1 the address happens to be 0x200200. After
adding this address to fpp.config.C, I can rebuild and see the value at that
address which is printed out by the printf mentioned above which in this case
happened to be 0, so I added it as the VALUE config parameter in fpp.config.C.
Finally, restore the original code.prims and run make to verify things work.

14 Aug '23
----------
With the C version of the ARM port out of the way, it is now time to take a
look at implementing the assembly version. Since clang can generate the ARM
assembly code, I can sneak a peek at the generated code and try to see if I
can get away with not having to read the voluminous ARM docs. Although I could
continue to use zig to assemble the ARM assembly code, I'll switch to old
faithful binutils just so I have coverage of all the available tools.

15 Aug '23
----------
I struggled a bit to figure out how to get the bytecode trampoline working
since I'm still continuing with my experiment to see if I can code this thing
up without reading the docs and looking at just the clang generated assembly
output. After some experiments, I figured out that adrp + adding the offset of
the address appears to work just enough to initialize addresses but I'm sure
there must be a shorter way to do it if I just went ahead and read the docs.
For now I'll go ahead with what works and leave the clean up for later.

Since this port is for the ARM 64 bit architecture, it makes sense to use the
THREAD type=1 for compactness.

---

Happy Independence Day to all you desis out there! ;)

16 Aug '23
----------
Just as in the MSP430 port, for this port also, I'll start off by linking the
assembly code generator scripts to the SPARC version. Since the SPARC port was
32 bits while this ARM port uses 64 bits, if it turns out that the scripts need
to be changed, so be it, I'll change it at the step where I run into trouble.

The configuration file fpp.config.arm is also a copy from the SPARC port.

17 Aug '23
----------
Since the write syscall uses registers x0,x1,x2 (and x8), I've decided to alloc
a different set of registers for ip, i and w so that I don't have to push/pop
them before/after each syscall. Since ARM has 30 registers, I guess I can be a
bit profligate with them, so I've used up an additional temp register as well.

21 Aug '23
----------
I'd been hoping that I could avoid reading the 1300+ page ARM architecture
manual by just looking at the generated assembly code from the clang C compiler
but when I came to this step where I need to implement a stack, I had no choice
but to start reading up on it to figure out how to deal with the machine stack
- mostly because of the unwieldy stack implementation that ARM v8 has chosen to
use starting with Aarch64.

From reading the docs (and Stack Overflow along with various helpful blogs), my
understanding is that stack entries need to push/pop registers in multiples of
two at a time since the stack pointer register SP must have 16 byte alignment
when accessing memory.

After spending way more time than was necessary thinking about how to deal with
this weird architectural twist, I think I have a really elegant implementation
which caches the top two stack entries (tos and nos) in registers without the
friction of shuffling data between the two registers by using a coroutine like
control flow mechanism for tracking which registers are "live".

Assume that 's' is the memory array backing the stack of size N. We can define
the push and pop operations on this stack using the following definition:

--- Pseudo Code {
initial state is (0,0)
push(v) :
	(0,n) -> nos=v ; yield (1,n)
	(1,n) -> tos=v ; yield (2,n)
	(2,N) -> overflow
	(2,n) -> s<-nos,tos ; nos=v ; yield (1,n+2)

v=pop() :
	(2,n) -> yield (1,n)::tos
	(1,n) -> yield (0,n)::nos
	(0,0) -> underflow
	(0,n) -> tos,nos<-s ; yield (1,n-2)::tos

--- Pseudo Code }

The above notation is just for my own consumption since I was using it to help
flesh things out. A more conventional implementation in C might look like this:

--- C Code {

int items=0;
value tos, nos; // the expectation is that these are in registers

int pop(value *s) {
	switch(items) {
		case 0 : pop2(s, &tos, &nos); // fall thru
		case 2 : items=1; return tos;
		case 1 : items=0; return nos;
	}
}

void push(value *s, value v) {
	switch(items) {
		case 2 : push2(s, tos, nos); // fall thru
		case 0 : items=1; nos=v; return;
		case 1 : items=2; tos=v; return;
	}
}

--- C code }

It should be fairly easy to extend this to many more registers and you can
almost see how it devolves into a SPARC register window like mechanism where
the "register window" needs to be filled or flushed only after N pops/pushes.

For the implementation in assembly, I used a jumptable since that seemed to
be the closest fit to the pseudo code.

Since ARM v8 has 30 registers, I'll continue to squander them like there is
no tomorrow. I'm also not going to bother with writing space constrained code
since the 64 bit architecture, allows me to assume that there will be plenty of
ROM and RAM to fling around. I may have to resort to writing tighter code if I
ever revisit ARM to do a 32 bit/Thumb16 implementation.

22 Aug '23
----------
For implementing lit, I decided to leverage clang's superoptimization powers
and generated the assembly equivalent of the following code:

	char *p=ip+8;
	int tos=0;
	do {
		tos<<=8;
		tos|=*--p;
	} while (p!=ip);

But using that resulted in a test failure which I had to debug to the fact that
after adding dup/drop in the previous step, I had (as usual, this has happened
multiple times now) completely forgotten to also modify key/emit to use dup and
drop. Luckily, during the previous port for MSP430, I had run into this exact
same bug and with some foresight, I'd changed the tests to catch this bug as
early as possible and paying down that $TECHDEBT turned out to be an excellent
move in hindsight. I looked at trying to move this test back one more step so
it can be caught at step 2 but that seems to be hard to implement so I'll leave
things as they are for now.

23 Aug '23
----------
While trying to implement jz, I filled up the 256 bytes of primitive space and
rather than widen the offset from 1 byte to 2, I decided to shuffle the largest
primitives from code.prims into forth.S

Since I wrote the primsize script a while back exactly to track down these type
of issues, I went ahead and ran it like this:
	../primsize forth | sort -n
which gives me the following list of the current heavyweight champions:
	16 next
	20 neg
	24 drop
	24 dup
	28 j
	48 emit
	48 key
	52 lit
So for this round of shifting the weight around, I'll go ahead and move the top
three: lit, key and emit from code.prims to forth.S

24 Aug '23
----------
While debugging step 5, the 256 byte primitive area became full again and this
time I decided to do a bit more invasive set of space optimizations. So along
with moving jz/jnz to forth.S, I also moved next so all the primitives that
prepend it became shorter as well.

25 Aug '23
----------
Implementing nip/dip required a revisit to the fancy push/pop mechanism that I
came up with at step 2 and I decided that the simplest rework to get nip/dip
working is to just use yet another register since I have so many left to
splurge on. Since pushpop is just a trampoline, I added some additional jump
offsets to special case the handling of the nos register.

I'm a bit worried though that I may have added more complexity than is good for
my own sanity. Just because I have 64 bits of address space does not mean that
I need to binge on it. I'll wait and see if this turns out to be way too clever
for my own good.

26 Aug '23
----------
Due to the legacy genrom (from sparc) that I've been using so far, I've been
treating the 64 bit ARM as a 32 bit architecture. But now that I need to access
memory, I might as well go all in and let its 64 bitness shine through.

This of course required the genrom script to be modified and I've changed the
symlink from the sparc version to the x86-sys version (which is also 64 bit). I
don't really remember why I didn't just do this at the very beginning.

Due to the genrom change, literals are now 8 bytes instead of 4 so the code in
the handler for that needed to be updated. A full regression test (runallsteps)
was done to make sure that nothing broke due to that change.

Finally, the port specific configuration values for the memory address and the
value at that address also needed to be updated.

28 Aug '23
----------
The kernel of truth ingrained in the quote about caching being one of the "hard
problems in Computer Science" is starting to make itself felt. The decision to
cache the top 2 stack entries in registers was done out of necessity due to the
16 byte stack alignment constraint for the SP register that Aarch64 imposes.

The knock on effects of that decision were felt initially in the implementation
of nip/dip. Now that it is time to implement pick/stick the grottiness of the
whole scheme is on display. But it is water under the bridge now and the least
that I can do is to document things in case I run into bugs later.

Here's the stack layout for registers and memory where the top of the stack is
to the left and the rightmost entry (x0) is the stack element that needs to be
"pick"ed. The ']' marks the "boundary" between register and memory elements.
sn is the number of elements cached in registers (sn is the register name that
is used to track this in forth.S). The number in the "pick" column indicates
the element that needs to be picked from the stack. For each column, the number
of stack elements shown in the table is #picks+2
.---------.----------------.---------------------.--------------------------.
| pick\sn |        0       |          1          |              2           |
+---------+----------------+---------------------+--------------------------+
|    1    | tos ] x1 x0    | tos nosr:x1 ] x0    | tos tosr:x1 nosr:x0 ]    |
|    2    | tos ] x2 x1 x0 | tos nosr:x2 ] x1 x0 | tos tosr:x2 nosr:x1 ] x0 |
'---------'----------------'---------------------'--------------------------'

Using the above table as a guide to the implementation, pick can be coded as:
pick\sn->    0                       1                       2
 1          pop2;tos=nosr;sn=2   tos=*(sp+0*8)           tos=nosr
 2          tos=*(sp+2*8)        tos=*(sp+1*8)           tos=*(sp+0*8)
 3          tos=*(sp+3*8)        tos=*(sp+2*8)           tos=*(sp+1*8)
...

Thus, in general, tos=*(sp+(n-sn)*8), except when pick==1. The code implemented
in forth.S is a straightforward encoding of the above logic.

---

In the case of stick, the equivalent code table is:
stick\sn->    0                       1                       2
  1        pop2;nosr=tosr;sn=1      *(sp+0*8)=nosr;sn=0 nosr=tosr;sn=1
  2        pop2;*(sp+0*8)=tosr;sn=1 *(sp+1*8)=nosr;sn=0 *(sp+0*8)=tosr;sn=1
  3        pop2;*(sp+1*8)=tosr;sn=1 *(sp+2*8)=nosr;sn=0 *(sp+1*8)=tosr;sn=1
 ...

The code for `stick` implemented in forth.S makes use of the parts that are
common between columns 0 and 2 to shave off a few bytes.

01 Sep '23
----------
One of my worries as I was implementing the "stack cached in registers" scheme
for ARM64 was that the existing tests in rom.4th weren't providing full code
coverage of all of the additional assembly code. My hope was that the tables
that I'd laboriously constructed in the previous JOURNAL entry would provide
sufficient guard rails to keep me on the straight and narrow path. Well, it
turned out that at step 32, long after most of the assembly code related steps
were completed, I ran into a weird bug which led me on a wild goose chase and
took quite a while to track down.

From the assert output generated by the test code, it was clear that it was
just the last test that was failing and since it involved a mix of return stack
manipulation along with a larger stack usage on the data stack I wondered if
there was some kind of a corruption due to an overflow on either the data stack
or the return stack that was going on. Given that ARM64 and x86-64 both have
the same 8 byte per element stack usage, I was willing to concede that it was
unlikely that a stack overflow could be the cause here.

Reviewing the last set of assembly code changes, I noticed a bit of detritus in
the code for `stick` (unreachable code, which is now cleaned up) and since that
code had made it in, I suspected that there might be other lingering bugs in
there as well. So I went over all of that code and the relevant tables as well
with a fine tooth comb but could not figure out any brokenness there.

I then tried to use the big hammer of running qemu with the option to trace the
entire instruction sequence (using "-d in_asm,cpu") which will log the register
contents at each step as well. Although that does generate a fairly voluminous
amount of data which can be useful, unfortunately, (probably due to some kind
of an interaction with TCG), there are large gaps in the execution sequence
logs which precludes all of that data from being very useful in this particular
debugging exercise since I do need each instruction to be traced.

I was getting ready to let loose gdb on Qemu and had started reading up on that
but then got distracted enough to go read through the ARMv8 architecture manual
again. Now, the ARMv8 ISA manual is quite hefty, weighing in at ~3300 pages. So
it was only fair that I tried to skim through most of the stuff gleaning just
enough information to understand how the stack handling is done. Note that I'd
done this previously while I was implementing the initial set of stack routines
and that was when I had stumbled on the weird alignment on 16 bytes imposed by
the ARM64 ISA on the stack pointer. One thing led to another and that's how I'd
ended up with the current scheme of using ARM64's plentiful register set to
cache the topmost data stack entries.

Luckily, while re-reading through all of those arcane details, I noticed that
the docs for LDR, where it talks about stack pre-decrement and post-increment,
requires you to use an additional constant for post-increment and realized that
my understanding of LDP/SDP was flawed.

Now, given my earlier experience with the PDP11 pre/post increments, and the
fact that my only introduction to ARM assembly was by looking at the assembly
code generated by clang, my mental model went something like this:
"stp x0, x1, [sp, #-16]!" is how you handle the pre decrement, so, by symmetry,
"ldp x0, x1, [sp]" should perform the equivalent post increment. But after
reading through the ARM ISA docs, it was clear that the code needed to be
changed to: "ldp x0, x1, [sp], #16"

The constant "#-16" which is specified in the code for pushing entries onto the
stack should have been a hint that it would be needed while popping off entries
from the stack as well. Anyway, all of that is 20/20 hindsight now. So, perhaps
the lesson here is that it serves me right for not having read all the arcana
in all of the relevant parts of the ~3300 pages of the ARMv8 ISA manual or at
least going through it in enough detail to avoid these kinds of blunders.

02 Sep '23
----------
Things were chugging along nicely until I needed to add dictionary headers at
step 41 which caused the offset of `next` to exceed 12 bits and this makes it
so that it doesn't fit into the 12 bit space for an immediate value. Rather
than read through the docs yet again I'm just going to use yet another level of
indirection which seems to be quite expedient at this point. This of course
triggered a failure at step 13 since it caused the address hardcoded in the
fpp.config.arm configuration file to go out of whack so I had to fix that as
well to get the test to pass.

08 Sep '23
----------
At step 58, I ran into yet another bug that needed a fair amount of debugging.
Since qemu is not of much use even with the "-d in_asm,cpu" logging option, I
decided to fall back to my old printf debugging strategy by enabling "debug=1"
in the fpp.config file. Unfortunately this triggered a regression which I had
to debug first when I increased the width of the output (which defaulted to
assuming a 16-bit cell size). After changing it to use the current CELL size,
I could see that the SEGV was happening in find while traversing the dictionary
entries. I could see that the regression started at step 56 but it was not at
all clear why things had worked before I added the debugging.

In hindsight if I had looked at the addresses more carefully, I could have
figured out the problem immediately. But since I guess I wasn't paying enough
attention it took me quite a while to figure out that I had overstepped the
memory bounds and that I needed to increase it. Since memory will hopefully
never be a constraint on a 64-bit architecture, I've doubled it from the 1KB
that it is currently allocating to a whopping 2KB ;)

Even after that doubling I ran into yet another SEGV and luckily my hunch that
it was a return stack overflow turned out to be correct when I bumped up the
return stack size also by doubling it from 120 bytes to 240 bytes. Some binary
searching for the "sufficient" value of the return stack shows no segv at 176
bytes but I might as well just leave it at the higher setting.

15 Sep '23
----------
I spent a fair bit of time again trying to understand a new segv that happened
at step 59. I finally found that while a doubling of the allocated RAM space
was not sufficient to fix the issue, a quadrupling of the allocation did fix
it. Although it looks like the problem is fixed, I have a feeling in my bones
that there is something funky afoot that I don't quite understand so I spent
a fair bit of time adding even more tracing to try to figure out what is going
on. I didn't get to the bottom of it to my satisfacation but I don't want this
issue to hold up the porting effort on ARM64 for much longer. So, for now, I'm
going to reluctantly leave this change in as $TECHDEBT and move on.

18 Sep '23
----------
This entry marks the conclusion of the ARM64/Aarch64 port using Linux syscalls.
Although I had expected this to be an easy port, it had its fair share of bugs
which made it take a little more than a month to finish. It may also have been
because I was doing it at an unhurried pace, in laid back fashion while also
spending time on other things that are starting to be more interesting.

The bug that I ran into at step 32 with an incorrect stack implementation shows
that the test coverage needs to be improved (to sanity check read/write to the
memory backing up the stack) but I'll assume that the paucity of registers on
most conventional low end microcontrollers will guarantee that this situation
will not usually arise. So I think I'll leave that as $TECHDEBT.

The bugs that I ran into at steps 58 and 59 were a complete surprise to me so
one of the sanity checks that I'd like to do as a followup is to figure out the
actual RAM requirement. The data and return stack usage is reported by running
the x86 emulator which reports it in bytes - but only for x86 so I need a means
of doing the same thing on other architectures as well.

With the ARM port now complete, the only major port remaining on the list that
I'd started with almost a year ago is RISC-V and since it is also a RISC chip
much like ARM, I think I should be able to finish it in a New York minute.

So let's see how that goes.

---

On a personal note, today would have been Lisa's 20th birthday.
Like Browning in her poem, I wonder, in how many ways do I grieve for thee?
Miss you Lisamma.

22 Sep '23
----------
For the riscv-zigcc port, I've decided to short circuit through all the steps
since I think I have the methodology down pat now. The only difficulty I faced
in this port was at step 13 and so I used the instructions that I'd previously
documented in the JOURNAL entry for 11 Aug '23 to figure out the address and
value to be used in the fpp.config file. Just like the ARM port, I've used zig
for the build and qemu for testing. I've used the arm-zigcc makefile and config
as the templates for the equivalent files in the RISC-V port and the rest of
the scripts are just symlinks to the corresponding scripts in the C directory.

The address and value used in the configuration file may be valid only for the
final step of this port so I'm going to weasel out of that issue by taking the
easy way out by not creating the runallsteps entry for this port. Since this
issue is starting to be a bit if a pain in the neck for now I'll just go ahead
and mark it as $TECHDEBT here.

25 Sep '23
----------
Since the riscv-zigcc port is done, I could call the RISC-V porting complete
and move on to something else. But given that RISC-V is the new hotness and
furthermore, given the fact that some of the recent crop of the lowest priced
microcontrollers are now based on this architecture, I think it is only prudent
to have a low level port on this as well. So for the most part, this is just a
learning exercise to get more familiarity with the ISA.

I had worked on RISC-V when I worked at Amazon(Ring) but since all of the code
was C/C++, I didn't really need to bother with assembly there except when there
was a crash and even then, GDB+JTAG was usually nice enough to get a C function
level backtrace. So this will be my first exposure to RISC-V assembly at a very
close level. Nevertheless, that still is not reason enough for me to go read
the voluminous ISA docs which very likely clock in at thousands of pages. Just
like I did with the ARM port, I'm going to try the experiment of getting away
with not reading any of the docs unless absolutely essential. This turned out
to be not such a great idea during the ARM port, but since RISC-V is hopefully
better thought out, I'm hoping that reading the clang generated assembly should
be sufficient to get me most of the way there.

As with the ARM port, I'll eschew zig for the build and use binutils instead
since that gives a good coverage over the tools as well. For the configuration
file, I've made a copy of the fpp.config from the arm64-sys port since I assume
that should be pretty close in terms of the ISA.

14 Oct '23
----------
It is exactly one year since I made the first commit to this repo on github and
as they say, "you've come a long way, baby" ;)

Almost as an anniversary gift, I've managed to finish up the RISC-V syscall
based port on Linux which is coded in assembly primarily for ease of porting to
baremetal. Since this was an RV64 port, which was picked for ease of build and
test, I may follow this up with an RV32 variant as well. The RISC-V docs also
mentioned a 16-bit "size optimized" version, so I may make an attempt at doing
that port as well if that turns out to be a fairly easy "adjacent" port.

As ports go, the RV64 port was relatively easy although I did run into a couple
of nasty bugs along the way due to the tests not catching them early enough and
passing it through to much later steps where it becomes progressively harder to
debug. Looking to the future, tightening up the code coverage could be an area
of focus as I move in to year #2 of romforth.

Given that I've successfully completed quite a few ports (a baker's dozen?) for
a variety of distinct "architectures", I think it is only fair that I can lay
claim to the fact that romforth is an "ultra portable" version of Forth. I'm
proud of the methodology that I've created which allows a structured means of
creating new ports for any new architecture and in some sense you can almost
think of it as an almost gamified means of porting Forth.

Since most of the primary CPUs that I listed at the beginning of this project
are now complete, (see JOURNAL entry dated 04 Nov '22) I think it may also be
time to shift focus from even more ports to testing things on real hardware
rather than just emulation, which is the expedient approach I've taken so far.

Anyway, all of that is off in the rosy future. For today, I'm just going to
look back at all of the work that I've done and give myself a pat on the back.

16 Oct '23
----------
After thinking about next steps, I decided to take a shot at a RISC-V 32-bit
port since binutils could be used for the build and qemu-riscv32 for testing.

For the generator scripts, I used the x86-32 bit build scripts and for the rest
of the CPU specific code, it was just a matter of replacing the constant 8 with
4 to denote the switch from the 64 bit RISC-V port to a 32 bit port. All in all
this port turned out to be much easier than I could have ever imagined and I'll
go ahead and mark this port complete in one shot rather than the usual 73 step
long drawn out process.

18 Oct '23
----------
With the RISC-V 32 and 64 bit ports out of the way, I did some research on the
"16 bit" RISC-V variant and from the quick browse that I did it appears to just
be an opcode variant and so I'll skip over that and move on to something I've
had in the back of my mind for a while.

There are many Forth implementations which use a "THREAD"ing technique called
"Subroutine Threaded Code/STC" which is just an old fashioned way of saying
that instead of relying on an interpreter, the Forth code is directly turned
into machine code with the usual space/time tradeoffs. Given Forth's philosophy
of simplicity, this type of "compilation" is done with nary a lexer or parser
or optimizer or machine code generator in sight. So I'm going to try to see how
far I can get with reimplementing the MSP430 port, using "STC" THREAD'ing.

I'm choosing the MSP430 since it is in the lineage of the PDP11 (with readily
available hardware). I could have picked the RISC-V but I'll hold off on that
until I've done more research into exactly how the 16-bit mode is supposed to
work.

19 Oct '23
----------
My initial plan to implement "subroutine threaded code" THREAD'ing type was to
leverage the C preprocessor (as a macro processor) to run all the necessary
code expansions that were necessary. But after trying out various attempts at
making it work, I've decided that plain old M4 might be the simple way to go
about this. I know that M4 is gnarly and pretty much everyone uniformly detests
it. But I see it as just another tool in my arsenal and despite some misgivings
about it, I'll just go ahead and use it. I'm reminded of "something something
angels fear to tread" so sue me ;)

23 Oct '23
----------
My brash/first attempt at implementing jumps was to manipulate the PC directly
using machine code that looked like this:
    0f930: 30 50 f8 ff               ADD     #0xfff8, PC
After thinking a bit about this approach, I've decided to go back and redo the
j'ump implementation to use MSP430's JMP opcode instead, since that takes up
much less code space. Part of the reason I didn't use JMP to begin with was
that the MSP430 uses 10 bit offsets for JMPs which meant bit fiddling (since it
is not byte aligned) and I didn't want to change the scripts too much at this
point to special case them. After thinking about it over the weekend though, I
decided, for now, that I may be able to tolerate the additional complexity.

I was also able to get away with not having to change the generator scripts at
this point by leveraging/(using the hack that) the MSP430 assembler allows the
EQU pseudo-op to reuse the same name multiple times.

25 Oct '23
----------
The first case of a workaround to handle M4 has now made its way into the code.
Since 'inc' is a Forth primitive as well as an assembler opcode, I was using it
on the left and right hand sides of the definitions in code.prims. This caused
m4 to go into an infinite loop. Luckily, the MSP430 GCC assembler appears to be
case-insensitive for opcodes (ie it treats 'inc' and 'INC' identically) so I
was able to hack my way out of this predicament by replacing all the assembler
'inc' opcodes with 'INC'. I assume mixed case might also work although I didn't
bother trying it.

30 Oct '23
----------
The earlier Forth interpreter for MSP430 (which I'd implemented a while back)
used THREAD type 2 encoding for interpretation so it was more compact in terms
of ROM space usage. Since the current implementation uses machine code aka STC
(subroutine threaded code), it is much less compact and this can be verified
from the fact that we have now run out of ROM space at step 19 compared to the
older implementation which needed the additional space only at step 36. Just as
in the earlier implementation I've chosen to use the largest device that the
compiler supports in one shot rather than add more space incrementally.

06 Nov '23
----------
After making steady progress for a while I ran into a bug that stumped me for a
bit. Lots of debugging later (which involved staring, a lot, at the disassembly
then placing a few strategic breakpoints followed by single stepping), it turns
out that the bug was a side effect of using M4. Some of the strings used in the
dictionary header needed M4 specific quotes so that it wouldn't get expanded
into other strings of assembly code. Despite how hairy the debugging turned out
to be, that was a really fun debug exercise, but probably only for those who
think of debugging as fun. What was especially nice was not having anyone
breathing down my neck and asking for daily (hourly?) status updates.

28 Nov '23
----------
What with the Thanksgiving break and other distractions things are moving along
slower than usual. I ran into an issue where the existing common code cannot be
made to work with the newer THREAD type so while fixing that up I decided to
also take this as an opportunity to pay down some of the techdebt that has been
building up over the past year. I've been rather profligate in making copies of
the genrom scripts and I decided to turn them into symlinks instead. The hacky
use of 'lit' to zero fill and pad out a byte has been replaced with an explicit
'pad0' directive. But this change then snowballed into modifications to the
genrom scripts and that's when I decided to do a proper clean up job with the
net result of: 11 files changed, 30 insertions(+), 867 deletions(-)

With 867 fewer lines of code my "LOC performance metric" will take a hit and I
will have to kiss goodbye to that "10x programmer" performance bonus I guess. I
was really hoping for a Ferrari for Christmas this year but that will just have
to wait. And, yes that was just sarcasm, in case you didn't get it ;)

04 Dec '23
----------
Since the Nov 28 change to replace 'lit' with 'pad0' was done piecemeal so as
to just get step 50 to work, that change will need to be repeated at all later
steps which depend on the newer keyword. Rather than do it all in one shot,
I'll continue with the philosophy of only making small targeted changes to help
make progress one "step" at a time. So the changes here are sufficient to get
step 50 to pass.

Also now that 'suffixret' exists, I decided to use it to terminate definitions.

And in other news, I got bitten by my decision to use M4 once again at this
step. M4 needs quote characters and the defaults are "`" on the left and "'" on
the right. Since those quote characters would clash with many of the existing
Forth words, I'd chosen to use '[' and ']' as the quote characters instead and
this choice was made fairly early on and I now realize it may have been too
hasty since it runs into trouble with the definitions named 'run[' and ']run'
which are used at step 51.

Rather than try to struggle valiantly with m4, I'll just cave in and change the
names of the routines to run{ and }run instead.

There, there, that wasn't so hard, was it?

23 Dec '23
----------
So there you have it, my first "subroutine threaded code"/STC port of romforth
to the MSP430. This port turned out to be much more troublesome than most of
the recent ports partly because machine code is unforgiving and also because it
was difficult to inspect the generated code without dropping into the debugger
to strategically place a few breakpoints and then look at the disassembly.

Another reason this took so long, I think, was that the THREAD=4 setting was
added as it was being used which took a fair bit of rework of the common code
as I had to be very careful not to break any of the existing stuff while I was
at it.

My hope is that future STC ports will be much easier than this since most of
the skeleton code for THREAD type 4 is now in place and the only thing that
needs changing will just be the machine code specific parts.

Looking ahead, I'm thinking of either implementing yet another THREAD type that
I've been considering for a while now or try another STC port (perhaps redo one
of the existing ports, just like I did for the MSP430) to see if things are
easier the second time around.

But all that work can wait for the New Year. Since it is Christmas time now, I
think it is time to take a break - both to look back and look ahead and also to
focus on family and friends and not go too crazy from all the stresses and
strains of entertaining all of them ;)

Merry Christmas everyone! And wish you all a wonderful and Happy New Year!

02 Jan '24
----------
I've decided to start off on yet another STC port while the memory of the one
that I finished is still relatively fresh in my memory. This time around, I've
picked the Z80 for the port and the rationale is pretty much identical to the
reasons why I picked the MSP430 earlier - ie, a working implementation already
is in place. Hopefully much of this work should be limited to sanity checking
and verifying that the framework for STC/THREAD type 4 which is in place can be
easily carried over to a newer architecture without too much effort.

10 Jan '24
----------
I didn't really care enough to code a real version of rp@! which would allow
twiddling with Z80's SP register especially since the ucsim_z80 simulator seems
to be finicky about having the stack within the F000-FFFF address range. So for
now I'm just going to sneak in a 'nop' as the implementation. Obviously this is
a completely broken implementation if you ever need to switch the stack but if
you need it you can fix it yourself (or, you know, "call me, maybe")

16 Jan '24
----------
When I started off on this port, my expectation was that I'd be done with it
fairly quickly and now here I am, almost 2 weeks in and I haven't even got to
the parts that require heavy lifting. I'm going to try and speed things up even
though that implies adding techdebt even if no one (except me, probably) cares
if this gets any done faster. To achieve the quicker cadence, I'm planning to
copy the steps that I followed in the msp430-stc port as is. So although I know
that exec cannot be implemented as a 'nop', I'll follow that step here since it
was done that way in the earlier port.

17 Jan '24
----------
After whining about the slow pace of progress yesterday, I'm glad that after an
all day coding marathon I've managed to complete the z80-stc port. The fact
that I could refer to the previously completed msp430-stc implementation and
use it as a template definitely helped speed up the process. With this port now
out of the way, I think I can safely stake the claim that STC implementations
for romforth, are for the most part, a solved problem. Anyone who cares enough
about performance and is willing to trade it off against increased ROM usage
can choose a part with a larger ROM and spend some quality time tussling with
the machine code (and M4 if they choose to use the same methodology that I
picked) and be able to crank out a new port in fairly short order.

With all the different THREADing types that I've implemented (4 so far), I
think I have fairly decent coverage of the ones that are commonly used to
implement Forth. While "subroutine threaded code" makes the tradeoff in favor
of performance, it is possible to go in the opposite direction and use a slower
implementation which takes up less space. For example, THREAD type 1 makes that
choice. For the next port, I'm considering a variation of that THREADing type 1
about which I've been thinking quite a while.

05 Feb '24
----------
In my previous commit, I'd created a TODO list of CPU architectures that can be
used as "relatively easy" porting targets since they have QEMU user emulation
support. After spending some time thinking it over though, I've decided that
before I go branching off to support even more CPUs I should really go back and
take a look at the original problem that I was trying to solve when I started
this project, which was to get Forth running on my MSP430 "Value Line LaunchPad
Development Kit" which has a microcontroller with just 2KB ROM and 128 bytes of
RAM.

As you can see from the entry for "msp430-as" in the table at the end of the
README, the "full"/fourforth/(4/4) Forth implementation needs 2810 bytes of
ROM (for the version without tests), which means it definitely will not fit in
the 2KB ROM. Moreover, the 128 byte RAM may be too small to hold a full runtime
dictionary (but might be able to hold a tiny set of words though).

After the implementation of "msp430-stc" which uses almost twice the ROM as the
"msp430-as" by trading off space for time, it is fairly clear to me that it is
now time to try the opposite trade-off as well to see if I can get a version
that will fit in a smaller ROM.

To set the stage for that implementation, let me start with a small digression
by discussing the ISA of one of the earliest computers: the TX-0. The TX-0 has
just 4 opcodes and is implemented with just a measly 3600 transistors although
they did add an escape hatch (as opcode "10") to extend the ISA without any
real limits by making it a catch all type of opcode.

We could use the same idea to come up with an ISA for a "minimal Forth CPU"
with just 4 "instructions":
	00 X	: push X
	01	: pop
	10 X	: call X
	11	: return

Note that just like in the TX-0, the "10" opcode is used as an escape hatch to
extend the functionality without having to define an extensive opcode set right
at the outset.

But even a cursory glance at the "packing efficiency" of this instruction set
shows that we should try to get rid of the 01 and 11 opcodes. Which leaves me
with just two opcodes which need to be encoded and these can be denoted as:
	0 X	: push X
	1 X	: exec X
so "0" acts as opcode for Forth's "literal" and "1" is the new catch all to
handle everything else and thus we get to a "2 instruction Forth" CPU.

Finally, we can take the next simplification step and go all the way to decide
that even the two opcodes are in some sense superfluous. So the final encoding
can just be:
	X	: exec X

If X is used as the offset to the address where it is implemented, we end up
with an encoding which is compact and reasonably performant. So this is how I
ended up with THREAD type 1. THREAD type 2 can then be considered a 2 byte
variant of the same scheme which is used only for the PDP11 and MSP430 ports.
THREAD type 3 is yet another variant of this scheme which is used in C code.

While this encoding is space efficient, the resulting binary is not portable
since the actual values used for each bytecode happens to be whatever address
is applicable to that processor. Now, one could argue that binary portability
is useless - since portability of the higher level Forth code is, for the most
part, the only "real" requirement. And obviously, this will result in trading
off efficiency/time for the sake of a portable binary.

Nevertheless, for the sake of my own curiosity, I'm going to try to go ahead
with creating a portable encoding as well. Like most things in computer science
all it requires is an additional level of indirection such that instead of X
being an offset, X becomes an index which can be dereferenced to an offset.

With this encoding, one possibility is to pick the index number for each Forth
word based on the order in which they are implemented. This can result in a
rather arbitrary mapping from Forth words to the corresponding bytecode.

Instead, I'm going to try to use a "mnemonic mapping" from each Forth word to
an ASCII character, which might make the binary a bit readable as well.

My thinking on this idea is: just as Forth code is made up of "words", what if
we use characters as the building blocks? Since this "language" is built out of
characters, it seems appropriate to refer to it as 'F'. Just as Forth words can
be strung together (but delimited by spaces), strings of 'F' characters can be
used to implement Forth words defined in terms of lower level "opcodes" except
that unlike Forth definitions, they don't need dictionary entries since the new
definitions can also be named using single characters. I'm hoping that using
this implementation technique I can get a "fourforth" implementation that can
fit into really small spaces - even on relatively tiny ROMs such as the
microcontrollers used in the MSP430 "Value Line Launchpad Development Kit".

That's enough blather for today - let me try to turn at least some of those
ideas into actual code real soon now.

09 Feb '24
----------
Now that the bytecode implementation has begun in earnest, I need to pick a
bytecode for Forth's bye (halt) opcode and for now I'm going to pick the very
last character in the ASCII charset which is 'DEL'/0x7f for it.

12 Feb '24
----------
For generating the 'F' bytecodes (which I'll refer to as Fcode from now on),
I've copy pasted the genprims and genrom Perl scripts as well as the makefile
and the configuration fpp.config.msp430 from the msp430-as port and made some
(mostly minor) modifications to retrofit them to generate Fcode instead of the
MSP430 assembly code that they currently generate.

---

To pick the 'F' bytecodes for Forth's key and emit primitives, I'm leaning on
the UNIX heritage to map them to '<' and '>' respectively.

---

Picking a bytecode for the equivalent of Forth' LITeral is a bit difficult (pun
intended) due to the various CPU architecture bit lengths that need to be
supported. For now, I'm leaning toward using the digits 1..8 to designate how
many bytes of the literal follow the opcode. I'll start with just '1' which is
used to prefix a single byte and then add more as required later.

13 Feb '24
----------
While working on step 5 of this port, I ran into an issue with the msp430-as
assembler which errors out with the message:
    forth.s: Fatal error: line 243: unknown relocation type: 0x7 (BFD_RELOC_8)

The code that it errored on was this segment of code in rom.s (which was
generated by a modified version of genrom):

243:		.byte lbl000_then-.-1
244:		.byte '1'
245:		.byte 37
246:		.byte '>'
247:	lbl000_then:

I couldn't see anything that was obviously wrong with this code since I can put
the offset (==3, calculated manually) to replace the "lbl000_then-.-1" and get
it to work (but only after making the same kind of change by hand in two other
places in the code where the assembler was also failing). After a couple of
experiments I found that I could workaround the assembler error if I replaced
the code at line 243 with:

243:		.word lbl000_then-.-2

but this requires all the offsets to become word sized instead of byte sized
and since the primary purpose of this port is to try and minimize space usage
this workaround will obviously not fly.

Rather than try to kowtow to whatever erroneous demands the assembler is making
on this code, I've decided to ignore it and instead, use the same workaround
that I had used in the C port (where an offset computation facility does not
even exist) by using a "patchrom" Perl script (a slightly modified copy of the
version from the C port) to figure out the required jump offsets and patch
those pre-computed values into rom.s

This avoids having to generate the code shown above and so I don't have to
deal with whatever bug it is that msp430-as is (probably) encountering.

---

To pick the 'F' bytecodes for the implementation of inc/dec I wanted to use a
set of characters that were in some sense "symmetric" and the obvious choice of
(i)nc and (d)ec doesn't meet that criteria so I've chosen incremen(T) and
decremen(t) instead.

While testing the change, I ran into an existing bug in the implementation of
literals since it doesn't handle negative bytes correctly and I've fixed it as
part of this change.

---

The choice of 'v' for in(v) was motivated in part by the fact that I want to
reserve 'i' for the loop variable.

---

The choice of ni(p) and di(P) was again dictated by the notion of "symmetry"
that I mentioned earlier for inc/dec and in this case I chose the capital
alphabet for dip as a mnemonic for the fact that it increases the stack size.

I'm now wondering if (D)up/(d)rop would have been a better choice for dup/drop
instead of the current mapping of dup/drop to '['/']'.

---

The mappings for +/-/&/|/^ to their respective characters was fairly easy and
for 2drop I'm going to make the choice of picking 'd' for now.

---

For swap I'm going to pick 'S' although it breaks the "symmetry" notion that
I've been harping on during the past couple of selections. Moving on ...

19 Feb '24
----------
Real life intervened and caused a delay to the progress of this work. I got
randomly selected for Jury duty and I spent most of the past week in the Hall
of Justice at 190 W. Hedding. It started off with the jury selection process
which took up both days of 14/15 February and the morning session of the 16'th
at the end of which I have been selected as Juror #10. The actual hearing of
the criminal case started in the afternoon session of the 16'th. The judge for
the case estimates that the case should be concluded by the end of the month. I
am not permitted to discuss anything about the case until it is over so I may
update this JOURNAL with notes about the case but they will only be local
commits until the case is resolved at which time I will be free to do the git
push to publish my changes.

With that explanation of why there has been no progress on this project out of
the way, I can now return to working on it just for this rainy monday since the
court observes a "President's day" holiday for today. So as a result of the
court holiday I did manage to get some work done to add support for '@'/fetch.

So far only 1 byte literals are supported and since MSP430 addresses can be
16-bits, I went ahead and added a lit2/'2' primitive to handle 2 byte literals.
Using this I can push addresses on the stack to verify the functionality of '@'

20 Feb '24
----------
Jury duty ended a little early today so I was able to get some debugging done
to fix up the implementation of c@/c!

To implement c@/c! I first had to address the problem of picking opcodes that
can be used to meaningfully represent them in ASCII and for now I've chosen 'C'
and 'c' (for the same "symmetry" reasons that I've mentioned in some of the
earlier entries in the JOURNAL).

Unlike the msp430-as port where I was able to sneak in a '_fa_ke_' entry in
code.prims to add a .data directive, I've chosen to use a simpler fix (which is
hardcoded into genprims).

The availability of the msp430-as port makes this port a bit easy since I can
just use the existing code as a template to copy and paste but the bugs are
always new.

22 Feb '24
----------
For the same "symmetry" reasons that I've already mentioned in some of the
previous JOURNAL entries, pic(K) and stic(k) are denoted using 'K' and 'k'
respectively.

While the implementation for pick was done fairly quickly, almost two days ago,
I ran into a weird bug while trying to implement stick. Running `make` resulted
in a failing run with the following message at the tail end of test.log:
	(mspdebug) Running. Press Ctrl+C to interrupt...
	console: read error
and after some debugging and just looking at the output of
	msp430-objdump -dx forth | less
with special attention paid to the offset addresses of the functions, it was
clear that the starting byte of the code was getting placed at odd addresses.
I'm still not quite sure why my attention was drawn to it, dumb luck I guess.

Anyway, the easy fix was to use a ".align 1" directive after the rom bytecodes
to make the rest of the code start on even addresses. I'm not sure why I didn't
run into this problem before this - I guess it was just even more dumb luck.

---

I can't think of a "symmetric" ASCII character notation for sp@!/rp@! so I'm
going to make do with denoting them using (') and (") which seem "symmetric"
enough for my taste, for now. Since all this gets processed by genprims, I can
always revisit these decisions later, if I think the mapping must be changed.

---

It was decision time again to pick ASCII characters to denote >r and r> and
since they are similar to function entry/exit "brace" operators, the choice of
'{' and '}' seems to be the fairly obvious choice to me, at least for now.

---

To denote "exec", I was torn between choosing one of the non-alphanumeric
symbols vs picking an alphabet. For now, I've gone ahead and used 'x' as the
denotation although no equivalent symmetrical mapping for 'X' can ever exist
since there is no inverse for "exec" - unless I go out on a limb to implement
"come from" - like INTERCAL ;)

The implementation of "exec" is based mostly on the "bytecode is an index"
indirection implemented in "realnext".

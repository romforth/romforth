INDEX
-----
	* 11 Nov '22
	* 13 Nov '22
	* 15 Nov '22
	* 18 Nov '22
	* 30 Nov '22
	* 01 Dec '22
	* 03 Dec '22
	* 05 Dec '22
	* 06 Dec '22
	* 07 Dec '22
	* 08 Dec '22
	* 09 Dec '22
	* 12 Dec '22
	* 15 Dec '22
	* 16 Dec '22
	* 18 Dec '22
	* 19 Dec '22
	* 20 Dec '22
	* 22 Dec '22
	* 23 Dec '22
	* 06 Jan '23
	* 07 Jan '23
	* 08 Jan '23
	* 10 Jan '23
	* 11 Jan '23
	* 12 Jan '23
	* 13 Jan '23
	* 14 Jan '23
	* 16 Jan '23
	* 17 Jan '23
	* 18 Jan '23
	* 23 Jan '23
	* 26 Jan '23
	* 01 Feb '23
	* 03 Feb '23
	* 15 Feb '23
	* 21 Feb '23
	* 22 Feb '23
	* 23 Feb '23
	* 24 Feb '23
	* 25 Feb '23
	* 27 Feb '23
	* 01 Mar '23
	* 06 Mar '23
	* 08 Mar '23
	* 10 Mar '23
	* 11 Mar '23
	* 14 Mar '23
	* 15 Mar '23
	* 16 Mar '23
	* 17 Mar '23
	* 21 Mar '23
	* 23 Mar '23
	* 01 Apr '23
	* 03 Apr '23
	* 05 Apr '23
	* 18 Apr '23
	* 20 Apr '23
	* 21 Apr '23
	* 22 Apr '23
	* 25 Apr '23
	* 27 Apr '23
	* 29 Apr '23

11 Nov '22
----------
The difficulty I'm running into now with the C port is that it is turning into
what appears to be a long drawn out struggle between C and Forth to figure out
who has first dibs on access to the system.

Forth obviously considers the entire machine as personal property unto itself,
to treat as it wishes. For example, Forth needs access to the return stack but
modifying the return stack in C looks like a fairly heavyweight operation using
getcontext/setcontext or other lower level alternatives using "asm"

There is also clearly an impedance mismatch between Forth's view of memory and
the memory abstraction that C provides - especially since the Forth bit'ness
of this implementation by design is 16 bits vs whatever processor bit width it
happens to be on the system that the C compiler is running on.

Rather than go into contortions trying to make the two world views conform to
fit each other, I'll call this port to C complete, for the most part, since new
Forth definitions can be added to defs.4th (although clipping its wings like
this makes for a very crippled/powerless Forth implementation).

So it does look like there is a real need for direct access to the CPU to have
Forth's power shine forth, so I think I'll go back to the original roadmap and
pick up things back up from where I left off, looking at what port to do next.

13 Nov '22
----------
Rather than jump directly into selecting a processor for the next round of the
porting exercise, I decided to take a step back to look at where I could be
more productive and not waste time on repetitive grunt work.

So now that I've done the porting exercise a couple of times, one thing that
I've found which appears to be a serious waste of time is starting over from
scratch for each port with an empty rom.4th and then adding the same generic
code over and over again after each step as the port progresses. For example,
the rom.4th changes to verify the key/emit functionality was done in commit
589f315d74e90e3e097112dc8760b41cdf958a22 at the time of the initial bootstrap.
At the time of "porting" this change to GNU "as", the same set of changes was
done in rom.4th at commit 2eba44f4643e42c98b8cf654c3936a333a4e225d. This was
repeated yet again at the time of the C port, when the exact same set of
changes to rom.4th was made in commit 07c25aaf30e1a7dc0a566adc086e3d0a3f896519

So rather than repeat this for each port, it makes sense to abstract out
the generic code in rom.4th and delimit each step of the porting process
within that file so that we can increase a "step" variable after each step
of the porting process so that when all the "steps" are complete, and all the
tests run successfully, we can declare that port complete.

This removes all of the duplicated effort that goes into keeping the tests
(which are part of rom.4th) in sync with each of the porting steps. Instead
of that approach, the new process ensures that the rom.4th contents remain
the same for all ports and the only thing that changes is the "step" variable
(which in some sense denotes the progress of a specific port).

Only time will tell if this "premature standardization" is a good thing or not.

As part of this process, I've also decided to add yet another primitive and
sneak it into the rom.4th "standard" as part of this overhaul. The primary
reason to add it in is for symmetry with "pick". For lack of a better name,
I'm calling it "stick" and like "pick", which gets an element from the stack,
"stick" replaces an element in the stack with a new value.

To parameterize individual ports, I've added a provision for Perl/shell-like
"dollar" variables. Since the code processor does not yet exist, I've not
modified the existing rom.4th files but created the new/generic version at
the top level. As this gets fleshed out and tested, the other rom.4th files
will be eventually obsoleted and removed.

---

That's it for the technical part of this journal entry. On a personal note,
as of today, it is 13 years since Lisa died. She would have been just the age
at which I was getting into the swing of all things related to coding. I wonder
if she would have chosen to be a coder like me.

Anyway, miss you Lisamma.

15 Nov '22
----------
I'm yet again at the crossroads of choosing a processor to work on next and as
with the earlier choice that was made, of fleshing out the generic test code in
rom.4th first, I've chosen to again start off by writing up what amounts to an
elaborate and generic how-to/"process document" on how to go about the porting
exercise for any given processor. It is meant to match up with the "step"s in
the rom.4th test cases although there isn't an exact 1-1 correspondence since
this "code" is meant to be more for human consumption than for direct use by
machine.

This is also an attempt to consolidate the things I've learnt from the previous
round of porting exercises that have been completed so far and the expectation
is that this "code" will continue to be updated with newer ideas as I work on
additional ports for other CPUs.

Since it is written for a "generic" CPU, I've placed it under pseudo/code since
much of the "code", if you want to call it that, is a mishmash of C and Forth
along with some non-C like notation for auto increment/decrement borrowed from
6809 assembly code. Although it is pseudo-code I've written it in a way such
that it may be possible to write a parser for it and turn it into machine code.

18 Nov '22
----------
This is starting to become a pattern now I guess: everytime I think I should
start on a new port, the overhang of the previous work takes me off on yet
another tangent. In this case it is an attempt to make sure that the new
version of the tests in rom.4th can actually work seamlessly with the original
code. The newer version of rom.4th had some changes from the version in the
port directories so I assume it is wise to test stuff out now on known code
rather than figure things out the hard way on unknown code where I'm wrangling
a new CPU and new toolchain along with the newer tests. It will also prove
if this strategy was a good choice to begin with.

30 Nov '22
----------
I think the x86 port is now complete (yes, really, at least to my satisfaction)
now that the last of the annoying little techdebt details are cleared. So I can
declare unambiguosly that it is now time to start on the next port.

In the initial list of architectures that I had listed in the PORTING doc, I
realized that I missed a truly important one: the PDP11 (I've updated it there
now). In my early student days, we covered the PDP11 as part of the course on
"Computer Organization" based on the textbook of the same name authored by
V. Carl Hamacher, Zvonko G. Vranesic and Safwat G. Zaky.

---

A small personal anecdote about this book : I bought this book long, long ago
when I was a student (when it, quite literally, cost a fortune). From the
scribbles on the back of the book, it looks like the price was $7.95 (USD? or
more likely Singapore Dollar, since it is the "International Student Edition"
printed in Singapore) and it was sold for the princely sum of Indian Rs 125/-
which in my student days would probably have been about ~2-4 months worth of
lunch money. This was in the late 80's so I'm really dating myself here. I'm
really grateful that my Dad (Happy Birthday, Apai!) and Mom plunked down their
hard earned money to buy this book for me.

Thank you Apai & Mom! :heart: :RIP:

---

Switching back to the technical discussion, the pseudo code (in pseudo/code)
that I wrote to help with the porting reminded me of how well attuned the PDP11
instructions are to the programmers needs from an assembly coding point of view

I'll assume that the instruction sets of the 68000 and the MSP430, both of
which are elegant in their own ways, all trace their lineage back to this
beautifully crafted, gem of an ISA. Obviously, I can only talk about what I
know, so in case the PDP11 inherited its elegance from an earlier design, then
hey, here's a shout out to them too.

Some research into how to emulate a PDP11 and cross-compile/build for it led me
to: https://ancientbits.blogspot.com/2012/07/programming-barebones-pdp11.html
which walks through all of the steps required to do this in excellent detail.

The quick summary/cheatsheet is:
- Build/install binutils (for pdp11-aout-as and pdp11-aout-ld)
- Build/install simh to emulate the PDP11
- Build bin2load from https://github.com/jguillaumes/retroutils
  This utility is used to modify the a.out binary generated by the pdp11 as/ld
  into a "lda" binary which can be load'ed directly by simh during emulation.

Using these instructions I was able to successfully complete the "Preamble"
step of porting documented in pseudo/code for the PDP11 port.

01 Dec '22
----------
Starting at step 0 of the porting work for PDP11 brought me back to yet another
round of thinking about the format of code.prims. So far, I've used the
	code{ ... }code, inner{ ... }inner and fallthru
among other directives for the assembly language primitives of the x86 ports
but looking back at it now, I find all of that a bit too verbose compared to
the spareness of Forth's own : ... ; notation. So as an experiment, I'm going
to try doing an exercise in extreme minimalism: what if assembly code did not
use any type of decoration whatsoever?

So the plan is that assembly code will be written in code.prims in the format:
	forthlabel : assembly-line1 ; assembly-line2 ; ... ;
all on one line to improve the "code density". The "forthlabel" is just the
conventional forth word name and the assembly code delimited by the semicolons
implement that word.

Since this will be preprocessed by the genprims script anyway, I'm thinking of
putting a spin on it though, where ';' will serve multiple purposes which
hopefully won't cause me too much confusion down the line.

As mentioned above, the ';' serves to delimit independent assembly code lines
but the new spin on it is that it also serves to denote calling "next" if it
is the terminating character on a line. If the line is not terminated by a
semicolon, the expectation is that the code will fall through to the next line
of code below it. So code blocks that currently looks like this:

	code{
	foo bar
		line1
		line2
		...
	}code

will turn into this:

	foo : line1 ; line2 ; ...

Note that the assembly label "bar" in the original code is no longer needed
since it will be auto-generated by the genprims script. In the initial x86
port, "bar" was usually a copy of "foo" if "foo" was alphanumeric (for example
"emit emit") or an alphanumeric replacement (for example "@ fetch"). I've
tried to semi-automate this by using the forth label if it is alphanumeric.

Similarly, inner{ ... }inner code blocks that currently looks like this:

	inner{
	foo bar
		line1
		line2
		...
	}inner

will turn into this:

	foo : line1 ; line2 ; ... ;

Note the addition of the terminating ';' in case of "inner" blocks which is
meant to denote adding the implicit call to "next".

Code blocks that needed "fallthru" can also be denoted in the new scheme just
by leaving out the terminating semicolon. Hopefully, this will make for a much
shorter and crisper implementation.

Although the purpose of the overall project is to showcase a really small Forth
implementation, simh/PDP11 provides me 64K of RAM which is such a luxury that
I'm going on a splurge and use an entire 16 bits for each word offset. This is
a code size win even for jsr calls so I'm not going to go into contortions to
reduce the offset down to 8 bits - although that should be fairly easy as well.

03 Dec '22
----------
Getting output to the console working under simh was not too much of a hassle
since I was continuing to follow the really helpful notes at
https://ancientbits.blogspot.com/2012/07/programming-barebones-pdp11.html

I did simplify the code, a lot, though, based on the sample code from the
"PDP11 Peripherals and Interfacing Handbook", an online copy of which is
available from:
http://www.bitsavers.org/pdf/dec/pdp11/handbooks/PDP11_PeripheralsHbk_1972.pdf

Although I initially used the console device for output, one difficulty I ran
into with using it was with trying to redirect that output to a named file. In
the end, I decided that the struggle was not worth it and just decided to use
a different device (the line printer, LPT/LP11) since simh allows it to be
directly attach'ed to a named file.

Next, I just need to do the same thing for console input as well. Let's see
how long figuring that one out takes.

05 Dec '22
----------
Sometimes it is the simplest things that take the longest to get done. It turns
out the premonition I had about redirecting the input from a file as mentioned
in my previous journal entry turned out to be fairly spot on.

My first attempt at implementing "key" was to use the console device and it
worked without much debugging - using the sample code from Digital in the
"PDP11 Peripherals and Interfacing Handbook" available from:
http://www.bitsavers.org/pdf/dec/pdp11/handbooks/PDP11_PeripheralsHbk_1972.pdf
came in pretty handy again.

Since I want to be able to automate the testing though, the next attempt was
to redirect the input from a file. I initially tried to use the same approach
that succeeded for me with "emit" (where I used the LPT device instead of the
DL11 console output). I thought I could attach the "Paper Tape Reader"/PC11/ptr
device to the input file and change the addresses from 017756X to 017755X and
call it a day. But for some unknown reason I haven't been able to get that
working so far. Running ex'amine on the device shows that the data exists as
expected but the code kept looping as if the data wasn't available. Rather than
spend even more time on trying to fix whatever was broken, I decided to read
through the simh docs to see if there was another device I could test instead
but happened to see the "send" command that allows you to inject data into the
console input. So for now, I've decided to use that feature as a workaround.

Given the time I've spent trying to get this working on simh, I now wonder if
it wouldn't have been faster to just write yet another emulator for the pdp11
just like I did for the x86. Perhaps, if I get stuck again, that's just what
I'll do.

06 Dec '22
----------
For implementing the data stack on the PDP11, there is a literal profusion of
choices since any of the PDP11 registers can be used as the data stack pointer
(given the PDP11's flexible addressing modes).

Since I want to see if the native/machine stack can be used for the return
stack, I'll choose the next available register (r2), rather than r6 as the
data stack pointer. The current register mapping is: R0: IP, R1: TOS, R2: SP

The remaining decision is about where to place the data stack. I'll make the
same choice that I made on the x86 port, which is to have it grow to low memory
starting from the beginning of the text area. So the current memory layout
looks like this:

			0x100 -> higher memory
	  ------------------------------
	   <- data stack | code/text ->
	  ------------------------------

07 Dec '22
----------
During the x86 port, I chose to use the macro features of the x86 assembler
to do all of the macro expansions that were needed when a Forth word used a
"lower" level forth word. For the PDP11 port though, I want to try something
different and have most of those expansions done by genrom instead. This seems
to be a cleaner approach than the ugliness of the x86 version where I have
to disambiguate between the macro expansion and a regular call by using '_' to
prefix the words that needed to be expanded.

So this required a little bit of addition to genrom's capabilities.

In the x86 port, I was using 8 bit offsets so all of the addresses were stored
as offsets from the base of the text area. Since I'm using the full 16 bits
for the PDP11 port, I can store the addresses as is.

08 Dec '22
----------
While working my way through "step 5" to implement conditionals on the PDP11
I decided that the scope of this step is too large and needs to be broken up
into smaller steps which are finer grained and more easily tested.

I also found that using "jmp" as a label seems to cause a hiccup for the
PDP11 assembler so it needs to be renamed to something other than "jmp".
I'll pick "j" as the replacement name, for now.

So, my solution to address these issues is to separate out the support for
implementing the primitives "j/jz/jnz" into 3 sub-steps which I'm calling
steps 4.1, 4.2 and 4.3 and then follow that up with the implementation for
"if{ ... }else{ ... }if" in genrom (which remains the same as before) as
part of the original "step 5".

I chose to use the floating point notation for the newer steps since it
allows me to not have to redo the numbering for all of the the other later
steps, thus keeping those step numbers the same, just in case they are
referred elsewhere.

Since it is quite useful to be able to test each of the basic "j/jz/jnz"
primitives independently of the language support (which is only added later
in "step 5"), some standalone/newer tests for these steps have been added
to rom.4th as well. This change then snowballed into requiring changes to
test.inp and test.expected as well. So while I was there I decided to clean
up the conditions used for the earlier tests from "step>N-1" to "step>=N"
which makes it easier to match up each test with the corresponding "step"
during coding and testing.

Since more granular steps are being added, I decided it is safer to test
it all out on the x86 ports first before trying it out on the PDP11 port.

One addition that I've made to the genrom feature set is the ability to
use "immediate offsets" which are different from the "immediate literals".
The "literals" are the usual Forth literals prefixed with the lit operator
and can be denoted as bare numbers/variables or prefixed with the $ notation.

The "offsets" are new and are used for encoding JUMP offsets which don't
need to be prefixed with 'lit' - they are denoted using a '#' prefix.

09 Dec '22
----------
Today was a fairly productive day as I cranked away at most of the easy
parts of the port. The next set of primitives are the hard ones since they
usually require you to pay attention to a lot of detail. I did start off
thinking about how to implement exec/enter/exit/call and have some ideas
about tying it to the PDP11 JSR instruction but that needs me to use the R6
register instead of the R4 register which is used currently.

I'm tired now though and I think all of that can wait for another day.

12 Dec '22
----------
I have a decent implementation of exec/enter/exit/call now, I think.

Trying to think of the issues that slowed me down, one obvious thing in
hindsight is the GNU assembler's violation of the law of least surprise.

My expectation was that "jmp r" where r is a register containing the
address to jump to should "just work". I found the hard way that the PDP11
GNU assembler expects this to be "jmp (r)" but since there was no error
either way, I had to spend some time looking at various docs to figure out
what was going on. Once past exec, enter/exit was the next gauntlet. I had
an idea of using JSR to do the call/return linkage and that panned out well
because all of the complex link chaining is automatically handled by the CPU.

Here also, the elegance of the PDP11 in the flexibility of JSR linkage shines
through. Looking at the history of PDP11 and Forth on wikipedia, it looks
like both are of about the same vintage (late 60's) and they seem to be a
perfect fit for each other.

15 Dec '22
----------
I found and fixed a stupid bug that managed to crawl into the code. It was
subtle, asymptomatic, and serious enough to cause memory corruptions and
it turned out to be an unnecessarily long and drawn out debug exercise.

The symptom was that although the simulation ended successfully and the test
passed, I noticed that the address at which the simulation ended was not at
the expected address. On the PDP11, halt's opcode is 0 so if the code goes
off into the weeds and accesses an uninitialized address with content 0, it
will halt right there instead of where it was expected to halt. Since "call"
is a tricky beast to implement, I was being fairly cautious and luckily was
able to catch the problem (although it was asymptomatic since the test itself
succeeds)

After a boatload of debugging using simh and struggling with the stupid
oct (used by simh) <-> hex (used by gas) conversions, I finally figured
out it was due to memory corruption of the instructions in the code area.

The cause of the memory corruption was because the return stack which grows
to low memory was initialized to the end of the code area for primitives
instead of the very tail end of the "rom" and this happened because the
"mem" label was not really at the tail end of code (including rom) but in
the middle of it (since it was defined in code.prims).

So although the debugging/understanding of what was going on took a while,
the fix was trivial: just place "mem" at the very end so it just needed
to be moved from code.prims to forth.S

---

After that bug was fixed, I ran into yet another bug with the same symptoms
- this one turned out to be bug in "call" itself since I was unnecessarily
incrementing the instruction pointer (since I used the x86 code as a template)

With both bugs fixed, the tests pass and emulator reports the halt happening
at the expected/right address, currently at PC: 000420

---

While doing an initial/quick browse of the PDP11 instruction set, I'd seen the
ASL/ASR instructions for shifting bits. Since these could only do 1-bit shifts,
I decided to defer the implementation of the shift operators << and >> until
they were really needed (and loop operations could be fleshed out). That time
has now arrived and my choices are to either implement this in Forth using
loops or do a native implementation (using loops in the assembler)

Since using a Forth loop would have less performance than native loops, I
decided to use assembly code and the initial implementation looked like this:
	<<     : nip ; 1: ; asl nos ; sob tos, 1b ; t_n ;
	>>     : nip ; 1: ; asr nos ; sob tos, 1b ; t_n ;
But reading through the PDP11 docs again, I noticed yet another opcode: ASH
which can be do multiple bit shifts. So the final implementation uses that.

Which means I could have saved all of the effort that went into the commit
titled "Move the shift operators to a later step". In any case, I assume
there will be microcontrollers that can only do 1-bit shifts so I hope all
this work was not a complete waste of effort and might come in handy later.

16 Dec '22
----------
As of the last commit from yesterday, the PDP11 Forth runtime can be considered
complete so I've included the PDP11 under the "allsteps" regression step in
the toplevel makefile.

---

Comparing sizes with the x86 port, without the tests compiled in, the PDP11
binary weighs in at 422 bytes (including initialization) where x86 needs 338
bytes. The additional overhead is partly because of using 2 byte offsets and
also the fact that x86 byte opcodes can be a tiny bit more compact than the
PDP11 opcodes which need atleast 2 bytes.

The PDP11 binary with all of the tests and initialization code clocks in at
1828 bytes compared to 1236 bytes for the x86 binary. Most of this difference
boils down to the fact that I chose to uniformly use 2 bytes for all Forth
words instead of the hybrid scheme on x86 which uses 1 byte for primitives and
3 byte calls for defined words.

---

The part I like best about this port is that code.prims has been whittled
down to just 60 lines of code. So if we use Fred Brooks' productivity metric
of ~10 lines of debugged code per day, for a "regular" programmer, I'll
guesstimate that a new Forth port can be completed in about a week (or two),
assuming a decent architecture like the PDP11.

---

So, where to next? I think I have a couple of choices:
1. Shrink wrap the x86 and x86-as code.prims just as I did for the PDP11
	- $TECHDEBT, nah!
2. Start off on a new port to one of the architectures listed in PORTING
	- Just completed one, nah!
3. Use the runtime I already have to create a Forth REPL for the PDP11 (or x86)

I think I like option 3 best so that's what I'll be spending some time on next.

18 Dec '22
----------
I've decided to go ahead with the REPL implementation to see how well it fares.

The "real" Forth REPL needs to read in "tokens" (which are defined as any
sequence of non-whitespace characters) and look them up in a "dictionary" and
either run the code (if it is found in the dictionary) or attempt to turn it
into a "literal" number (if it is composed of numeric characters).
If it doesn't match either of those categories the REPL could report an error.

As usual, I'll start off with small changes that I can test easily. So to begin
with, the only thing that the REPL does is read a "token" from the input. This
functionality is called "parse" in some of the Forth implementations that I
looked at so I'll stick to that convention.

Most implementations also use an input buffer to hold the bytes but since it
can be done in a single pass, I'll use the unallocated area for that purpose so
that the memory layout doesn't have to be fragmented into even more segments.
So this breaks with the usual Forth convention of needing words such as TIB
#TIB >IN etc but I prefer the simplicity of what I've done and hope that it
doesn't turn out to be too simplistic.

Looking ahead and planning for ports to other processors, it makes sense to
continue with the "step"wise addition of functionality that I've been using so
far. So the changes that I've made so far have been ifdef'ed under step 39.

To sanity test the implementation, the length of the token that was read is
verified and in addition, it checks the returned location where the string is
stored and also verifies the start and end bytes of the token that was read.

Testing these changes showed that it worked on x86 but failed in a weird way on
the PDP11 simh emulator despite the fact that the changes tested were identical
in both cases. Before lugging out the big guns for debugging the PDP11 issue, I
had a gut feel that the return stack was overflowing and based on that hunch I
bumped up the return stack size and luckily enough that fixed the problem.

Rationalizing about this later, it is obvious that the x86 version was not
affected since the return stack grows to higher addresses (which is currently
unused) whereas on the PDP11 the return stack grows to lower addresses (ie
toward the code area) and any stack overflow will result in overwriting and
corrupting the code area resulting in the weird errors that were observed.

Looking at the emulator output (for the x86) does show that the return stack
size had reached its configured limit. So, for the "real" fix, I've doubled
the configured stack size for the return stack on both the x86 and the PDP11.

It was just dumb luck that the problem was diagnosed fairly easily and I'm
glad this turned out to be an easy fix rather than yet another long drawn out
nightmare debug/redesign exercise.

19 Dec '22
----------
Continuing with the exercise of incrementally adding functionality to the REPL,
at this step (step==40), I've added support for turning a numeric string (read
by "parse" from the input stream) into the equivalent integer when the "state"
variable is non-zero (ie in "interpret"ing state). I've named the word that
does this "atoi" after the C library function that does the same thing.

20 Dec '22
----------
I'm starting to work on adding a dictionary and that brings up a philosophical
question: How much Forth do you really need?

Adding the dictionary manipulation routines (which in conventional Forth are
typically named "create" and "find") requires that the existing "primitive"
words and "defined" words will now need additional space to store their
"metadata" with the dictionary name and header in addition to the "data" (with
just the executable code). This additional requirement for ROM/RAM may exceed
the hardware capabilities that a really "small" microcontroller may have.

The most "minimal Forth" might be one which has just the data stack in RAM
and a bunch of primitives saved in ROM with all of the heavy lifting done
via "metacompilation" performed on the "umblical host". This can easily run
on boards with just a few bytes of RAM and very little ROM (say, less than
about 256 bytes of ROM, if we use something like the single byte offset
scheme that I used in the original x86 implementation).

The next step up might be to add a return stack which increases the RAM
requirements by a bit. Assuming N levels of nesting with 16-bit return
addresses requires N*2 bytes of additional RAM. For example, 4 levels of
call nesting and 4 data stack elements can easily fit within 16 bytes of RAM.

With a larger ROM, it may be possible to have a "static dictionary" stored on
the target (rather than on the host). This allows us to have something close to
a regular interactive Forth except the ability to add new definitions and we
are getting closer to the eventual goal of getting rid of the "metacompilation"
step. I assume that a 512 to 1KB ROM might be sufficient for such a standalone
Forth implementation which can support "find" but not "create" since supporting
"dynamic" dictionary additions enforces the requirement for a larger RAM.

Finally, with an even larger RAM, say 512 bytes or more, it will be possible
to have an "extensible dictionary" which can be used to define new words
residing on the target (with, say, 64 bytes reserved for data+return stack)
and have a completely standalone Forth target which can dispense with the
"umblical hosted metacompilation".

Thus we can see that there are effectively 4 "levels" of Forth needed.
For lack of better names, I'll refer to these "levels" as:
1/4 : "oneforth" (pun intended), which has only primitives and a data stack
      ROM : ~256 bytes, RAM : in the single digit byte range?
2/4 : "twoforth" which has definitions and a return stack (in addition to
      the primitives and data stack that "oneforth" has)
      ROM : ~256 bytes, RAM : 16 bytes (or thereabouts in two digit byte range)
3/4 : "threeforth" which has a static dictionary (in addition to the primitives
      and definitions and the two stacks that "twoforth" has)
      ROM : ~512 bytes, RAM : 16 bytes (or thereabouts in two digit byte range)
4/4 : a full fledged "fourforth"/full/regular Forth with a dynamic dictionary
      in addition to the rest of the bells and whistles from "threeforth".
      ROM : ~1024 bytes, RAM : 512 bytes or more - to hold the dictionary

So the answer to my earlier question: How much Forth do you really need?
is "it depends" so my response is to provide 4 options in the makefile
(as named above) and let the user who is stuck with a specific choice of
microprocessor decide how much Forth they really need.

Since microcontrollers come in various sizes, I'll also need to think of a
"shrink to fit" capability rather than the current incremental "step" wise
implementation such that only the closure of the set of all words required
from rom.4th gets pulled into the final ROM image.

22 Dec '22
----------
This entry is just a documentation of the debug exercise I went through, to fix
a bug, that cropped up while adding dictionary headers to all the "words".

I'm documenting it here simply as a reminder from "current me" to "future me"
in case other issues like this pop up on other architectures, as part of any
future porting exercises, by which time I expect I'll probably have forgotten
many of the more intricate parts of the plumbing. My hope is that this
documentation will help with making those debug exercises faster/smoother or at
least more productive.

Ok, so lets start with the problem. I'd made some code changes, primarily to
the script (genprims) that turns code.prims to assembly to generate dictionary
headers for each of those primitives. Testing it was resulting in a failure
only when the dictionary headers are generated, whereas things work as expected
when the headers are not generated. With the dictionary headers in place, I was
getting the following error from the pdp11/simh emulator:
	Trap stack push abort, PC: 000416 (HALT)
Using bc, we can map this octal address to the hex value:
	obase=16
	ibase=8
	000416
	10E
And subtracting 100 from 10E give address 0xE which can be looked up in the
assembly listing file which maps to:
			bye:
	000e	0000		halt
So it appears that it halted as expected, but why does it report that strange
"Trap stack push abort" error message?

Since the "stepfile" approach gives me a means of testing this at small code
change increments, I decided to give that a shot to find the earliest change
that triggers this bug. Running "make allsteps" and waiting for a while until
it fails and then running "head -1 fpp.config" gives me:
	step=22
which shows that the earliest failure is triggered at step 22. I decided to
confirm that things were really working at the previous step by setting the
step value to 21 and rerunning make :
	cd pdp11 ; sed -i 's/step=22/step=21/' fpp.config ; make
This to my surprise showed that that the test actually had failed even at
the earlier step 21 with this error:
	Trap stack push abort, PC: 000612 (JMP @(R0)+)
Unfortunately, this is not reported as a non-zero exit by pdp11/simh so despite
the error, make saw it as success and moved on to the next step.

I could change the makefile to handle anything other than "HALT instruction"
as an error and rerun the whole regression test with "make allsteps" to see if
I can catch this error much earlier. So I went ahead and did that and after the
usual long wait for the regression failure, and using "head -1 fpp.config",
just as before, it turns out the earliest failure actually happens at step 14
and the error is the same as the one that happened at step 21:
	Trap stack push abort, PC: 000612 (JMP @(R0)+)
Again using bc to do the oct->hex conversion:
	obase=16
	ibase=8
	000612
	18A
Subtracting 100 from 18A gives us offset 8A, which maps to the fetch/@
operator (by looking up address 8A in the forth assembly listing):
	96                    lbl007:
	97 0088 4112           mov (r1), r1
	98 008a 5800           jmp @(r0)+
So for context, what is happening is that at step 14, we have added the "here"
variable and we are fetch'ing its value and that for some strange reason fails
when we add the dictionary header (but works fine when there is no header).

Since I'm aware of alignment issues (from the time I worked on SPARC at Sun
Microsystems) the problem is obvious: the addition of the header made the
location of the "here" variable unaligned, so all that is needed to fix this
issue is to add a alignment directive (".align" in the case of binutils) ahead
of variable declarations.

If I was a newbie who was not aware of processor alignment issues, I guess the
next step might have been to trawl through the code in SIMH to figure out
exactly why it reports that error, but in this particular case, that additional
step was not required due to my earlier experience with these types of issues.

If I was a newbie working directly on the hardware and ran into something like
this, I assume it would result in either grey hair or maybe no hair ;)
The hard lesson here might be : always use an emulator - but that can come with
its own share of latent bugs especially if the emulation does not perfectly
match the hardware.

After fixing this alignment issue with variables in the genprims script, I then
decided to run yet another round of "make allsteps" in the hope that I was past
the entire class of such problems but it again ran into the earlier failure at
step 22 (which was the first problem that I had documented above, prior to the
step 14 failure).

Since alignment issues were top of mind for me, and it is at step 22 that the
generated definition for "bl" is used for the first time, it was fairly clear
to me that this issue was also due to not having an alignment directive for the
generated code produced by the genrom script. So that script was also modified
to generate the ".align" directive ahead of definitions as well.

In hindsight, it is clear that like most debugging exercises, cracking it was
a mix of grunt work and dumb luck. The "lucky part" was in observing that step
22 was not the very first failure and tracking the very first failure all the
way back to step 14 where it was easy to figure out the alignment problem. Once
that was out of the way, seeing the new issue again at step 22, and putting 2
and 2 together was a no-brainer. I assume things would have been harder if
these were encountered the other way around (ie in the opposite order).

Anyway, running the "make allsteps" regression step again after making these
two changes resulted in all of the tests passing without any further breakage.
I hope documenting all of this in gory detail now turns out to be useful later.

For now, the addition of the dictionary headers has been done only for the
PDP11 port - which I'll use as the "primary" port going forward. Adding the
dictionary headers to the x86 code is the next step. Since x86 supports
unaligned access, this bug will not be encountered there so I hope that the
addition of the headers to the x86 port goes more smoothly than this.

23 Dec '22
----------
Now that the dictionary support for x86 GNU "as" is done, it is time to look
at repeating it for the x86 nasm port as well. Since the initial bootstrap
implementation was done on x86 nasm, it has a makefile which is different from
that of the other ports. So as part of this exercise, I decided to "demote" it
a bit so it is no longer considered the "primary" port and it is now just "yet
another" port. This change also ensures that all of the makefiles now follow
the same template but getting there needed some major surgery to the x86 and
the x86-as makefiles since the x86-as makefile had some implicit dependencies
on the x86 build. But all of this is technical debt and in preparation for the
new year, I might as well pay it down now rather than later.

So now that the dictionary headers are available for all the current ports, I
plan to take a small break from all this for a week (or two) and just relax
over the holidays so here's to hoping for a refreshed, relaxed and wonderful
New Year.

06 Jan '23
----------
As I was getting ready to add the functionality to "exec" words from the repl,
and thinking about how to code something like "lfa2cfa", I realized that the
align directive used in PDP11 has now turned into a stumbling block since the
runtime does not have any meta data from the build to figure out if a padding
alignment byte was added or not. So the only choice apparent to me is to rework
the dictionary header layout by shuffling the fields around so that the padding
is kept out of the way.

The new header format (which, btw, completely breaks with the traditional Forth
header layout) can be described using the simple ascii diagram layout shown
below where the ^ symbol marks alignment boundaries:
	... | align | pad | nfa:(name ... | count) | lfa | cfa ... |
                    ^                              ^     ^
The layout could also be described more formally using this C'ish pseudo code:

	struct name {
		optional byte alignment[...];
		optional byte pad[...];
		byte name[count];
		byte count;
	};
	struct dict {
		struct name nfa;
		struct dict *lfa;
		byte cfa[...];
	};

The alignment bytes are used only if the previous dictionary entry ended on an
unaligned byte boundary. The pad bytes are used so that the name field always
ends at an aligned byte boundary.

Using this new scheme, it is clear that to get to the nfa from the lfa, we
just subtract the count (and unlike the earlier scheme, the padding and/or
alignment bytes are not in the way). Going from the lfa to the cfa is also
trivial (just add "cell"). The reverse mapping from the cfa to lfa also becomes
trivial (just subtract "cell"). This would have been much harder to do with the
traditional Forth header layout, so, all in all, I think this scheme is a much
better layout than the conventional Forth dictionary header layout.

Since making this change will regress the tests at steps 41, 42 and 43, I've
decided to rollback the step value to 40 and just make the dictionary header
changes after only a manual/visual inspection. I'll add the modified tests back
in at each step progression rather than turn this into one humongous commit.

07 Jan '23
----------
Adding support for exec'ing words from the repl exposed a bug that many of the
words did not have dictionary headers (but only on x86). It turns out that the
generation of the dictionary headers was not being done correctly for many of
the x86 specific code.prims directives. I'll attribute this to the existing
$TECHDEBT that genprims (and genrom) in each of the ports are copy-pasted. At
some point I should consolidate all of them and in addition have a unified
format for code.prims as well. For now though, I've just fixed the bugs in
genprims (in both x86 and x86-as).

08 Jan '23
----------
With the support for exec'ing defined words from the repl, "threeforth" is
in some sense complete since we can now interactively "exec" all the variables,
primitive definitions and Forth definitions which are available as part of the
dictionary. Since two different types of "thread"ing are used in the x86 and
PDP11 ports, I've added a config variable called "THREAD" to distinguish among
them. The x86 version which uses an opcode to prepend the cfa is called thread
type 1 and the PDP11 version which uses a bare cfa is called type 2.

The previous commit added the requirement that the "latest" variable needs to
be the last variable defined in code.prims since it is used as the boundary
between variables and primitives. This commit now adds another such requirement
that the definition of "bl" needs to be the very first Forth definition since
it is used as the boundary between primitive definitions and Forth definitions.

With this commit, all of the words that are already in the dictionary can be
run directly from the repl. As I've previously discussed in the entry dated
20 Dec '22, additional functionality to extend the dictionary is possible by
adding more Forth definitions. Even on relatively low-end microcontrollers, the
ROM tends to be fairly beefy, so this implementation proves that having an
easily portable and interactive version of Forth that can run even on the
lowest end microcontrollers is quite possible.

Currently the PDP11 ROM usage, (without all of the regression tests included),
clocks in at 1550 bytes and the x86 usage weighs in at 1217 bytes. With all
of the regression tests included, the PDP11 needs 3066 bytes and the x86 usage
is 2212 bytes. The "gensize" perl script which is part of this commit was used
to generate these numbers. I've also added this to the makefile so "make size"
should generate these results as well.

The runtime RAM usage can be estimated by running the the x86 emulation. RAM
usage, with all the tests enabled, shows that just a paltry 24 bytes for the
data stack and 12 bytes for the return stack are sufficient. Without the tests,
the usage remains at 4 bytes for data stack and 0 bytes for the return stack.
In addition, the static variables use 6 bytes.

So I'll go ahead and stake a claim that the "threeforth" version of Forth which
can be called interactive, (for some definition of exactly what "interactivity"
means in this context), can easily run even on microcontrollers that have less
than 32 bytes of RAM (if the current set of tests are disabled).

What threeforth cannot do is create new dictionary entries at runtime, which
one may claim is the essence of Forth. So now that threeforth is done, I can
now start on a final/fuller version of Forth (which I had called "fourforth" in
the entry dated 20 Dec '22) which can create dictionary entries and link them
to the older entries in ROM and exec them at run time for "full" interactivity.

10 Jan '23
----------
While working on this set of code changes, I realized my lack of foresight in
not providing something like "#}else{" and "#}elsif{" directives in the "fpp"
script. For now, I have to be very careful with the repeated use of "#{if" and
"#}if" pairs to make sure that these directives don't result in overlaps and
also cover all the cases. Perhaps I should follow Rust's example and enforce
complete coverage for all sum types, while I'm at it ;)

So far, for the Forth comments, I've been following a "structured commenting"
style where '[' stands for the "rest of the data stack" and ']' stands for the
"rest of the return stack" with '|' marking the boundary between them. Input
was denoted using '<' and output using '>' while memory addresses and values
were documented using "(addr:value)" with "//" used for additional clarifying
comments. Now that the dictionary can be modified at runtime, I'll extend that
notation a bit to use '\' to denote the contents of the dictionary.

The commit of the allocation (alloc, alloca) routines which was done yesterday,
marked the start of the implementation of "fourforth". Today I'm getting into
the meat of the implementation with the definition of "create" which "parse"s a
"token" from the input stream and adds it as a dictionary entry. Once this out
of the way, I can start working on the repl to add state handling and provide
a facility to deal with "immediate" words.

11 Jan '23
----------
In Forth, the "state" variable is used to track the transition from "interpret"
state (usually denoted by 0) where all words are exec'uted within the repl to
the "compile" state (usually denoted by 1) where all words are appended to the
latest word that was create'd. The conventional Forth word that does the switch
from 0 to 1 is '[' and the complementary word to switch the other way is ']'.
The state diagram that compactly expresses this is:
	state	event	nextstate
	0	[	1
	1	]	0
Since I've appropriated '[' for commenting purposes, I'm going to rename them
run[ and ]run which calls out the fact that the bracketed code is run even at
compile time. These words are internally used by the Forth "define"ing word ':'
and its complementary pair ';' which is the "immediate" word used to mark the
end of the definition started by ':' which means the above state diagram needs
to be extended a bit as shown below:
	state	event	nextstate
	0	:	1
	0	run[	1
	1	]run	0
	1	;	0

Once "compilation" starts and we assemble a sequence of existing Forth words
into a sequence of cfa's to be exec'uted, we need a means of switching from
"compile" state back to "interpret" state. Rather than hardcode some kind of
a reserved word to do this, "immediate" words count as Chuck Moore's brilliant
solution to do this in Forth. "immediate" words will be exec'uted by the repl
even in "compile" state and this provides a generic escape mechanism to allow
all types of intermediate processing to happen while "compile"ation is still
in progress.

Enabling the addition of "immediate" words to the dictionary now allows me to
code up a full fledged Forth REPL. While "create" enables adding new dictionary
entries, "immediate" allows us to create words that can switch the state. So,
as the next step forward, I'll work on a repl that can take advantage of the
"immediate"ness of words that have been added to the dictionary.

12 Jan '23
----------
This is the first year in which I cannot call either of my parents on their
anniversary. After Dad died in 2020, Mom soldiered on for two years and this
year I'll miss both of them.

Happy 56'th Anniversary Apai and Mom! All of us miss you. :heart:

13 Jan '23
----------
The bulk of the work involved in testing out the code for the all important
Forth words ':' and ';' (which are used to define new words in Forth) was done
as part of the tests in the previous commit at step 50. So in this commit, I've
consolidated those changes into actual definitions. Rather than code up a repl
to use these definitions, I've decided to make the tests at this step call ':'
and ';' explicitly since I'm still thinking through how to make ';' immediate.
---
On a personal note, as of today, it is 3 years since Dad passed away from
cancer (multiple myeloma) at the age of 79. Miss you Apai. :RIP:

14 Jan '23
----------
Since empty definitions were proven to work yesterday, the next step I could
think of was to add support for compiling numbers into the body of definitions.
After making those changes, testing showed some weird behaviour. It worked with
no issues on x86 but consistently got into a hang state on PDP11. I spent some
time going over the code with a fine tooth comb especially the #ifdef'ed parts
and adding some debug prints for troubleshooting to make sure I had not messed
up something related to the PDP11 specific parts since the code is now starting
to be rife with ugly #ifdef's sprinkled helter skelter. Despite all that work,
I didn't make much headway with those debug efforts, until I remembered that I
had observed this kind of failure once before (see the JOURNAL entry dated 18
Dec '22). Based on that I suspected yet another return stack overflow. The x86
emulator reported that the return stack usage was 18 bytes (of the configured
20). This was close enough to the limit that I decided to bump it up to see if
the problem went away and sure enough after increasing it to 30 bytes (on both
architectures), PDP11 also started working without any hitches. Whew!

16 Jan '23
----------
Now that I'm getting to the part where the repl starts to get a bit more
complicated with the addition of immediate words and compilation of defined
words, it was predictable enough that I'd run into weird bugs. But these bugs
were nasty and seemed to literally crawl out of the woodwork. They slowed me
down quite a bit so I think it is worth documenting them here. I'll list them
in the order that I found them:
1. state was not initialized to 0 (it was initialized to 1 for the c@/c! tests)
2. cpl_ex used @ instead of c@ to access the state variable
3. cpl_ex and cpl_ex_imm expected an lfa but were passed a cfa

Bug #1 was a "wrong initialization bug" where the repl code expected to start
with interpreter state==0 but because of the tests (written long long ago,
which predictably enough, I'd forgotten all about), it had been initialized to
1. The fix was to initialize the state variable prior to calling the repl.
So that was a relatively easy bug to fix.

Bug #2 and #3 fall under the category of type bugs. Since Forth does not have
any notion of static typing (or any means of enforcing it), such bugs can
easily sneak in and strike at runtime. Bug #2 was almost a C-like type cast
bug caused by using a byte as an int.

Bug #3 was subtler since an address on the stack just looks like any other
address. The initial coding was done with cpl_ex and cpl_ex_imm expecting an
lfa on the stack. But somewhere along the line, while refactoring stuff, I
changed the repl to send a cfa and forgot to update the called routines. I
think the lack of static typing may rule out using Forth for large projects
unless rigorous attention is paid to handling interface changes such as this.

Or perhaps it's just me being tired and careless.

Anyway, with all of these bugs out of the way, things are finally working. Yay!

---

After all the struggles I went through to get compile time definitions working,
adding variables and primitives turned out to be a walk in the park. So at
step 54, I think I can call the repl functionally complete and fourforth is
done. The rest as they say is just a "small matter of programming".

Looking at the stats generated by the gensize script, x86 needs 3021
bytes total and 1774 bytes without tests while PDP11 needs 4146 total and
without tests it fits in 2280 bytes.

So here's to freedom from the slavery of code bloat (on MLK Day)!

For comparison, here's what C needs:
	echo 'main(){}' > x.c ; make x ; wc -c x #  8544 x
which shows that the generated binary needs 8544 bytes - to do nothing!
And for another example with Rust:
	echo 'fn main(){}' > x.rst ; rustc x.rst ; wc -c x # 3321352 x
which shows the Rust binary needs ~3.3 MB to do nothing although stripping
the binary does bring it down to "only" 297232 bytes. Granted this is using
rustc 1.50.0. Finally, while I'm pointing fingers, let's not leave out Go:
 echo -e 'package main\nfunc main(){}' > x.go;go build x.go;wc -c x # 1101232 x
which shows Go needs no less than ~1.1MB to do nothing and even the stripped
binary needs 737896 bytes. Like the Rust version the Go version I have is also
behind the times (go version go1.6.2), but I don't really believe any newer
versions are going to improve anything. So the "bloat prize", by a wide margin,
should go to Go.

That's enough of a rant (and probably an unfair one at that - I assume all
three languages have good reason to have large binaries). For Go, I assume it
is their runtime and for Rust I think it is probably the standard library. C's
bloat might also be due to the standard library. In any case, on machines with
gigabytes of RAM, none of this bloat really matters.

So I'll continue to chip away at the problem that I'm trying to address for a
really niche and extremely narrow problem space of microcontrollers which are
resource constrained in terms of ROM and RAM (and quite likely, power usage).
So, changing gears to look at next steps, I could start a new port to yet
another such microcontroller architecture. Since the two ports that have been
completed so far have been little-endian, I'm tempted to try a big-endian
architecture for a change to see if that turns up any new portability issues.

SPARC, maybe?

17 Jan '23
----------
Before moving on to doing yet another port to some other processor, I decided
to finish fleshing out the repl a bit more to add support for the conditional
and loop control structures. But before adding even that, the very first thing
I really need is a means of writing comments. The typical implementation of
comments in Forth is trivial - something along the lines of "10 parse 2drop" to
read everything upto the end of the current line and ignore what was read. Oh,
and of course it must be marked "immediate" since it can be used within
definitions. The fact that comments can be added to the language after the fact
without any change to the "original language" is one of the more jaw dropping
features that folks new to Forth often encounter since you run into it sooner
than the fact that loops and conditional structures can also be bolted on to
the "language", in almost the same way, almost as an afterthought.

But before I can go ahead with adding support for comments, I need a more
flexible means of switching between the test code in rom and the repl.
Currently I'm counting words to handle this switch. A more flexible approach is
to use the old "2ret+call" technique to implement a simple semi-coroutine like
mechanism. So that will be the very first thing I'll work on before attempting
to code the rest of the stuff.

---

After trying out a couple of alternatives, rather than use semi-coroutines, I
ended up with a simpler approach which is to just do a multi-level return from
a "longjmp" like word which I've provisionally called "3ret" (since it drops
off the top 3 levels of the return stack, on x86). Calling 3ret from within the
"outer" repl will return control back to the test. During testing, I found that
the PDP11 needed an extra layer of return stack unwinding but I'll leave the
name as is for now since I can't think of something more meaningful currently.

18 Jan '23
----------
Now that I have a reliable means of switching from the repl back to test mode,
I went ahead with adding the code to handle comments (which as I mentioned in
the previous JOURNAL entry, is fairly trivial). Initially I debated with myself
whether adding new definitions should continue to be done in defs.4th or should
be part of the "console input" via rest.inp. For now I've reluctantly decided
to add the definitions to rest.inp (mixed in with the tests) rather than adding
just the definitions to defs.4th since the outer interpreter is the place which
can process "immediate" requests. A different way to solve this might be to
define "immediate:" which take a parameter (just like create) but that also
requires entangling the code with the input stream. Another idea is to
introduce yet another defining word pair (say imm{ ... }imm, just like the
def{ ... }def pair) to declare words which are immediate. Of these choices,
sticking newer definitions into rest.inp seemed easiest. So that's what I've
ended up doing for now.

One side effect of this choice is that the entirety of the code needed for a
"full Forth" implementation is now spread over three different files:
code.prims, defs.4th and now, rest.inp as well instead of being centralized
or available in one "object" such as the assembly listing file (forth_dict.lst)
This also means that an accurate means of getting the ROM/RAM requirements
becomes harder.

I'll assume that the amount of additional new code that will be needed is not
a lot. So I'll forge ahead and revisit this decision if it turns out to be a
major problem down the line. I also have in mind the idea of a "shrink to fit"
tool which can be used at runtime to generate the closure of all dependencies
of any given word. So that might be another alternative way of getting a single
snapshot of all of the required code.

---

One issue that showed up during testing is that comments need the newline
characters to be passed through. The existing code goes out of its way to get
rid of them (for legacy reasons). So I've added some special casing in the
makefiles for rest.inp, to preserve the newlines. I have a special generator
("genrestinp" on PDP11) which sticks the newlines back in (via the simh/"send"
command) and on x86, rest.inp is special cased so that the newlines are not
egregiously removed.

23 Jan '23
----------
This entry is just an attempt at documentating yet another bug that I ran into.
Hopefully the steps I took here will be useful in the future when strange bugs
such as this pop up.

The bug itself was fairly old and was introduced over a month back (on Dec 15)
but I ran into it only now, while it lay in wait biding its time to pounce and
lay waste my time.

This one was also seen only on the PDP11 port and showed up only when I added
support for the looping constructs at step 59 although I think it should have
popped up at step 58 as well.

Anyway, to begin at the beginning, the symptom of the problem I was running
into was that the PDP11 test would fail at the assert added in step 59 while
the x86 test passed without an error running the identical code changes.

Rather than use simh for debugging, I decided to go with "print debugging" and
so I added an implementation of '.' to defs.4th which prints out the value at
the top of the stack. I added a "dup ."  after the call to "outer" at step 59
in rom.4th to see why the assert was being hit and to see what that incorrect
value was. Unfortunately adding this "print" resulted in a hang while running
make within the pdp11 directory. (Note: when you run into a hang in simh, you
need to use Ctrl-e to break out of the hang, not Ctrl-c).

So now that things are going sideways rapidly, the next "print based debug" was
to add a "dup ." within cpl_ex to get a bigger picture of what was going on.

Running make in the pdp11 directory again after adding the newer print also
resulted in a hang. Getting out of the hang with Ctrl-e worked but doing so
made "make" remove the test.dict output file. So I needed to run whatever make
was running by hand. Since make only needs to run: "pdp11 simh_dict.cmds", I
just ran it manually then waited for it to hang and pressed Ctrl-e to get an
output file. The output in test.dict showed that a bunch of cfa's were
processed in the outer interpreter but to get more context I added another
debug print this time by adding "dup emit" at the start of "append".

The next round of testing was: make + Ctrl-e followed by another manual run
of: "pdp11 simh_dict.cmds" followed by Ctrl-e and then look at the generated
output in test.dict. At the tail end of the output, I noticed something that
caught my eye: the comments were being treated as compile/"exec"utable words.
And this pattern started soon after the code in the definition of "}else{"
which calls "[compile] }if" was processed. This code was added to the code as
step 58 in the previous commit where it appeared to work (ie my tests did not
signal any errors at step 58).

Since it was clear that something funny was going on with "[compile]", the next
debug print that I added was to check the value of the "state" variable. Since
PDP11 uses a padded out word for state due to alignment issues my guess was
that this difference was somehow triggering the difference in behavior on the
PDP11. But that line of thinking didn't turn up anything useful but all of that
debugging helped to narrow down the problem which could be now be summarized
as: "[compile] }if" was expected to result in "}if" being defexec'ed but it
looked like that wasn't happening on PDP11.

So the new round of debugging focused on the following execution chain:
	outer -> repl -> cpl_ex -> cpl_ex_imm -> defexec
mainly to see why the "exec" path inside defexec wasn't being taken on PDP11
when it needed to "defexec" the "[compile]'ed" word "}if".

defexec calls "isdefn" so the question was further narrowed down to see why
"isdefn" wasn't returning a "true" flag (on PDP11). This helped narrow it down
to ">=" not returning true. I verified that the values that were compared were
sane by "print"ing them out using '.' so the only code left to check was ">="
which was just a shim layer over '~' and just browsing the code and seeing the
difference between the code and the comment was enough of a hint to figure out
the bug - which was that the PDP11 implementation of '~' mistakenly used the
constant 0xF000 instead of 0x8000.

In hindsight, looking back at the other commits made on 15 Dec, it looks like
it was, all in all, a pretty productive day with a lot of progress made for the
PDP11 port, but doing too much on one day may have made me careless enough that
I let this bug slip through. Note that the "proof comment" that accompanies the
code was correct while the code itself was wrong (and the code had diverged
from the comment). The simple test case used to exercise the code did pass so
I could also attribute it to insufficient testing. In any case, it seems clear
that the bug might have been just a typo - ie, not a "thinko".

26 Jan '23
----------
With all of the recent commits, the repl has been gaining a fair bit of
functionality and so I'll consider the addition of '.' in today's commit as a
good stopping point for a "feature freeze" since all of the features that have
been added so far should be more than enough to get a decent amount of code
written and debugged directly from within the repl.

So I'll go out on a limb again and declare "fourforth" as officially complete,
ignoring the earlier assertion in the JOURNAL entry of 16 Jan '23 when I had
jumped the gun a bit and declared, a little too hastily perhaps, that it was
complete. Between then and now, over the past ten days, I've added support to
the repl for many of the control structures familiar to most programmers:
# Conditionals:
	* Forth's "if/then"	: if{ ... }if
	* and "if/else/then"	: if{ ... }else{ ... }if
# Various types of loops:
	* Forth's "while" loops	: loop{ ... }while{ ... }loop
	* and "until" loops	: loop{ ... }until{ ... }loop
	* and "for" loops	: for{ ... }for
Writing meaningful "stack picture" comments are enabled using '[' and
"print based debugging" is possible using '.'

Definitions can be created using the conventional ':' and ';' although in my
own code, I prefer using the syntactic sugared def{ ... }def that I've been
using using all along in defs.4th - I've enabled this in the repl as well by
using a tiny shim that wraps over the existing defining words ':' and ';'

Obviously I have no intention of adding a boatload of even more features and
word definitions to make this implementation conform to any of the existing
Forth standards since that will just result in bloating it up beyond any
reasonable hopes of fitting it into small microcontrollers. So I expect
feature additions to freeze here but I'll keep an open mind based on further
testing and future experience gained on real hardware.

Obviously this implementation can be extended to your heart's content in any
way you see fit - but those changes belong in other "project specific" repos.

Barring any other bugs that I may run into, I expect there will be no further
changes to any of the existing files. The only changes I expect to make as I
port this to newer architectures/microcontrollers/cpus will be to create new
directories and add them to the top level makefile - perhaps even add them to
the "allsteps" make target for regression test, in case that becomes necessary.

So now that I'm clear in my mind about what not to do, the next question always
goes back to what I should work on next? In the entry for 16 Jan '23 I tossed
out SPARC as an option since it is big-endian. That still sounds reasonable so
I'll start to look at what tools in terms of build and emulation are handy.
Another option might be to look at any of the other architectures that are
emulated on simh and also have binutils assembler support. Given my familiarity
with that toolchain now, switching to one of those architectures might also be
an option if the SPARC port starts to look like too much of a hassle.

01 Feb '23
----------
After spending some time looking at a couple of big-endian architectures to
come to a decision on the next porting target, SPARC and Motorola 68000 among
them, I decided to pivot a bit and go back and fix up the C port which got
stalled along the way, a while back.

The rationale behind this approach is that C compilers exist for quite a few
processors and I know that SPARC and the m68k architectures are well supported.
So rather than try to write the bare metal assembly code directly from scratch,
it makes more sense to generate the assembly code using the C compiler's "-S"
option (for those processors that do have a C compiler) and then tweak that
output to run on bare metal rather than try to do all of the heavy lifting all
by myself.

Instead of just continuing where I left off with the earlier version of the C
porting attempt, I decided to just get rid of the old code and start from
scratch so that I can start using the "step wise" approach that I had tested
for the PDP11. This will give me yet another opportunity to debug any porting
issues when using the "step wise" methodology. Since the PDP11 port was the
first attempt at using the "step wise" approach, I've copied over all of the
generator scripts from pdp11 and modified them to get a working version of the
C port for step 0.

Since the purpose of this exercise is to make the code as small as possible,
I've used the -Os option to optimize for space and sprinkled a few "register"
declarations in the hope that the compiler can do some "magic" with it although
IIRC, "register" hints are ignored by most modern C compilers.

This should also give me a good opportunity to see how well the latest and
greatest versions of the C compilers fare compared to earlier versions versus
my own hand coded assembler versions.

The C compilers that I'll use for this exercise (tail output from cc -v) are:
	gcc version 5.3.1 20160413 (Ubuntu 5.3.1-14ubuntu2)
	clang version 3.8.0-2ubuntu1 (tags/RELEASE_380/final)
since they are the versions that are available by default on the really ancient
Ubuntu 16.04 distro that I have on my laptop. I'll compare these against the
newer release versions of gcc (which seems to be 11.x) and clang (also at 11.x)

03 Feb '23
----------
We are barely at step 3 and it looks like a byte offset which was sufficient
for my hand coded assembly code is not sufficient for the code generated by
the C compiler even with the -Os option. So in terms of code density, it is
pretty clear that the compiler doesn't seem to be much of a match for a
competent coder - even in this day and age. Perhaps ChatGPT can hallucinate
better code - but only after it has ingested some of my code I guess ;)

15 Feb '23
----------
I'm back at trying to find a new solution to the problem documented as the
very first entry in this JOURNAL (see the entry dated 11 Nov '22 - note that my
frustration at finding a solution then was part of the reason that I started
this JOURNAL). Since this time around I've chosen to use GCC's "labeled gotos"
for jumps, by necessity, the "rom" needed to be local to main (or whichever C
function happened to contain the labels for the "primitive" operations). Since
higher level "definitions" also need access to the "primitives", this implies
that newer "definitions" (which need to be part of the "rom", in some sense)
also need to be in data structures local to main (just like the "rom" array
itself). Unlike assembly code, C does not provide any means of referring to
individual array elements. One solution might be to do a second pass using
objdump to parse the generated binary to get the addresses if they were outside
the function (in the global name space). Since that sounds a bit too hacky, my
solution is to put each of the "definitions" in its own "rom" array and then,
(this is the clever part), add a layer of indirection using yet another array
that contains pointers to the start of each of these "definition roms" and hope
and pray that the C compiler does not insist on rearranging the ordering of the
various "definition rom" array elements.

With this setup, referring to definitions just needs the index into that array
and the index can be passed around as an int on the data stack without having
to do any casts between pointers and ints. Unfortunately this separation also
means that I now need a third "machine" stack to hold the pointer sized return
addresses. This change then triggers a domino effect change on the how rp@! is
implemented but I'll defer that for now to minimize the amount of code that
needs to go in as part of this change set.

21 Feb '23
----------
To deal with variables, the initial implementation starting at step 14 assumed
that a struct (called "ram") with an array (called "mem") plus some offsets
into that was a good enough abstraction. This allowed a clean compile without
all of the warnings about "pointer to int casts" which the compiler would whine
about if I had chosen to directly use pointers instead.

Unfortunately that abstraction runs into trouble starting at step 41 where I
need to traverse the dictionary (which primarily involves pointer chasing).

Given that parts of the dictionary could be stored either in "ROM" or in RAM,
depending on whether it was defined at compile time or run time, the "prev"
pointer of a dictionary entry could be either in RAM or in "ROM".

But given that the current abstraction can only access RAM, following a pointer
into the "ROM" won't work without additional changes. So my choices are:
1. Create a similar memory access abstraction for data in "ROM"
2. Copy the "ROM" dictionary contents into the RAM and use RAM for everything
3. Give up on the abstraction and just use pointers directly

The downside to (2) is obviously the higher RAM requirement and the downside to
(1) is that each memory access will then need an additional tagging scheme to
distinguish between RAM vs "ROM" access.

So I'm going to cave in and just use pointers directly instead of the previous
"array + offset" scheme. But this brings up the problem of whether the location
of the variables will be at a small enough address that fits in an int since
the default is LP64 (long and pointer use 64 bits, while integers are 32 bits).

On my x86_64/Linux laptop, running "nm" on the generated binary shows that
static/global variables are allocated at addresses which fit in 32 bits while
addresses on the stack appear to need all 64 bits. Based on that small bit of
information, it looks like I can safely get away with casting the pointer to an
int to access the data despite the compiler warning.

It is not clear though if this address allocation is true for all other OS and
compiler combinations, so to be future proof, the safer means of doing this is
to use 64-bit ints but I'm not going to bother with that for now. On compilers
which generate either ILP64 or ILP32 (ie integers and pointers have the same
bit width), things should "just work".

So, after doing away with the whole "struct ram"+offsetting into its mem array
scheme that I was using earlier, the new scheme declares the three variables
that are needed at bootstrap within a "vars" struct which is aliased using a
"varalias" character array pointer. The offset of each of these variables is
small enough to fit in a short (or even a byte actually) so that is used in the
rom array instead of the actual pointer (which will not fit in a short) but
that meant adding a new "var" primitive which turns the short offset into the
appropriate address pointer.

Since I'm switching back to using pointers directly, I also decided to do away
with the distinction between the "return stack" and the "machine stack" (which
was introduced at step 23) since I can now refer to ip addresses directly. So
I've reverted the code to match the earlier design that was used in the x86 and
PDP11 ports of using only a "return stack" since the "ip" addresses are small
enough that they will fit in an int.

Since there have been a boatload of changes, that affect earlier steps, I've
gone ahead and added yet another Perl script (called runallsteps) to ensure
that no regressions were introduced by any of these changes at any of the
earlier steps.

One of the weird issues that I ran into while debugging this set of changes
was a compiler optimization issue. Although the dictionary structures were
correctly generated by genrom and compiled without any errors, there is no
direct reference to any of them in the C code and so the GCC compiler decided
(probably since I'm using the -Os option to optimize space) that all of the
unreferenced dictionary related structs are not needed and stripped them out of
the generated binary. To workaround the procrustean attitude of the compiler,
an extra array was added that references each of the generated structs and also
added an assert which accesses a random struct element to hint to the compiler
that all of the generated structs are needed (none can be discarded).

Another issue that needed to be debugged and resolved was that the padding
generated by the compiler is at odds with the expectation that all the entries
are packed together in the dictionary. The workaround to this issue was to use
GCC's __attribute__((packed)) directive to eliminate the padding.

---

On a personal note, it's my Mom's birthday today but this will be the first
year I will not be able to just call and hear her voice as always. Miss you
Mom, Happy Birthday! :RIP:

22 Feb '23
----------
Although step 42 worked without any problems, at step 43, I ran into a SEGV and
with some debugging I found that the sigsegv happened when "here" was looked up
in the dictionary. Debugging some more, I found that although the dictionary
headers were generated correctly, for all of the definitions in defs.4th, the
dictionary headers for the primitives (including "here") which was generated by
the genprims script was being stripped by the compiler since I had forgotten to
apply the same hack that I'd done yesterday for genrom. Rather than continue
down that hacky route, I decided to go with a different solution which makes
the dictionary struct header exactly the same as the assembly version and made
sure to make this change in both the genprims and the genrom scripts.

The new dictionary header structure also eliminates the need for the array of
structs that was needed in the previous implementation since the assignment to
the "latest" dictionary header pointer variable ensures that all the structs
are marked as live by the C compiler so it does not try to strip them out.

I'm happier with this version than the clunky hack that I'd coded up yesterday.

23 Feb '23
----------
Compared to coding in assembly, coding Forth in C is actually turning into a
real PITA. To debug the issues that cropped up at step 44, I needed to add even
more debug printfs which helped to narrow down the issues.

The first problem turned out to be that the current tests assume that the repl
lookup of "here" returns an address which is writable. For the C port though,
I've marked the statically generated dictionary headers as "const" which makes
them readonly so that they can, in theory at least, be stored in a "ROM". So
I needed to add another layer of indirection for "primitive variables" in C
which have been wrapped in the dictionary header. Unlike traditional Forth, the
"cfa" of these variables is readonly and only contain a pointer to the "real"
variable's writable location.

This is workable but requires changes to the tests in rom.4th when variables
are accessed via the "repl". For now I've made an ugly band aid fix of adding
yet another configuration parameter called "prim_var_deref". If that is set to
1, it means that the repl needs to do an additional indirection on the cfa
before fetching/storing a value to the address of the underlying variable.

With that issue out of the way, the next issue I ran into was another segv.
Tracking it down with the debug printfs showed that the problem was that the
CELL size was still set to 2 (which was inherited from the PDP11 port). In this
case since we are using CELL size to step over the lfa and since that is a
pointer sized location in the C implementation, CELL needed to be configured to
8 instead of 2. This is just yet another band aid fix rather than a "real fix"
so that I can think through what exactly "CELL" should mean in this port.

Traditionally, in Forth, the CELL size is the native "word" size of the CPU on
which the Forth VM runs. But given the mix of "word" sizes I have used along
the winding path to reach this point, I think I need at least 3 different CELL
descriptors. The "short" bytecodes used in the VM proper need a CELL size of 2,
the "int" sized stack entries (in the data stack and the return stack) need a
CELL size of 4 and of course any "pointer" sized values need a CELL size of 8.
Obviously the "one size fits all" philosophy of regular Forth is not going to
fly well here.

Since it is fairly late now, I'm going to commit this fix for now and continue
to think about better options for a later commit. I think I'll just sleep on it
and see if there is a neater way to encapsulate this mess.

In any case, since the common code in rom.4th was modified, I ran the full
regression using "make allsteps" and the earlier ports haven't rotted away yet.

24 Feb '23
----------
While coding in assembly, I had the full freedom to intersperse code with data.
Since C does not allow that freedom (for good reason), I needed to do a little
backtracking to modify some of the older decisions made at step 45.

With the placement of the dictionary header for variables in "ROM" (which was
done at the previous step, step 44, yesterday), the older method of using the
location of "latest" to distinguish between "primitive definitions" and
"primitive variables" no longer works since the dictionary header is separate
from the actual variable that it wraps. So I needed to fall back to a more
traditional Forth like means of invoking the cfa contents (think DOVAR, DOCOL
etc) from the dictionary. So I changed cfaexec to directly "call" the contents
of the dictionary, thus restoring the earlier freedom of assembler code to mix
data with code which C had taken away.

Since common code was changed at this step as well, I ran the full regression
using "make allsteps" to make sure that "all is well".

25 Feb '23
----------
The traditional Forth technique of directly "call"ing the cfa is a much better
solution than the existing, (and in hindsight, pretty clunky) method that I'd
implemented (for x86 and PDP11). I'll stick with the new change only for the C
port for now and revisit the earlier implementations later as time permits.

27 Feb '23
----------
The porting of steps 47, 48 and 49 were, for the most part, smooth sailing. At
step 50 though, I needed to introduce yet another configuration parameter which
I've denoted as THREAD type 3, for the C port which uses a short 2 byte offset
for the "primitives". Although PDP11 also uses a 2 byte offset, the C port does
not use a leading prefix at the start of definitions so I needed to distinguish
between these configurations with yet another parameter. This also required the
addition of yet another non-conventional Forth word which I've called "s," (for
"short ,") to append a 2 byte little-endian short to the dictionary.

While I was there, I realized that the machinestack configuration variable
which was introduced a while back (and then removed later) was still hanging
around in the x86 and PDP11 config files so I've cleaned that up as well.

As usual, since common code was modified, I ran make allsteps as a sanity check

01 Mar '23
----------
There was another SEGV that needed a fair bit of debugging at step 52. By
dumping out the list of words in the dictionary, it was clear that some of the
dictionary entries were getting corrupted. With additional tracing, I tracked
the cause of the corruption down to an overrun of the return stack. Since C
uses 4 bytes for each return stack entry which is twice the size used on x86
(and PDP11), I've doubled the configured return stack size for C (from 30 bytes
to 60 bytes). Although this change has fixed the sigsegv, I need to think of a
better way to deal with issues like this longer term since I had run into the
identical problem earlier as well (while doing the PDP11 port).

Another long standing issue (which I've mentioned earlier on 23 Feb '23) is the
usage of CELL for multiple/different things. Since C literals need 4 bytes (as
opposed to 2 bytes for x86 and PDP11), I've created a new configuration param
called LITC which needs to be set in the architecture specific fpp.config file
and configured it for the C port to 4 and for x86 and PDP11, it is set to 2.

06 Mar '23
----------
I seem to be making progress on the C port one segv at a time. The latest segv
came out of left field - primarily since I'd forgotten a relevant detail, which
I'll blame on the distractions from real life (rains, roof leaks).

Due to all of the recent rains (which were a welcome relief after a couple of
years of fairly intense drought) here in California, the low slope roof on my
patio decided to go ahead and spring a leak. I think it was last repaired about
10 years ago so it was bound to fail any day now. As a short term fix, while
browsing around in the nearby Home Depot, I found a "repair and seal" tape with
an aluminum overlay called "Resisto" and used that to patch up the ripped seams
(at least the ones that I could locate). Fingers crossed that all of it will
hold up for the next batch of rains that are predicted soon.

Anyway, coming back to the sigsegv, it turned out that the old way of marking
the dictionary entry for ";" as an immediate word, "after the fact" as it were,
does not really work since the dictionary headers are marked "const" (because
they are stored on a read-only page). An obvious way to workaround this is to
make the dictionary headers writable by removing the "const", but this requires
them to be placed in RAM. Since one of the primary rationales that led to this
project is minimizing RAM usage, moving the headers to RAM is not a very useful
solution. So it is clear that making the headers "const" is obviously a "good"
constraint to have since it allows more stuff to be held in ROM but it also
implies that the "immediate" bit needs to be set in the dictionary header prior
to the C compilation. So this required changes to the genrom script for the C
port which then had the follow on effect that to maintain compatibility across
the various ports, I need to repeat that same set of changes to genrom 3 more
times for all of the other ports as well (ie x86, x86-as and PDP11).

To mark words as "immediate", I went back to an approach I'd considered a while
ago and rejected (see my earlier entry dated 18 Jan '23). I'd decided against
doing it at that point in time but with hindsight, my mind is now made up that
reversing that decision is the right thing to do. So this change introduces the
keywords imm{ ... }imm to define immediate words (ie to create the dictionary
headers marked with the "immediate" bit set)

Making this change also involved changes to defs.4th (since the definition of
";immediate" becomes superfluous and can be removed) and to rom.4th as well
(since it no longer needs to call ";immediate"). As usual, since there were
changes to common code, "make allsteps" was used to verify all that code churn
did not introduce any regressions.

With all of that restructuring out of the way, the rest of the work looked very
simple: just "call" the cfa from the REPL when "interpreting" and prefix the
cfa with "enter" when "compiling". So I went ahead and prototyped that only to
find myself running into yet another SIGSEGV. Tracking that one down helped me
realize that the leaky roof had led to stuff seemingly leak out of my brain as
well. ;)

I had to go look at the code to remind myself that "enter" in the C port was
partially intended to abstract away the fact that I can't squirrel away a 32
(or a 64) bit wide pointer into an array of 16 bit shorts. Although C by design
cannot introspect on it's symbols at run time, Forth's dictionary allows it do
just that. So instead of calling "enter", I've modified it to push the cfa onto
the stack (by wrapping it with a "lit"eral) and issuing a "call" to that cfa.

Now that I know that even a small context switch from working on code to other
stuff is enough to make me forget tiny details, I hope that the prediction of
even more of these rains (which will likely result in some more of these roof
leaks) will not result in yet another round of the coding context in my head
getting washed away as well.

08 Mar '23
----------
Getting steps 54, 55 and 56 verified was pretty easy but I ran into a fair bit
of trouble at step 57 : "support conditionals at the repl". The first issue was
the fact that jump offsets are 16 bit. While this works fine on the PDP11 since
16 bits happens to also be the CELL size, it doesn't work on C since ints are
32 bit wide. So the first change was to introduce a definition to store shorts
called "s!". Once that was sorted out, I ran into a second difficulty: since I
use the cfa uniformly across variables, primitives and definitions, primitives
such as lit and j/jz/jnz which use "immediate addressing" to get their operands
will not work (unless I change the code to match, which would make them pretty
inefficient). Since I just need a means of getting their values to store into
the dictionary, I've used the workaround of adding a new word called "#jz" to
do this - the '#' is meant to be a mnemonic that it is an absolute value (kinda
like the equivalent denotation used in assembly). An alternative to this might
be to define the conditionals in defs.4th where I won't need to jump through
such hoops but I guess there might be some value in minimizing ROM usage unless
absolutely necessary so I'll stick to the current approach. In any case, once
that issue was sorted out, the third bug I ran into was that the jump offset
wasn't calculated correctly. This turned out to be due to the fact that C does
pointer addition which scales the offset by 2 (since it was a pointer to a
short) so I needed to scale down the offset by the equivalent amount before
storing it into the dictionary header. Once all these fixes were done,
conditionals started to work as expected.

Since common code was changed, I ran "make allsteps" to check for regressions.

10 Mar '23
----------
At step 60, I ran into a SIGSEGV which turned out to be a pain to debug. So I
added a few more debug prints to "show" each token as it is being parse'd
within the repl in the "outer" interpreter. Using this, I was able to narrow
down the SIGSEGV to be occurring when the "for{" keyword was being executed. By
adding an additional debug print to the "call" primitive, the bug was sort of
easier to track down to a misinterpretation of how "r>" was supposed to work.

In the C port, I had chosen to make the handling of CFA's (after a dictionary
lookup in the outer interpreter) uniform across primitives, variables and
definitions (both static and dynamic). This differs from the earlier x86 and
PDP11 implementations. In the C port, invoking "r>" (via the outer interpreter)
will turn it into the following sequence:
	lit CFA_of_r>_in_the_dictionary call
where the dictionary entry itself contains the following sequence at the CFA:
	r> exit

In the x86 and PDP11 ports (and even in the code generated by genrom for the C
port), primitive invocations are turned into direct jumps to the native code
offset which does not use "call" - and this is the important part: it does not
affect the return stack.

The additional "call" layering to "r>" in the "outer" interpreter in the C port
was messing with the functionality of "r>" and was the source of the bug. So
the simple fix was to move the code for "compile" from rest.inp (which is
handled by the outer interpreter which adds the "call" layer) to defs.4th
(which is handled by genrom which keeps "r>" and ">r" as primitives) and that
was good enough to fix the bug. I'll call this out as TECHDEBT since this
violates the law of least surprise and is going to bite "unwary me" somewhere
down the line.

11 Mar '23
----------
Looking back at the very first journal entry, it was exactly 4 months ago that
I started this journal - primarily to vent about the fact that I was giving up
on the very first attempt at a C port because of my frustration with how much
of a struggle it had become to make Forth see eye to eye with the abstraction
imposed on the baremetal by the C compiler.

So now that I've successfully completed a "second system"/from scratch C port,
this is as good a time as any to look back and figure out lessons learnt and
what could be done better for the other upcoming ports.

Although my second attempt at the C port took much longer than I ever expected,
the end result gives me a deep sense of satisfaction since I think that it has
resulted in a much better implementation overall since the read-only/ROM and
read-write/RAM areas have well delineated boundaries now.

It was also a bit more pleasant to test things out since I could debug things
in userland instead of mucking around in a slow emulator. The protections that
are offered by running it with MMU protected pages makes it more likely to die
sooner with a SIGSEGV, in case of bugs, instead of chugging away and corrupting
random locations in memory as happened in the case of the PDP11 port.

One thing that is pretty clear is that the "step wise" approach that was begun
as part of the PDP11 port turns out to be a really good idea. Some of the parts
which took longer in the C port need to be examined to see if it is possible to
break them up into smaller, more easily tested/debugged chunks.

One thing that I'm surprised about is that it took me almost 6 weeks to get the
C port done (despite it being a second attempt). Now that I've completed 4
ports in ~5 months, I guess it might be reasonable to estimate that each new
port will take ~5-6 weeks.

Since this port felt like it was starting to take too long, I may have been a
little too trigger happy in adding techdebt along the way. In particular, I'm
unhappy with the addition of yet another THREAD'ing type (3) which has resulted
in some parts of the code becoming even more cluttered with conditional compile
directives than earlier. I also had to implement things a little differently
from the older ports since the static part of the dictionary is now read-only.

I hope to bring the other ports into sync with this implementation so I can get
rid of at least some of the parameter types from the fpp.config configuration.

Anyway, that's work for another day. Today, I'm just going to bask in the fact
that I have yet another port under my belt, which I've completed successfully,
and the quality of which is to my satisfaction, instead of being one of those
rushed "just get it out the door" things that are common in many $DAYJOBs.

14 Mar '23
----------
Before starting on the next port I needed to do some research on how to setup
all the tools (build+emulation/flash in case of real hardware) that will be
required for that CPU. For x86 (and x86-as), the choice for the build tool was
straightforward: nasm/binutils. For x86 emulation, I chose to code an emulator
from scratch although using other existing tools might have been a workable
solution. For the PDP11, binutils and simh turned out to be a good choice.

For the next port, I have a choice of picking either SPARC or m68k since both
of them are big-endian architectures and both of them have gcc/binutils and
qemu support. Unfortunately, qemu does not provide a documented/simple means of
exiting from the guest VM (other than generating a triple-fault and using the
--no-reboot option). There doesn't seem to be an architecture neutral means of
accessing the serial ports either. So my choices are to peek at the code for
other guest OS'es to see how they manage to perform a graceful exit from QEMU
or to take a look at the QEMU code itself. I don't relish either of these
choices since it involves having to wade through the millions of lines of code
that both choices have to offer.

As an alternative, I've started to look at unicorn-engine which appears to be
layered on top of qemu. libcpu might be yet another alternative although it
appears to be dead since the code on github is marked as a read-only archive.

Before going off to jump into the deep end on that research, I decided to try
and see if I could generate a profile of the running code in the C port to see
which primitives are heavily used and might be in need of optimization when I
eventually start on the native code implementations. Rather than spend too long
generating a well thought out design, I threw together a "quick and dirty"
hacky prototype which seems to be good enough to get the job done.

To get the profile (which was only enabled for the C port, since it was easy to
get it done there), the following steps are needed:
	1. Uncomment the "#define PROFILE" in forth.c
	2. Run "make clean" in preparation for the next step
	3. Run "make 2> prof.tmp ; tail -101 prof.tmp > profile.counts"
	4. Run "join profile.counts profile.names | sort -nk 2 | less"
	5. Clean up by running "rm profile.names profile.counts prof.tmp"
	6. Comment out the "#define PROFILE" in forth.c

Using the above list of instructions, I generated a profile from running the
build+tests, the output of which is shown below. It is sorted on the second
column (which tracks the number of times the primitive was called):
{begin:profile
	1 1 bye,bye
	14 1 inv,inv
	29 1 stick,stick
	31 1 lbl011,rp@!
	34 1 exec,exec
	39 1 lbl015,p!
	30 2 lbl010,sp@!
	38 2 lbl014,p@
	20 14 lbl004,|
	6 18 emit,emit
	43 19 lbl018,0=
	8 32 neg,neg
	0 79 next,next
	40 107 lbl016,<<
	21 337 lbl005,^
	41 369 lbl017,>>
	25 741 lbl007,!
	37 1363 call,call
	44 3308 var,var
	9 5242 jnz,jnz
	27 6165 lbl009,c!
	5 6265 key,key
	12 11263 inc,inc
	28 16527 pick,pick
	16 20377 dip,dip
	15 21303 nip,nip
	3 21336 lbl000,2drop
	24 21744 lbl006,@
	13 22702 dec,dec
	19 26095 lbl003,&
	4 27407 drop,drop
	26 28766 lbl008,c@
	32 29528 lbl012,>r
	33 29553 lbl013,r>
	17 47075 lbl001,-
	18 53971 lbl002,+
	11 70029 j,j
	2 70224 dup,dup
	42 75757 over,over
	7 86147 lit,lit
	22 86607 swap,swap
	23 86607 t_n,t_n
	10 95966 jz,jz
	35 113738 enter,enter
	36 115076 exit,exit
}end:profile

One surprising piece of info that shows up in this data is that there are 79
jumps to offset 0 (the row "0 79 next,next" in the data above). That equates
to a "nop" which isn't explicitly coded anywhere so I assume it indicates a
bug of some kind, so I think I'll track that down next.

Since this is not the profile of a real workload, it cannot really be used to
make decisions. But it does highlight some of the big hitters that I'll need to
be aware of when working on all of the future ports (or to optimize the earlier
ones).

15 Mar '23
----------
I tracked down the cause of the NOPs that I found in the profile yesterday to
the fact that variables are encoded in the dictionary using a pointer (within
the CFA). There is no way other than to use a pointer sized encoding for this
since the C compiler will error out, otherwise. Due to the little-endianness of
x86, the "short" offsets to which it is cast sees a pair of NOP's (after the
"lit" that precedes the variable address has already cast the pointer to an int
and skipped over the leading 4 bytes which contain the address).

I hope the following ascii diagram makes the situation clearer:
	----------------------------------------
	| lit     | address pointer   | exit    |
	----------------------------------------
	| 2 bytes | 4 bytes + 4 bytes | 2 bytes |

These 4 bytes are 0 filled -----^----- since the address happens to fit in
the preceding 4 bytes. Since these are 0's they are seen as 2 nops by the VM.

Since the nops are harmless and are just an artifact of the C compilation, I'm
going to ignore them and move on to the next port.

16 Mar '23
----------
One pattern that I've seen repeated in this project is that at every place when
I need to pick a new CPU, I agonize over the decision mostly because all of the
alternatives have some blocker that makes every single one of the available
choices fairly painful. My earlier choice of the PDP11 was in no small part due
to simh/pdp11 "dwim"ming along to my intentions without turning into a blocker.

So, here I am, at yet another fork in the road, and while I evaluate qemu vs
unicorn vs libcpu vs whatever else may show up in my research, my gut instinct
is telling me to pivot yet again - to something easier.

Since the entire point of the C port was to be able to generate assembly code
so that I could leverage that code without having to go through thousands of
pages of CPU architecture manuals, for each CPU that I want to port to, my
"light bulb" thought was: why not start with an x86 assembly language port?
Obviously this will be different from the earlier x86/x86-as ports since
1. It is a userland port and
2. It will be 64 bit, not a 16 bit realmode implementation, and the best part
3. It can run natively, with no emulators involved.

As an additional bonus, it will give me a chance to compare the code generated
by the compiler vs hand written code (in terms of both size and speed).
So that's what I'm going to do next while I continue researching alternatives
for how to easily emulate SPARC/m68k/other CPUs on my list.

17 Mar '23
----------
One of my observations about why it takes so long to do a port is that an
inordinate amount of time is spent on updating the JOURNAL entries. While it
certainly does help documenting various aspects of the design and also the bugs
encountered along the way, it is a big time sink. So in this new x86 assembly
"userland" port, I'm going radio silent until the port is complete.

I'll just document this one piece of info, before I switch off JOURNAL updates,
that I'm splitting up step 0 into smaller chunks since getting started can be
very painful as you research tools and figure out how to build the code as well
as fleshing out the infrastructure to do the emulation and test. This makes the
"runallsteps" script the final arbiter of the actual "steps" and I'll note as a
$TECHDEBT that at some future point in time, I'll need to update the steps that
are outlined in pseudo/code so that they are in sync with what I do in reality.

21 Mar '23
----------
This is an important enough piece of information that I'll break the radio
silence that I'd promised in the previous JOURNAL entry and document this here.

Since the x86 userland assembly port uses a dictionary layout that is aligned
with the dictionary layout that was used as part of the C port (but breaks with
tradition from the earlier ports which were done in assembly), I've decided to
document it in some detail since I assume this will be the format used by all
future ports.

I'll start with the layout of ROM which contains these parts (in this order):
- Start up/init code implemented in native/machine code
       Assembled from forth.S
- init and test "bytecodes"
       Generated from rom.4th by genrom and assembled from rom.s
- dictionary headers for the "primitive variables"
       Generated from code.prims by genprims and assembled from dict.s
       usual format: align; pad; nfa; lfa; cfa:{ lit ; $var_addr ; exit }
       Note that "here" needs to be very first dictionary entry - this is
       verified by the test code
- dictionary headers for the "primitives"
       Generated from code.prims by genprims and assembled from dict.s
       usual format: align; pad; nfa; lfa; cfa:{ $prim ; exit }
       There are no ordering constraints except that the dictionary entry
       preceding the first one needs to be "latest"
- dictionary headers for the defined words/"definitions"
       Generated from defs.4th by genrom and assembled from defs[_dict].s
       usual format: align; pad; nfa; lfa; cfa:{ ... ; exit }
- Machine code for the primitives (usually starting on a 256 byte boundary)
       Generated from code.prims by genprims and assembled from prims[_dict].s

For now, RAM contains:
- the datastack
- the return stack
- the "primitive" variables
- the "memory area" (used by the return stack and the runtime dictionary)

To summarize:
        ROM: {
                startup/init code : forth.s
                init/test byte code : rom.4th
                primitive variable dictionary headers : code.prims
                        cfa : lit $var ; exit : {
                                here
                                ...
                                latest
                        }
                primitive code dictionary headers : code.prims
                        cfa : $prim ; exit
                defined words dictionary headers : defs.4th
                        cfa : ... ; exit
                machine code for the primitives, starting on 256 byte boundary?
                        assembled from code.prims
        }
        RAM: { // ordering and overlap of these sub components is undefined
                data stack
                return stack
                "primitive" variables
                available memory
        }

23 Mar '23
----------
So now that the x86 assembly userland port has also been completed, I can now
break my self imposed radio silence.

This port took only about a week but that required me to work over the weekend
and pretty much ignore everything else that was going on around me. So I still
think a reasonable estimate for how long a port should take is 2-4 weeks if we
can assume that all the other dependencies are resolved and there are no other
blockers.

The fact that the MMU on the x86 provides decent fault isolation and quickly
generates a SIGSEGV instead of corrupting random locations in memory also
helped a lot with the turnaround.

In any case, being productive is a function of lots of environmental variables
so being able to finish this in a week just goes to show the importance of
having fairly good infrastructure to be able to build and test things quickly.
All in all, I think I now have a good enough framework in place for porting all
of this to other CPUs in the future.

Since the C port and x86 assembly port both work in userland, running natively,
it gives me an opportunity to compare compiler vs hand written code performance

Running `perf stat`, I generated the following table comparing the two:

.-------------------------------------------------------.
| Metric		| C		| Assembly	|
+-----------------------+---------------+---------------+
| Task-clock (msec)	| 4.439651	| 3.957470	|
| CPUs utilized		| 0.884		| 0.861		|
| Cycles		| 9,969,446	| 8,866,091	|
| Instructions		| 10,365,760	| 6,413,838	|
| Insns per cycle	| 1.04		| 0.72		|
| Branches		| 2,374,783	| 1,734,081	|
| Branches M/sec	| 534.903	| 438.179	|
| Branch-misses		| 204,129	| 130,745	|
| % of all branches	| 8.60% (56.95%)| 7.54% (41.86%)|
| Time elapsed		| 0.005021309(s)| 0.004598909(s)|
'-------------------------------------------------------'

The hand written assembly version appears to be better on pretty much every
metric, so I assume compilers still have some catching up to do ; gcc --version
reports: gcc (Ubuntu 5.3.1-14ubuntu2) 5.3.1 20160413

Looking forward, I still need to get to a conclusion on what tools to use for
future CPU ports - unicorn appears to be the best choice I've found so far.
But for now, this project goes on the backburner since I'll need to address my
"real world" problems first (starting with my leaky patio roof for one, and tax
season will soon be upon me, before I even know it).

So the SPARC and m68k ports (and all the others), will just have to wait.

Oh, and before I forget: Happy Birthday Shiji!

01 Apr '23
----------
While researching SPARC32 emulation, I had one of my usual pivot ideas: rather
than start directly on SPARC which needs emulation, why not first start with
an x86 32 bit port which can run natively so that the x86 gets "full porting
coverage" in some sense, and be done with it. The older x86 and x86-as ports
provide 16-bit "realmode", if you will, coverage of the x86 and the x86-user
(and the C port) were tested on 64 bits so this could be the last hurrah on
x86 with a 32 bit port.

Since I have a really ancient 32 bit x86 Toshiba laptop (which I think I bought
new in 2003) which is still going strong, I decided to use it for the 32 bit
port. The first issue with using it though was getting it to use a modern linux
distro (I used to run Solaris on it). Ubuntu is my usual distro of choice but
none of the recent versions of Ubuntu appear to be able to even boot up on the
"puny" 256MB memory that this laptop has.

After a bunch of research and experiments with various distros, I've settled
on using it with NixOS 22.05, which according to Repology has the largest
selection of package choices. I don't need a lot of stuff for development
but it is nice to know I have choices, if I need it.

Since GNOME is too bloated to run on 256MB of memory, I needed a slim window
manager, so I've installed dwm on it for now although at some point I want to
port olvwm to it as well. For actual development, I was able to pull in a
fairly recent version of gcc (10.3.0) using nix-shell. So with all of those
preliminaries out of the way, I can now start on the actual port.

03 Apr '23
----------
Rather than start from scratch, as I'd done with most of the earlier ports,
this time, I'm using most of the code "as is" from the x86-user port since I
assume most of the code can be common across these two ports.

To start off, I've modified the runallsteps scripts since it makes it easy to
run all the regression steps, if needed. Next I copied over files as needed
from x86-user into x86-32 and made some small tweaks for the 64 bit to 32 bit
change and ran make/`runallsteps x86-32` until I had a passing "step 0".

The primary changes required were to switch all the registers to use the 32 bit
variants and to use the 32 bit "lodsl" instruction equivalent of the 64 bit
"lodsq" instruction.

----------

The API for calling putchar from assembly appears to have changed with the
newer version of OS/glibc/gcc that I'm using for this port, so rather than
try to parameterize that as well, I'm going to just document it here and
quietly move on since this is just another userland port which I'm using
only to sanity check the 32 bit port.

05 Apr '23
----------
I'm starting to realize that I should have named the directories better, but
in my defense I'll just say that naming is hard.

The just concluded "x86-32" port denotes an "x86 32 bit userland assembly" port
which currently holds the record for how fast a port can be done mostly because
it just needed a few fairly simple modifications to the "x86-user" port.

The "x86-user" port in turn denoted the "x86 64 bit userland assembly" port
which held the previous record for how soon a port could be done - at ~1 week.

From the timestamps, starting from the beginning to the end of the port, it
took ~3 days as per the git log (Apr 1 to Apr 4) but looking in detail at the
git timestamps, the actual time spent appears to only have been ~5-6 hours.

I guess that it helped that I used a script which automated much of the grunt
work - since it updated the "step" used in the stepfile at each incremental
step before running `make` and `git commit`ted the change on success.

The script was setup to exit when the `make` invocation failed so that it let
me intervene and fix up things manually whenever there was a failure. I feel
that the script definitely helped speed things up since it got rid of all of
the mundane work and allowed me to focus on just the new bugs that showed up.

Unfortunately, this port hit a speed bump while trying to integrate it back
into the existing regression test harness. Since this is an x86 32 bit port, I
first tried to compile a 32 bit x86 binary on my 64 bit laptop by using the
"-m32" option to cc but that failed with:
	/usr/bin/ld: cannot find crt1.o: No such file or directory
	/usr/bin/ld: cannot find crti.o: No such file or directory
in addition to even more errors about an inability to find libgcc

In an ideal world, the only thing needed to fix this is probably to run:
	`apt update ; apt install libc6:i386 libgcc1:i386`

Unfortunately, I'm running Ubuntu 16.04, a distro which is ancient and is no
longer supported since it is past it's 5 year LTS. So I can't install the newer
libraries using `apt`. I could upgrade to a newer Ubuntu distro but all of the
newer distros, after 16.04, need atleast 4 GB of memory which my ancient laptop
does not have and I'm definitely not going out to buy a newer laptop just to
continue on the treadmill of never ending software bloat which appears to have
become the hallmark of modern software. Do people even remember that we went to
the moon (and returned back, safely) using ~70KB ROM and ~2KB RAM? Sorry this
is turning into a rant, I just needed to vent.

For the record, I'll note that the changes required in the makefile to run into
the errors noted earlier was the addition of these directives in the makefile:
	ASFLAGS=-m32
	LDFLAGS=-m32

I made a half-hearted attempt to see if clang fared any better by setting
	CC=clang
in the makefile and it came up with an even longer list of missing libraries:
	/usr/bin/ld: cannot find crt1.o: No such file or directory
	/usr/bin/ld: cannot find crti.o: No such file or directory
	/usr/bin/ld: cannot find crtbegin.o: No such file or directory
	/usr/bin/ld: cannot find -lgcc
	/usr/bin/ld: cannot find -lgcc_s
	/usr/bin/ld: cannot find -lc
	/usr/bin/ld: cannot find -lgcc
	/usr/bin/ld: cannot find -lgcc_s
	/usr/bin/ld: cannot find crtend.o: No such file or directory
	/usr/bin/ld: cannot find crtn.o: No such file or directory

So now that I'm kind of stuck, I see a couple of choices to move forward.

My knee jerk choice is to ignore this issue by not adding the 32-bit build as
part of the regression test since I know that it was built and tested perfectly
fine on a 32 bit system, but that would be just be me trying to weasel out of
this stupid problem.

Another alternative given that I know that NixOS can run without any issues
on my ancient 32-bit laptop (with "only" 256MB of memory) would be to "upgrade"
my laptop from Ubuntu 16.04 to the latest version of Nix. But I don't want to
go through what appears to be an unnecessary hassle especially since this is
the "primary" system on which I do all of my coding and I don't know what other
problems will show up trying to do the upgrade to a completely alien distro.

Since both the available choices don't appear too palatable, I'm going to be
doing some more research trying to figure out what other solutions exist which
might include the less invasive option of giving one of the newer "Debian lite"
ISO images a whirl.

Since it is starting to get close to tax time though, that is the high priority
item on my todo list now, so I'll need to get that done before coming back to
see what I can do about this stupid mess.

For now I'm going to disable the regression test for the x86-32 port.

18 Apr '23
----------
I'm restarting from where I left off before tax time and spring break caused an
interruption to my regular schedule.

It did take a while to find a good solution to the cross compilation issue that
I'd mentioned in the previous JOURNAL entry but the solution that I've found
after all of the research done over the past couple of weeks is just too good
to be true so all of the time spent reading up stuff on various internet forums
(Stack Overflow, Ask Ubuntu, Reddit, etc) was well worth the effort.

I'll start off with some background: rather than try to solve the immediate
problem of figuring out how to run (or even build) 32 bit x86 binaries on an
x86_64 system, which I was struggling with earlier (documented in the previous
JOURNAL entry) I tried to find a solution to the older problem of how I could
go about testing other architectures on my laptop. That research turned up
QEMU user mode - I was aware of QEMU system emulation but QEMU user was new to
me.

So now that I'm no longer limited to just the older architectures supported by
SIMH or having to do the equivalent of "DIY emulation" using Unicorn (which in
turn is also layered over QEMU), I have the luxury of emulating ~43 different
architectures using QEMU directly from my laptop without much effort.

With that temporary resolution to the emulation problem out of the way, I could
then go back to figuring out how to do cross compilation for all of the various
architectures. The simplest (and quite possibly the absolute gem of a solution)
which is beautifully documented in Andrew Kelley's blog about `zig cc`[1]
[1] `zig cc` a Powerful Drop-In Replacement for GCC_Clang - Andrew Kelley.html
is: just use `zig cc`. Of course it does add a dependency on `zig` but in some
sense that may be a net win since, as Andrew points out in his blog, you are
trading in clang using ~380 MiB for zig using just ~45 MiB for what is vastly
more functionality. Note that using `zig cc` does come with a one-time cost in
terms of building out the cache the very first time a build is done.

I'm tempted to give zig - the language, a shot as well - especially since it
has the `comptime` feature which mirrors the equivalent functionality of Forth.

Some of the other options I looked before deciding on `zig cc` were:
1. A bunch of VM/container/schroot/chroot alternatives, each seemingly more
   complicated than the next.
2. `cargo cross` (which wouldn't work for me due to the `apt` dependencies
   mentioned in the previous entry, dated 05 Apr '23, of this JOURNAL)
3. `cargo test` using the target.triple.runner (rust only? though, I think)
4. Nix's pkgCross which I didn't investigate too deeply since it appears to be
   tied at the hip to nixpkgs (and the documentation wasn't too clear either)

20 Apr '23
----------
As I mentioned in the previous JOURNAL entry, although `zig cc` is currently
needed only to build and test the 32-bit x86 version on a 64-bit x86 system,
I'm going to start cautiously and see how `zig cc` fares on the plain old C
code in the `C` subdirectory before attempting more experiments with `zig cc`.

Another advantage to doing it this way is that I can use the `target` option
to generate code for other architectures easily (so I can have a look at the
assembly before doing the actual port).

I started off by running the usual regression test (running `./runallsteps C`),
and hit the first issue which was that zig (or more likely clang, under the
covers) allocates the variables at different locations compared to gcc. This
resulted in requiring changes to the `runallsteps` regression script. For the
most part the changes involved were:
	- run the regression script (until a failure is seen)
	- cd C ; objdump -dx ./forth_dict | grep 'vars$'
	- copy paste the address into the right place in the runallsteps script
	- rinse lather repeat
But this started getting old pretty fast so I decided to bring the memory tests
(starting at step 13) in parity with the x86 assembly versions by changing the
load address to use the memory contents of init but this failed as well since
`zig cc`/`clang` moves the locations of the functions around after each build
(likely to improve security by using ASLR).

After puzzling over this a bit, I ran objdump after compiling a couple of times
and tried to see if there were any addresses that remained unchanged between
the various runs and it appears that the only set of addresses that seem to
remain unchanged between runs are the following:
  SYMTAB               0x00000000002002e8
  STRTAB               0x0000000000200400
  GNU_HASH             0x00000000002003a8
  HASH                 0x00000000002003c8
  VERSYM               0x0000000000200378
  VERNEED              0x0000000000200384

For now I've just picked the very first address just to get this over with.

Since the only reason for having a "test" field in the "var" struct was to be
able to read it (using it's hardcoded address), that can now be removed.

One nice result of this exercise is that the regression test for C is much
simpler since all of the hardcoded constants that were stuck in there are now
eliminated and may actually make this portable to other systems without any
changes to the `fpp.config.C` configuration file.

Just to check for portability between zig/clang vs gcc I compared the objdump
between the zig generated binary and the gcc generated binary, and see that
they have no addresses in common at all, so this code will SEGV if it is
regression tested using gcc from step 13 onward. I could obviously solve that
by splitting the C directory into C-gcc (which keeps the current semantics) and
create something new, say C-zig-cc (to use zig cc), but I'm not going to bother
with that for now. Although portability is the driving force behind this code,
portability across CPU's, not compilers, is what I'm aiming for.

21 Apr '23
----------
Before moving on to focus on the remaining work, I decided to redo the earlier
comparison that I had done on 23 Mar '23 to include the `zig cc` results as
well. Since `zig cc` uses the newer clang version (zig cc --version reports
"clang version 16.0.1"), it gives me a chance to compare the latest clang
compiler version vs a gcc version from ~7 years ago vs hand written assembly
code performance.

The table below is a copy of the original table with the addition of another
column to track the performance of the binary generated using `zig cc`/clang
and all of the performance data is generated using `perf stat` as before.

.-----------------------------------------------------------------------.
| Metric		| GCC 5.3.1	| Assembly	| zig cc/clang	|
+-----------------------+---------------+---------------+---------------+
| Task-clock (msec)	| 4.439651	| 3.957470	| 2.886195	|
| CPUs utilized		| 0.884		| 0.861		| 0.831		|
| Cycles		| 9,969,446	| 8,866,091	| 6,435,679	|
| Instructions		| 10,365,760	| 6,413,838	| 8,338,773	|
| Insns per cycle	| 1.04		| 0.72		| 1.30		|
| Branches		| 2,374,783	| 1,734,081	| 1,297,254	|
| Branches M/sec	| 534.903	| 438.179	| 449.469	|
| Branch-misses		| 204,129	| 130,745	| 101,190	|
| % of all branches	| 8.60% (56.95%)| 7.54% (41.86%)| 7.80% (28.73%)|
| Time elapsed		| 0.005021309(s)| 0.004598909(s)| 0.003472718(s)|
'-----------------------------------------------------------------------'

So this time I can gracefully accept defeat at the hands of the latest compiler
since it has me beat on almost every metric except for the total number of
instructions executed (which I think is a proxy for how small the code can be).

BTW, this was using the -Oz optimization option to clang so I assume that the
only place compilers are still lagging (at least on x86, which I assume has
received the bulk of the optimizations), is in generating compact code compared
to what can be done manually. So I think there is still a reason to forge ahead
with my hobby project since I'm targeting it for resource constrained systems.

22 Apr '23
----------
Yesterday's journal entry about the large sizes of the generated binaries got
me wondering about why they need to be that large. For example, the size of
C/forth_dict generated using `zig cc -Oz` is ~31K/12K (before/after running
`strip` on the generated binary). The size of the code generated for x86-user,
which is generated from x86 assembly, but running in userland, is ~36K/14K
(again, the sizes listed are before/after strip'ing). Since these sizes are
~4-5x larger than the corresponding "baremetal" equivalents in x86/forth_dict
it makes sense to assume that all of that bloat is probably coming from the
libc/libgcc/libdl/crt* libraries.

These libraries are required for the support of start/exit and getchar/putchar.
So it sounds like I could try to shrink them down by coding to Linux's syscall
layer directly instead of using any of the higher level libraries. Obviously,
that comes with the risk of ABI changes that break that interface but since I
just need SYS_{exit,read,write}, 3 constants total, I think I can live a little
dangerously. I spent a fair bit of time researching how to do all that so I'm
going to turn that into yet another x86 port which I'll call x86-sys.

So that's what I'm going to be working on next. As a data point, the "step 0"
implementation using the syscall interface to just halt, clocks in at only 664
bytes compared to a minimal C/assembler code that needs more than ~10x that
size due to all of the libraries mentioned above.

25 Apr '23
----------
I was able to wrap up the x86-sys port also fairly quickly. It was completed in
just about ~2 days but it was possible to finish this up quickly only because
it was just yet another variation on one of the existing x86 ports - in this
case it was a mod of the x86-user port to create a standalone/freestanding
binary without any library dependencies, by directly calling into the Linux
syscall layer and thus continue to have it work in userland.

The overall size of the binary is now ~28K/8K (before/after running `strip`)
which is a savings of about 4KB on the strip'ed binary compared to the version
generated by `zig cc` (with the -Oz flag), which I think is significant since
adding in the libraries result in a ~50% increase in size.

One problem with using the syscall interface directly is that it results in a
measurable performance impact ; this implementation clocks in as the worst of
the bunch among all of the x86 ports as measured by `perf stat`. I assume this
is primarily because it is invoking syscalls which can be expensive, instead of
library calls, primarily for the putchar/getchar routines, which just cache the
data in file system buffers in memory and issues syscalls only to flush the
data, perhaps just once, at the end of the execution.

Here's a summary of the various x86 port variations that have been done so far:
16 bit real mode:
	x86	: using nasm (running baremetal, not even a BIOS)
	x86-as	: using GNU as (running baremetal, not even a BIOS)
32 bit:
	x86-32	: using GNU as (running on a 32-bit libc userland)
64 bit:
	x86-user: using GNU as, libc userland
	C	: using GCC -Os, libc userland
	C	: using zig cc -Oz, libc userland
	x86-sys	: GNU as, Linux syscall

With all of these x86 port variations out of the way, I think I'm going to give
x86 a rest (for real, this time) and move on to other architectures. So the
older decision of making a choice between SPARC and m68k is back on the table.

I'll take a look at trying to build and test them using cross-compilation using
`zig cc` (or any other available means if that runs into problems) along with
emulation using qemu-user (or any other available alternatives) and see how far
I can get.

27 Apr '23
----------
Although I keep declaring that I'm finished with x86, for real this time, there
seems to always be some new tiny little detail that crops up to remind me of
unfinished business.

Before starting out on using `zig cc` on SPARC or m68k, I wondered if it was
safer to try it out on the x86 assembly ports first. Since I was able to
successfully use it on the C port, it seemed sensible to try it on the x86-user
assembly port which is also 64 bit and can run natively. So I went ahead and
did that.

The very first issue that I ran into with switching to using `zig cc` from GCC
(or perhaps more correctly, gas) was that clang does not seem to be aware of
the "movsxd" instruction and errors out. I worked around that by switching it
to use the "movsbq" instruction instead, which had the nice effect of reducing
the code by one line.

After fixing that I ran into a really strange issue that took a while to debug.
It turns out that `zig cc` internally uses a cache but the .o object file from
assembling forth.S doesn't get marked as stale after the increment of each step
value done by the runallsteps regression script, probably due to all of the
preprocessing shenanigans that I do as part of the make. Rather than file a bug
against `zig cc`, since I'm unsure for now, about exactly who is at fault here,
I've just added a line in the runallsteps script to remove the stale entry
before each build.

Once I was past that, at step 13, there was the usual problem that the address
and value that are fetch'ed and compared need to be modified since `zig cc`
counts as a new "platform" on which this code is being run.

The final issue that I ran into was at step 50 where I consistently hit a segv.
This reminded of the earlier problem which I'd run into during the x86-sys port
which I'd fixed by bumping up the memory allocation and that fixed the issue
here as well.

With all of those bugs fixed, `./runallsteps x86-user` runs through all of the
62 steps successfully, regression testing each step along the way.

Thinking about next steps, a useful follow up to this exercise might be try out
`zig cc` for the 32 bit x86-32 assembly port as well so that I can enable
regression tests for x86-32, which are currently disabled (see my earlier entry
dated 5 Apr '23 for the reasons). Before venturing off into foreign lands by
trying to see how `zig cc` handles non-x86 architectures, it seems prudent to
check how a 32 bit x86 binary generated using `zig cc` fares on my 64 bit host.

29 Apr '23
----------
I managed to get `zig cc` to build 32 bit binaries on the x86-32 port so it can
now run natively on my 64-bit Ubuntu system. With this change, the x86-32 port,
which was the one outlier that wasn't part of the regression tests, can also
now be added to the set of ports which are regression tested.

For the record, this testing was done using `zig version`
	0.11.0-dev.2725+4374ce51b.

`zig targets` lists two targets for 32-bit: x86-linux-gnu and x86-linux-musl
these are listed under libc, which I assume means these targets are supported
on Linux using libc. Since I'm using an ancient version of Ubuntu which uses
glibc 2.23, my first attempt was to use the `x86-linux-gnu` target using:
	zig cc -target x86-linux-gnu
Although I was able to compile a binary, which is reported as having 32 bitness
	ELF 32-bit LSB executable, Intel 80386
(the above output was from `file`), it fails to run and even `strace` whines:
	execve("./a.out", ["./a.out"], [/* 30 vars */]) = -1 ENOENT

Rather than spend too much time debugging this, I decided to give the next
available option, which was the `x86-linux-musl` target a shot using:
	zig cc -target x86-linux-musl
This was able to successfully generate a 32 bit binary which was runnable.

From there, it was just a matter of removing the stale object from zig's cache
(just like I'd mentioned in the previous JOURNAL entry), and then changing the
ADDR and VALUE parameters in the `fpp` configuration file at step 13 and then
bumping up the memory allocation at step 24 (and again all the way to 2K at
step 62). With all of this sorted out, `./runallsteps x86-32` can now run to
completion through all 62 regression steps.

Despite my earlier claim that the 16-bit, 32-bit and 64-bit ports complete the
x86 porting landscape, I realized while working on this change that each of the
available APIs (such as baremetal, BIOS, UEFI, multiboot, various OS and
library combos) are all viable porting targets. But I think I've ported x86
enough times already so I'm going to give it a rest and move on from x86, for
real this time.
